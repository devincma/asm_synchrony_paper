{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spike Morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from get_iEEG_data import *\n",
    "from spike_detector import *\n",
    "from spike_morphology import *\n",
    "from iEEG_helper_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- -- IEEG password file saved -- --\n"
     ]
    }
   ],
   "source": [
    "def create_pwd_file(username, password, fname=None):\n",
    "    if fname is None:\n",
    "        fname = \"{}_ieeglogin.bin\".format(username[:3])\n",
    "    with open(fname, \"wb\") as f:\n",
    "        f.write(password.encode())\n",
    "    print(\"-- -- IEEG password file saved -- --\")\n",
    "\n",
    "\n",
    "create_pwd_file(\"dma\", \"mycqEv-pevfo4-roqfan\")\n",
    "\n",
    "with open(\"dma_ieeglogin.bin\", \"r\") as f:\n",
    "    s = Session(\"dma\", f.read())\n",
    "\n",
    "ds = s.open_dataset(\"HUP210_phaseII\")\n",
    "all_channel_labels = np.array(ds.get_channel_labels())\n",
    "label_idxs = electrode_selection(all_channel_labels)\n",
    "labels = all_channel_labels[label_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ieeg_data, fs = get_iEEG_data(\n",
    "    \"dma\",\n",
    "    \"dma_ieeglogin.bin\",\n",
    "    \"HUP210_phaseII\",\n",
    "    (179677) * 1e6,\n",
    "    (179677 + 20) * 1e6,\n",
    "    labels,\n",
    ")\n",
    "\n",
    "fs = int(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['LJ12'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m good_channel_indicies \u001b[39m=\u001b[39m good_channels_res[\u001b[39m0\u001b[39m]\n\u001b[1;32m      3\u001b[0m good_labels \u001b[39m=\u001b[39m labels[good_channel_indicies]\n\u001b[0;32m----> 4\u001b[0m ieeg_data \u001b[39m=\u001b[39m ieeg_data[good_labels]\u001b[39m.\u001b[39mto_numpy()\n\u001b[1;32m      6\u001b[0m ieeg_data \u001b[39m=\u001b[39m common_average_montage(ieeg_data)\n\u001b[1;32m      9\u001b[0m \u001b[39m# Apply the filters directly on the DataFrame\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/leif/littlab/users/devinma/Libraries/miniconda3/lib/python3.11/site-packages/pandas/core/frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3812\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 3813\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   3815\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[0;32m/mnt/leif/littlab/users/devinma/Libraries/miniconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6067\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6070\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6072\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   6073\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6074\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/leif/littlab/users/devinma/Libraries/miniconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:6133\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6130\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6132\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m-> 6133\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['LJ12'] not in index\""
     ]
    }
   ],
   "source": [
    "good_channels_res = detect_bad_channels_optimized(ieeg_data.to_numpy(), fs)\n",
    "good_channel_indicies = good_channels_res[0]\n",
    "good_labels = labels[good_channel_indicies]\n",
    "ieeg_data = ieeg_data[good_labels].to_numpy()\n",
    "\n",
    "ieeg_data = common_average_montage(ieeg_data)\n",
    "\n",
    "\n",
    "# Apply the filters directly on the DataFrame\n",
    "ieeg_data = pd.DataFrame(notch_filter(ieeg_data.values, 59, 61, fs))\n",
    "ieeg_data = pd.DataFrame(bandpass_filter(ieeg_data.values, 1, 70, fs))\n",
    "\n",
    "ieeg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = spike_detector(\n",
    "    data=ieeg_data,\n",
    "    fs=fs,\n",
    "    labels=good_labels,\n",
    ")\n",
    "print(f\"{len(np.unique(output[:, 2]))} spikes detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.astype(int)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_good = 0\n",
    "\n",
    "for spike in output:\n",
    "    channel_id = spike[1]\n",
    "    peak_index = spike[0]\n",
    "    spike_signal = ieeg_data[peak_index - 1000 : peak_index + 1000][\n",
    "        channel_id\n",
    "    ].to_numpy()\n",
    "\n",
    "    basic_features, advanced_features, is_valid, bad_reason = extract_spike_morphology(\n",
    "        spike_signal\n",
    "    )\n",
    "\n",
    "    if is_valid:\n",
    "        num_good += 1\n",
    "        # peak, left_point, right_point, slow_end, slow_max = basic_features\n",
    "        # print(basic_features)\n",
    "        # print(advanced_features)\n",
    "        # plt.plot(spike_signal)\n",
    "        # plt.plot(peak, spike_signal[peak], \"x\")\n",
    "        # plt.plot(left_point, spike_signal[left_point], \"o\")\n",
    "        # plt.plot(right_point, spike_signal[right_point], \"o\")\n",
    "        # plt.plot(slow_end, spike_signal[slow_end], \"o\", color=\"k\")\n",
    "        # plt.title(\"A spike\")\n",
    "        # plt.xlim(250, 1750)\n",
    "        # plt.show()\n",
    "    else:\n",
    "        print(bad_reason)\n",
    "        plt.plot(spike_signal)\n",
    "        plt.title(f\"NOT a spike because of {bad_reason}\")\n",
    "        plt.xlim(250, 1750)\n",
    "        plt.show()\n",
    "    # elif bad_reason != \"Short segment\":\n",
    "    #     print(bad_reason)\n",
    "    # plt.plot(spike_signal)\n",
    "    # plt.title(f\"NOT a spike because of {bad_reason}\")\n",
    "    # plt.xlim(250, 1750)\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = [\n",
    "#     \"slow_max\",\n",
    "#     \"rise_amp\",\n",
    "#     \"decay_amp\",\n",
    "#     \"slow_width\",\n",
    "#     \"slow_amp\",\n",
    "#     \"rise_slope\",\n",
    "#     \"decay_slope\",\n",
    "#     \"average_amp\",\n",
    "# ]\n",
    "\n",
    "# for feature in features:\n",
    "#     fig, axarr = plt.subplots(\n",
    "#         nrows=(len(all_spikes_dfs) + 1) // 2,\n",
    "#         ncols=2,\n",
    "#         figsize=(16, 4 * (len(all_spikes_dfs) + 1) // 2),\n",
    "#     )\n",
    "#     fig.suptitle(f\"Change in {feature} across hour\")\n",
    "\n",
    "#     for idx, (df, hup_id, fs) in enumerate(\n",
    "#         zip(all_spikes_dfs, completed_hup_ids, all_fs)\n",
    "#     ):\n",
    "#         grouped = df.groupby(\"peak_hour\").mean()\n",
    "#         row = idx // 2\n",
    "#         col = idx % 2\n",
    "#         sns.regplot(\n",
    "#             x=grouped.index,\n",
    "#             y=grouped[feature],\n",
    "#             ax=axarr[row, col],\n",
    "#             lowess=True,\n",
    "#             scatter_kws={\"s\": 10},\n",
    "#             line_kws={\"color\": \"red\"},\n",
    "#         )\n",
    "#         axarr[row, col].set_title(f\"HUP {hup_id} {fs}Hz\")\n",
    "#         axarr[row, col].set_xlabel(\"Hour\")\n",
    "#         axarr[row, col].set_ylabel(feature)\n",
    "\n",
    "#         # Load seizure times and plot vertical lines\n",
    "#         seizure_times_sec = np.load(os.path.join(SEIZURES_DIR, f\"HUP_{hup_id}.npy\"))\n",
    "#         seizure_times_hour = seizure_times_sec[:, 0] / 3600  # convert seconds to hours\n",
    "#         for seizure_time in seizure_times_hour:\n",
    "#             axarr[row, col].axvline(x=seizure_time, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "#     # Delete unused subplots\n",
    "#     for i in range(len(all_spikes_dfs), 2 * ((len(all_spikes_dfs) + 1) // 2)):\n",
    "#         row = i // 2\n",
    "#         col = i % 2\n",
    "#         fig.delaxes(axarr[row, col])\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.subplots_adjust(top=0.9)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_and_plot_longest_spike_train(test, patient_hup_id, fs, ax):\n",
    "#     # Group by 'sequence_index_mask' and count rows in each group\n",
    "#     grouped = test.groupby(\"sequence_index_mask\").size()\n",
    "\n",
    "#     # Identify the sequence_index_mask with the maximum count\n",
    "#     longest_spike_train_mask = grouped.idxmax()\n",
    "#     longest_spike_train_count = grouped.max()\n",
    "\n",
    "#     print(\n",
    "#         f\"The longest spike train has sequence_index_mask: {longest_spike_train_mask} with {longest_spike_train_count} spikes.\"\n",
    "#     )\n",
    "\n",
    "#     # To get the rows corresponding to the longest spike train:\n",
    "#     longest_spike_train_df = test[\n",
    "#         test[\"sequence_index_mask\"] == longest_spike_train_mask\n",
    "#     ]\n",
    "\n",
    "#     # Get the smallest peak_index and largest peak_index\n",
    "#     smallest_peak_index = longest_spike_train_df[\"peak_index\"].min()\n",
    "#     largest_peak_index = longest_spike_train_df[\"peak_index\"].max()\n",
    "\n",
    "#     dataset_name = f\"HUP{patient_hup_id}_phaseII\"\n",
    "#     dataset = session.open_dataset(dataset_name)\n",
    "#     all_channel_labels = np.array(dataset.get_channel_labels())\n",
    "\n",
    "#     ieeg_data, _ = get_iEEG_data(\n",
    "#         \"dma\",\n",
    "#         \"dma_ieeglogin.bin\",\n",
    "#         f\"HUP{patient_hup_id}_phaseII\",\n",
    "#         (smallest_peak_index - 1000) / fs * 1e6,\n",
    "#         (largest_peak_index + 1000) / fs * 1e6,\n",
    "#         all_channel_labels,\n",
    "#     )\n",
    "\n",
    "#     print(ieeg_data.shape)\n",
    "#     for channel in ieeg_data.columns:\n",
    "#         ax.plot(ieeg_data[channel])\n",
    "\n",
    "#     ax.set_ylabel(\"Amplitude\")\n",
    "#     ax.set_xlabel(\"Time\")\n",
    "#     ax.set_title(f\"HUP {hup_id}\")\n",
    "\n",
    "#     return ieeg_data\n",
    "\n",
    "# # Creating a subplot figure\n",
    "# n_patients = len(all_spikes_dfs)\n",
    "\n",
    "\n",
    "# # Looping over the dataframes\n",
    "# for all_spikes_df, fs, hup_id in zip(all_spikes_dfs, all_fs, completed_hup_ids):\n",
    "#     print(f\"Processing HUP {hup_id}...\")\n",
    "\n",
    "#     # Check for sequence change based on sequence_index or inter_spike_interval_samples\n",
    "#     change_mask = all_spikes_df[\"inter_spike_interval_samples\"] > 55\n",
    "\n",
    "#     # Create the sequence_index_mask\n",
    "#     all_spikes_df[\"sequence_index_mask\"] = change_mask.astype(int).cumsum()\n",
    "\n",
    "#     # Load seizure times and plot vertical lines\n",
    "#     seizure_times_sec = np.load(os.path.join(SEIZURES_DIR, f\"HUP_{hup_id}.npy\"))\n",
    "#     seizure_times_hour = seizure_times_sec[:, 0] / 3600  # convert seconds to hours\n",
    "\n",
    "#     fig, axs = plt.subplots(1, 3, figsize=(15, 6))  # 1 row, 3 columns for each patient\n",
    "\n",
    "#     # Extracting Fano Factors for the three scenarios:\n",
    "#     # 1. Max medication\n",
    "#     max_medication_data = all_spikes_df[all_spikes_df[\"peak_hour\"].isin([0, 1, 2])]\n",
    "#     get_and_plot_longest_spike_train(max_medication_data, hup_id, fs, axs[0])\n",
    "#     axs[0].set_title(f\"HUP {hup_id} - Max Medication\")\n",
    "\n",
    "#     # 2. Before seizure\n",
    "#     first_seizure_hour = int(seizure_times_hour[0])\n",
    "#     before_seizure_data = all_spikes_df[\n",
    "#         all_spikes_df[\"peak_hour\"].isin(\n",
    "#             range(first_seizure_hour - 2, first_seizure_hour + 1)\n",
    "#         )\n",
    "#     ]\n",
    "#     get_and_plot_longest_spike_train(before_seizure_data, hup_id, fs, axs[1])\n",
    "#     axs[1].set_title(f\"HUP {hup_id} - Before Seizure\")\n",
    "\n",
    "#     # 3. After seizure\n",
    "#     last_hours = sorted(all_spikes_df[\"peak_hour\"].unique())[-6:-3]\n",
    "#     after_seizure_data = all_spikes_df[all_spikes_df[\"peak_hour\"].isin(last_hours)]\n",
    "#     get_and_plot_longest_spike_train(after_seizure_data, hup_id, fs, axs[2])\n",
    "#     axs[2].set_title(f\"HUP {hup_id} - After Seizure\")\n",
    "\n",
    "#     fig.suptitle(f\"HUP {hup_id}\")\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()  # Displays the figure"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
