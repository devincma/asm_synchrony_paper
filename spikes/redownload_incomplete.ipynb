{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ieeg.auth import Session\n",
    "\n",
    "from get_iEEG_data import *\n",
    "from iEEG_helper_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPIKES_OUTPUT_DIR = \"../../Data/spikes/devin_spikes/\"\n",
    "SYNCHRONY_broadband_DIRECTORY = \"../../Data/synchrony/all/broadband\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load HUP_implant_dates.xlsx\n",
    "nina_patients_df = pd.read_excel(\"../../Data/HUP_implant_dates.xlsx\")\n",
    "# Make the hup_id column integers\n",
    "nina_patients_df[\"hup_id\"] = nina_patients_df[\"hup_id\"].astype(int)\n",
    "nina_patients_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Already completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incomplete_hup_ids = [\n",
    "    143,\n",
    "    146,\n",
    "    155,\n",
    "    157,\n",
    "    158,\n",
    "    161,\n",
    "    163,\n",
    "    164,\n",
    "    165,\n",
    "    171,\n",
    "    182,\n",
    "    188,\n",
    "    206,\n",
    "    210,\n",
    "]\n",
    "incomplete_hup_ids.sort()\n",
    "print(incomplete_hup_ids)\n",
    "len(incomplete_hup_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep the rows in nina_patients_df that have hup_ids not in completed_hup_ids\n",
    "nina_patients_df = nina_patients_df[nina_patients_df[\"hup_id\"].isin(incomplete_hup_ids)]\n",
    "# Reset the index\n",
    "nina_patients_df = nina_patients_df.reset_index(drop=True)\n",
    "nina_patients_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a boolean column in nina_patients_df called is_single_dataset and make it True if IEEG_Portal_Number ends with \"phaseII\"\n",
    "nina_patients_df[\"is_single_dataset\"] = nina_patients_df[\n",
    "    \"IEEG_Portal_Number\"\n",
    "].str.endswith(\"phaseII\")\n",
    "nina_patients_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows in nina_patients_df where is_single_dataset is False\n",
    "nina_patients_df = nina_patients_df[nina_patients_df.is_single_dataset == True]\n",
    "# Sort by hup_id in ascending order\n",
    "nina_patients_df = nina_patients_df.sort_values(by=[\"hup_id\"], ascending=True)\n",
    "# Drop columns Implant_Date, implant_time, Explant_Date, weight_kg\n",
    "nina_patients_df = nina_patients_df.drop(\n",
    "    columns=[\"Implant_Date\", \"implant_time\", \"Explant_Date\", \"weight_kg\"]\n",
    ")\n",
    "# Reset index\n",
    "nina_patients_df = nina_patients_df.reset_index(drop=True)\n",
    "nina_patients_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nina_patients_df[nina_patients_df[\"hup_id\"] % 2 == 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nina_patients_df[nina_patients_df[\"hup_id\"] % 2 == 1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = nina_patients_df[nina_patients_df[\"hup_id\"] % 2 == 1].reset_index(drop=True)\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Using Carlos session\")\n",
    "with open(\"agu_ieeglogin.bin\", \"r\") as f:\n",
    "    session = Session(\"aguilac\", f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through every row in batch\n",
    "for index, row in batch.iterrows():\n",
    "    hup_id = row[\"hup_id\"]\n",
    "    dataset_name = row[\"IEEG_Portal_Number\"]\n",
    "    print(dataset_name)\n",
    "\n",
    "    dataset = session.open_dataset(dataset_name)\n",
    "\n",
    "    all_channel_labels = np.array(dataset.get_channel_labels())\n",
    "    channel_labels_to_download = all_channel_labels[\n",
    "        electrode_selection(all_channel_labels)\n",
    "    ]\n",
    "\n",
    "    duration_usec = dataset.get_time_series_details(\n",
    "        channel_labels_to_download[0]\n",
    "    ).duration\n",
    "    duration_hours = int(duration_usec / 1000000 / 60 / 60)\n",
    "    enlarged_duration_hours = duration_hours + 24\n",
    "\n",
    "    print(f\"Opening {dataset_name} with duration {duration_hours} hours\")\n",
    "\n",
    "    # Calculate the total number of 2-minute intervals in the enlarged duration\n",
    "    total_intervals = enlarged_duration_hours * 30  # 60min/hour / 2min = 30\n",
    "\n",
    "    synchrony_broadband_vector_to_save = np.full(total_intervals, np.nan)\n",
    "\n",
    "    # Loop through each 2-minute interval\n",
    "    for interval in range(total_intervals):\n",
    "        print(f\"Getting iEEG data for interval {interval} out of {total_intervals}\")\n",
    "        duration_usec = 1.2e8  # 2 minutes\n",
    "        start_time_usec = interval * 2 * 60 * 1e6  # 2 minutes in microseconds\n",
    "        stop_time_usec = start_time_usec + duration_usec\n",
    "\n",
    "        try:\n",
    "            ieeg_data, fs = get_iEEG_data(\n",
    "                \"aguilac\",\n",
    "                \"agu_ieeglogin.bin\",\n",
    "                dataset_name,\n",
    "                start_time_usec,\n",
    "                stop_time_usec,\n",
    "                channel_labels_to_download,\n",
    "            )\n",
    "            fs = int(fs)\n",
    "        except Exception as e:\n",
    "            # handle the exception\n",
    "            print(f\"Error: {e}\")\n",
    "            break\n",
    "\n",
    "        # Drop rows that has any nan\n",
    "        ieeg_data = ieeg_data.dropna(axis=0, how=\"any\")\n",
    "        if ieeg_data.empty:\n",
    "            print(\"Empty dataframe after dropping nan, skip...\")\n",
    "            continue\n",
    "\n",
    "        good_channels_res = detect_bad_channels_optimized(ieeg_data.to_numpy(), fs)\n",
    "        good_channel_indicies = good_channels_res[0]\n",
    "        good_channel_labels = channel_labels_to_download[good_channel_indicies]\n",
    "        ieeg_data = ieeg_data[good_channel_labels].to_numpy()\n",
    "\n",
    "        # Check if ieeg_data is empty after dropping bad channels\n",
    "        if ieeg_data.size == 0:\n",
    "            print(\"Empty dataframe after dropping bad channels, skip...\")\n",
    "            continue\n",
    "\n",
    "        ieeg_data = common_average_montage(ieeg_data)\n",
    "\n",
    "        # Apply the filters directly on the DataFrame\n",
    "        ieeg_data = notch_filter(ieeg_data, 59, 61, fs)\n",
    "\n",
    "        ##############################\n",
    "        # Calculate synchrony (broadband)\n",
    "        ##############################\n",
    "        _, R = calculate_synchrony(ieeg_data.T)\n",
    "        synchrony_broadband_vector_to_save[interval] = R\n",
    "\n",
    "        print(f\"Finished calculating synchrony for interval {interval}\")\n",
    "\n",
    "    ##############################\n",
    "    # Save the synchrony output\n",
    "    ##############################\n",
    "    np.save(\n",
    "        os.path.join(SYNCHRONY_broadband_DIRECTORY, f\"HUP_{hup_id}.npy\"),\n",
    "        synchrony_broadband_vector_to_save,\n",
    "    )\n",
    "    print(f\"Saved synchrony output for HUP {hup_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter nbconvert --to python redownload_incomplete.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
