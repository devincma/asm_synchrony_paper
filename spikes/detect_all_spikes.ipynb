{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ieeg.auth import Session\n",
    "\n",
    "from get_iEEG_data import *\n",
    "from spike_detector import *\n",
    "from spike_morphology import *\n",
    "from iEEG_helper_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPIKES_OUTPUT_DIR = \"../../Data/spikes/devin_spikes_new/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_hup_ids_for_spike_detector = np.load(\"good_hup_ids_for_spike_detector.npy\")\n",
    "good_hup_ids_for_spike_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_hup_ids_for_spike_detector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load HUP_implant_dates.xlsx\n",
    "nina_patients_df = pd.read_excel(\"../../Data/HUP_implant_dates.xlsx\")\n",
    "# Make the hup_id column integers\n",
    "nina_patients_df[\"hup_id\"] = nina_patients_df[\"hup_id\"].astype(int)\n",
    "nina_patients_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a boolean column in nina_patients_df called is_single_dataset and make it True if IEEG_Portal_Number ends with \"phaseII\"\n",
    "nina_patients_df[\"is_single_dataset\"] = nina_patients_df[\n",
    "    \"IEEG_Portal_Number\"\n",
    "].str.endswith(\"phaseII\")\n",
    "# Add a boolean column in nina_patients_df called is_good_for_spike_detector and make it True if the row's hup_id is in good_hup_ids_for_spike_detector\n",
    "nina_patients_df[\"is_good_for_spike_detector\"] = nina_patients_df[\"hup_id\"].isin(\n",
    "    good_hup_ids_for_spike_detector\n",
    ")\n",
    "nina_patients_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows in nina_patients_df where is_single_dataset is False\n",
    "nina_patients_df = nina_patients_df[nina_patients_df.is_single_dataset == True]\n",
    "# Drop the rows in nina_patients_df where is_good_for_spike_detector is False\n",
    "nina_patients_df = nina_patients_df[nina_patients_df.is_good_for_spike_detector == True]\n",
    "# Sort by hup_id in ascending order\n",
    "nina_patients_df = nina_patients_df.sort_values(by=[\"hup_id\"], ascending=True)\n",
    "# Drop columns Implant_Date, implant_time, Explant_Date, weight_kg\n",
    "nina_patients_df = nina_patients_df.drop(\n",
    "    columns=[\"Implant_Date\", \"implant_time\", \"Explant_Date\", \"weight_kg\"]\n",
    ")\n",
    "# Reset index\n",
    "nina_patients_df = nina_patients_df.reset_index(drop=True)\n",
    "nina_patients_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nina_patients_df[nina_patients_df[\"hup_id\"] % 6 == 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nina_patients_df[nina_patients_df[\"hup_id\"] % 6 == 1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nina_patients_df[nina_patients_df[\"hup_id\"] % 6 == 2].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nina_patients_df[nina_patients_df[\"hup_id\"] % 6 == 3].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nina_patients_df[nina_patients_df[\"hup_id\"] % 6 == 4].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nina_patients_df[nina_patients_df[\"hup_id\"] % 6 == 5].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = nina_patients_df[nina_patients_df[\"hup_id\"] % 6 == 0].reset_index(drop=True)\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Using Carlos session\")\n",
    "with open(\"agu_ieeglogin.bin\", \"r\") as f:\n",
    "    session = Session(\"aguilac\", f.read())\n",
    "\n",
    "# print(\"Using Devin session\")\n",
    "# with open(\"dma_ieeglogin.bin\", \"r\") as f:\n",
    "#     session = Session(\"dma\", f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing HUP 138 with dataset HUP138_phaseII\n",
      "['LA01' 'LA02' 'LA03' 'LA04' 'LA05' 'LA06' 'LA07' 'LA08' 'LB01' 'LB02'\n",
      " 'LB03' 'LB04' 'LB05' 'LB06' 'LB07' 'LB08' 'LC01' 'LC02' 'LC03' 'LC04'\n",
      " 'LC05' 'LC06' 'LC07' 'LC08' 'LD01' 'LD02' 'LD03' 'LD04' 'LD05' 'LD06'\n",
      " 'LD07' 'LD08' 'LE01' 'LE02' 'LE03' 'LE04' 'LE05' 'LE06' 'LE07' 'LE08'\n",
      " 'LF01' 'LF02' 'LF03' 'LF04' 'LF05' 'LF06' 'LF07' 'LF08' 'LF09' 'LF10'\n",
      " 'LF11' 'LF12' 'LG01' 'LG02' 'LG03' 'LG04' 'LG05' 'LG06' 'LG07' 'LG08'\n",
      " 'RA01' 'RA02' 'RA03' 'RA04' 'RA05' 'RA06' 'RA07' 'RA08' 'RB01' 'RB02'\n",
      " 'RB03' 'RB04' 'RB05' 'RB06' 'RB07' 'RB08' 'RC01' 'RC02' 'RC03' 'RC04'\n",
      " 'RC05' 'RC06' 'RC07' 'RC08' 'RE01' 'RE02' 'RE03' 'RE04' 'RE05' 'RE06'\n",
      " 'RE07' 'RE08' 'RF01' 'RF02' 'RF03' 'RF04' 'RF05' 'RF06' 'RF07' 'RF08'\n",
      " 'RF09' 'RF10' 'RF11' 'RF12' 'RG01' 'RG02' 'RG03' 'RG04' 'RG05' 'RG06'\n",
      " 'RG07' 'RG08']\n",
      "Opening HUP138_phaseII with duration 172 hours\n",
      "Getting iEEG data for interval 200 out of 5880\n",
      "['LA01' 'LA02' 'LA03' 'LA04' 'LA05' 'LA06' 'LA07' 'LA08' 'LB01' 'LB02'\n",
      " 'LB03' 'LB04' 'LB05' 'LB06' 'LB07' 'LB08' 'LC01' 'LC02' 'LC03' 'LC04'\n",
      " 'LC05' 'LC06' 'LC07' 'LC08' 'LD01' 'LD02' 'LD03' 'LD04' 'LD05' 'LD06'\n",
      " 'LD07' 'LD08' 'LE01' 'LE02' 'LE03' 'LE04' 'LE05' 'LE06' 'LE07' 'LE08'\n",
      " 'LF01' 'LF02' 'LF03' 'LF04' 'LF05' 'LF06' 'LF07' 'LF08' 'LF09' 'LF10'\n",
      " 'LF11' 'LF12' 'LG01' 'LG02' 'LG03' 'LG04' 'LG05' 'LG06' 'LG07' 'LG08'\n",
      " 'RA01' 'RA02' 'RA03' 'RA04' 'RA05' 'RA06' 'RA07' 'RA08' 'RB01' 'RB02'\n",
      " 'RB03' 'RB04' 'RB05' 'RB06' 'RB07' 'RB08' 'RC01' 'RC02' 'RC03' 'RC04'\n",
      " 'RC05' 'RC06' 'RC07' 'RC08' 'RE01' 'RE02' 'RE03' 'RE04' 'RE05' 'RE06'\n",
      " 'RE07' 'RE08' 'RF01' 'RF02' 'RF03' 'RF04' 'RF05' 'RF06' 'RF07' 'RF08'\n",
      " 'RF09' 'RF10' 'RF11' 'RF12' 'RG01' 'RG02' 'RG03' 'RG04' 'RG05' 'RG06'\n",
      " 'RG07' 'RG08']\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/mnt/leif/littlab/users/devinma/Code/spikes/detect_all_spikes.ipynb Cell 17\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpioneer.seas.upenn.edu/mnt/leif/littlab/users/devinma/Code/spikes/detect_all_spikes.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=63'>64</a>\u001b[0m ieeg_data \u001b[39m=\u001b[39m ieeg_data[good_channel_labels]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpioneer.seas.upenn.edu/mnt/leif/littlab/users/devinma/Code/spikes/detect_all_spikes.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39m# assert that the column labels are the same as good_channel_labels and in the same order\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bpioneer.seas.upenn.edu/mnt/leif/littlab/users/devinma/Code/spikes/detect_all_spikes.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39massert\u001b[39;00m np\u001b[39m.\u001b[39mall(ieeg_data\u001b[39m.\u001b[39mcolumns \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mshuffle(good_channel_labels))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpioneer.seas.upenn.edu/mnt/leif/littlab/users/devinma/Code/spikes/detect_all_spikes.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=66'>67</a>\u001b[0m \u001b[39m# ieeg_data = ieeg_data.to_numpy()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpioneer.seas.upenn.edu/mnt/leif/littlab/users/devinma/Code/spikes/detect_all_spikes.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=67'>68</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpioneer.seas.upenn.edu/mnt/leif/littlab/users/devinma/Code/spikes/detect_all_spikes.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=68'>69</a>\u001b[0m \u001b[39m# # Check if ieeg_data is empty after dropping bad channels\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bpioneer.seas.upenn.edu/mnt/leif/littlab/users/devinma/Code/spikes/detect_all_spikes.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=137'>138</a>\u001b[0m \u001b[39m# # )\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bpioneer.seas.upenn.edu/mnt/leif/littlab/users/devinma/Code/spikes/detect_all_spikes.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=138'>139</a>\u001b[0m \u001b[39m# # print(f\"Saved spike output for interval {interval} for HUP {hup_id}\")\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Iterate through every row in batch\n",
    "for index, row in batch.iterrows():\n",
    "    hup_id = row[\"hup_id\"]\n",
    "    dataset_name = row[\"IEEG_Portal_Number\"]\n",
    "\n",
    "    print(f\"Processing HUP {hup_id} with dataset {dataset_name}\")\n",
    "\n",
    "    dataset = session.open_dataset(dataset_name)\n",
    "\n",
    "    all_channel_labels = np.array(dataset.get_channel_labels())\n",
    "    channel_labels_to_download = all_channel_labels[\n",
    "        electrode_selection(all_channel_labels)\n",
    "    ]\n",
    "\n",
    "    print(channel_labels_to_download)\n",
    "\n",
    "    duration_usec = dataset.get_time_series_details(\n",
    "        channel_labels_to_download[0]\n",
    "    ).duration\n",
    "    duration_hours = int(duration_usec / 1000000 / 60 / 60)\n",
    "    enlarged_duration_hours = duration_hours + 24\n",
    "\n",
    "    print(f\"Opening {dataset_name} with duration {duration_hours} hours\")\n",
    "\n",
    "    # Calculate the total number of 2-minute intervals in the enlarged duration\n",
    "    total_intervals = enlarged_duration_hours * 30  # 60min/hour / 2min = 30\n",
    "\n",
    "    # Loop through each 2-minute interval\n",
    "    for interval in range(200, total_intervals):\n",
    "        print(f\"Getting iEEG data for interval {interval} out of {total_intervals}\")\n",
    "        duration_usec = 1.2e8  # 2 minutes\n",
    "        start_time_usec = interval * 2 * 60 * 1e6  # 2 minutes in microseconds\n",
    "        stop_time_usec = start_time_usec + duration_usec\n",
    "\n",
    "        try:\n",
    "            ieeg_data, fs = get_iEEG_data(\n",
    "                \"aguilac\",\n",
    "                \"agu_ieeglogin.bin\",\n",
    "                dataset_name,\n",
    "                start_time_usec,\n",
    "                stop_time_usec,\n",
    "                channel_labels_to_download,\n",
    "            )\n",
    "            fs = int(fs)\n",
    "        except Exception as e:\n",
    "            # handle the exception\n",
    "            print(f\"Error: {e}\")\n",
    "            break\n",
    "\n",
    "        # Check if ieeg_data dataframe is all NaNs\n",
    "        if ieeg_data.isnull().values.all():\n",
    "            print(\"Empty dataframe after download, skip...\")\n",
    "            continue\n",
    "\n",
    "        good_channels_res = detect_bad_channels_optimized(ieeg_data.to_numpy(), fs)\n",
    "        good_channel_indicies = good_channels_res[0]\n",
    "        good_channel_labels = channel_labels_to_download[good_channel_indicies]\n",
    "\n",
    "        # Assert that all of the good_channel_labels are in channel_labels_to_download\n",
    "        assert np.all(np.isin(good_channel_labels, channel_labels_to_download))\n",
    "\n",
    "        print(good_channel_labels)\n",
    "\n",
    "        ieeg_data = ieeg_data[good_channel_labels]\n",
    "        # assert that the column labels are the same as good_channel_labels and in the same order\n",
    "        assert np.all(ieeg_data.columns == good_channel_labels)\n",
    "        # ieeg_data = ieeg_data.to_numpy()\n",
    "\n",
    "        # # Check if ieeg_data is empty after dropping bad channels\n",
    "        # if ieeg_data.size == 0:\n",
    "        #     print(\"Empty dataframe after artifact rejection, skip...\")\n",
    "        #     continue\n",
    "\n",
    "        # ieeg_data = common_average_montage(ieeg_data)\n",
    "\n",
    "        # # Apply the filters directly on the DataFrame\n",
    "        # ieeg_data = notch_filter(ieeg_data, 59, 61, fs)\n",
    "        # ieeg_data = bandpass_filter(ieeg_data, 1, 70, fs)\n",
    "\n",
    "        # ##############################\n",
    "        # # Detect spikes\n",
    "        # ##############################\n",
    "\n",
    "        # spike_output = spike_detector(\n",
    "        #     data=ieeg_data,\n",
    "        #     fs=fs,\n",
    "        #     electrode_labels=good_channel_labels,\n",
    "        # )\n",
    "        # if len(spike_output) == 0:\n",
    "        #     print(\"No spikes detected, skip saving...\")\n",
    "        #     continue\n",
    "        # else:\n",
    "        #     print(f\"Detected {len(spike_output)} spikes\")\n",
    "\n",
    "        # ##############################\n",
    "        # # Extract spike morphologies\n",
    "        # ##############################\n",
    "        # # Preallocate the result array\n",
    "        # spike_output_to_save = np.empty((spike_output.shape[0], 16), dtype=object)\n",
    "        # spike_output_to_save[:, :] = np.NaN  # Fill with NaNs\n",
    "\n",
    "        # for i, spike in enumerate(spike_output):\n",
    "        #     peak_index = int(spike[0])\n",
    "        #     channel_index = int(spike[1])\n",
    "        #     channel_label = spike[2]\n",
    "\n",
    "        #     # Fill the first two columns with peak_index and channel_index\n",
    "        #     spike_output_to_save[i, 0] = peak_index\n",
    "        #     spike_output_to_save[i, 1] = channel_index\n",
    "        #     spike_output_to_save[i, 2] = channel_label\n",
    "\n",
    "        #     spike_signal = ieeg_data[\n",
    "        #         peak_index - 1000 : peak_index + 1000, channel_index\n",
    "        #     ]\n",
    "\n",
    "        #     try:\n",
    "        #         (\n",
    "        #             basic_features,\n",
    "        #             advanced_features,\n",
    "        #             is_valid,\n",
    "        #             bad_reason,\n",
    "        #         ) = extract_spike_morphology(spike_signal)\n",
    "\n",
    "        #         if is_valid:\n",
    "        #             # Fill the rest of the columns with computed features\n",
    "        #             spike_output_to_save[i, 3:8] = basic_features\n",
    "        #             spike_output_to_save[i, 8:16] = advanced_features\n",
    "        #     except Exception as e:\n",
    "        #         print(f\"Error extracting spike features: {e}\")\n",
    "        #         continue\n",
    "\n",
    "        # # ##############################\n",
    "        # # # Save the spike output\n",
    "        # # ##############################\n",
    "        # # np.save(\n",
    "        # #     os.path.join(SPIKES_OUTPUT_DIR, f\"{dataset_name}_{interval}.npy\"),\n",
    "        # #     spike_output_to_save,\n",
    "        # # )\n",
    "        # # print(f\"Saved spike output for interval {interval} for HUP {hup_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
