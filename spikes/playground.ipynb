{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground for Interictal Spike Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf __pycache__\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from ieeg.auth import Session\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.signal import butter, filtfilt, iirnotch\n",
    "\n",
    "from get_iEEG_data import *\n",
    "from spike_detector import *\n",
    "from iEEG_helper_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- -- IEEG password file saved -- --\n"
     ]
    }
   ],
   "source": [
    "def create_pwd_file(username, password, fname=None):\n",
    "    if fname is None:\n",
    "        fname = \"{}_ieeglogin.bin\".format(username[:3])\n",
    "    with open(fname, \"wb\") as f:\n",
    "        f.write(password.encode())\n",
    "    print(\"-- -- IEEG password file saved -- --\")\n",
    "\n",
    "\n",
    "create_pwd_file(\"dma\", \"mycqEv-pevfo4-roqfan\")\n",
    "\n",
    "with open(\"dma_ieeglogin.bin\", \"r\") as f:\n",
    "    s = Session(\"dma\", f.read())\n",
    "\n",
    "ds = s.open_dataset(\"HUP210_phaseII\")\n",
    "all_channel_labels = np.array(ds.get_channel_labels())\n",
    "label_idxs = electrode_selection(all_channel_labels)\n",
    "labels = all_channel_labels[label_idxs]\n",
    "\n",
    "ieeg_data, fs = get_iEEG_data(\n",
    "    \"dma\",\n",
    "    \"dma_ieeglogin.bin\",\n",
    "    \"HUP210_phaseII\",\n",
    "    (179677 + (72600 / 1024)) * 1e6,\n",
    "    (179677 + (72600 / 1024) + 60) * 1e6,\n",
    "    labels,\n",
    ")\n",
    "\n",
    "fs = int(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.507928</td>\n",
       "      <td>2.125174</td>\n",
       "      <td>8.540212</td>\n",
       "      <td>0.357006</td>\n",
       "      <td>-4.551463</td>\n",
       "      <td>-17.110671</td>\n",
       "      <td>-15.294157</td>\n",
       "      <td>-75.082156</td>\n",
       "      <td>-75.407262</td>\n",
       "      <td>-30.703291</td>\n",
       "      <td>...</td>\n",
       "      <td>6.578267</td>\n",
       "      <td>5.322186</td>\n",
       "      <td>4.252136</td>\n",
       "      <td>2.192042</td>\n",
       "      <td>-7.168558</td>\n",
       "      <td>-26.368686</td>\n",
       "      <td>-64.437617</td>\n",
       "      <td>-85.056307</td>\n",
       "      <td>-54.985452</td>\n",
       "      <td>-4.403216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.963548</td>\n",
       "      <td>4.301169</td>\n",
       "      <td>10.330361</td>\n",
       "      <td>1.503340</td>\n",
       "      <td>-3.682178</td>\n",
       "      <td>-15.489678</td>\n",
       "      <td>-15.263365</td>\n",
       "      <td>-77.764374</td>\n",
       "      <td>-76.767731</td>\n",
       "      <td>-31.167498</td>\n",
       "      <td>...</td>\n",
       "      <td>7.001846</td>\n",
       "      <td>5.936817</td>\n",
       "      <td>4.790761</td>\n",
       "      <td>2.319565</td>\n",
       "      <td>-6.585044</td>\n",
       "      <td>-25.207571</td>\n",
       "      <td>-64.402307</td>\n",
       "      <td>-87.344945</td>\n",
       "      <td>-57.820404</td>\n",
       "      <td>-7.098123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.321397</td>\n",
       "      <td>6.500112</td>\n",
       "      <td>12.129850</td>\n",
       "      <td>2.689941</td>\n",
       "      <td>-2.773226</td>\n",
       "      <td>-13.861167</td>\n",
       "      <td>-15.234097</td>\n",
       "      <td>-80.364181</td>\n",
       "      <td>-78.048396</td>\n",
       "      <td>-31.563032</td>\n",
       "      <td>...</td>\n",
       "      <td>7.373700</td>\n",
       "      <td>6.475069</td>\n",
       "      <td>5.277968</td>\n",
       "      <td>2.423922</td>\n",
       "      <td>-6.028722</td>\n",
       "      <td>-24.112919</td>\n",
       "      <td>-64.411549</td>\n",
       "      <td>-89.644190</td>\n",
       "      <td>-60.642614</td>\n",
       "      <td>-9.461599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.504992</td>\n",
       "      <td>8.747131</td>\n",
       "      <td>13.955796</td>\n",
       "      <td>3.954757</td>\n",
       "      <td>-1.783153</td>\n",
       "      <td>-12.209362</td>\n",
       "      <td>-15.203165</td>\n",
       "      <td>-82.801981</td>\n",
       "      <td>-79.172064</td>\n",
       "      <td>-31.829357</td>\n",
       "      <td>...</td>\n",
       "      <td>7.645019</td>\n",
       "      <td>6.868037</td>\n",
       "      <td>5.662821</td>\n",
       "      <td>2.480735</td>\n",
       "      <td>-5.526403</td>\n",
       "      <td>-23.139549</td>\n",
       "      <td>-64.495517</td>\n",
       "      <td>-91.952975</td>\n",
       "      <td>-63.436568</td>\n",
       "      <td>-11.226597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.461515</td>\n",
       "      <td>11.058034</td>\n",
       "      <td>15.830545</td>\n",
       "      <td>5.326356</td>\n",
       "      <td>-0.674855</td>\n",
       "      <td>-10.512439</td>\n",
       "      <td>-15.165433</td>\n",
       "      <td>-85.014694</td>\n",
       "      <td>-80.079047</td>\n",
       "      <td>-31.926122</td>\n",
       "      <td>...</td>\n",
       "      <td>7.776745</td>\n",
       "      <td>7.064336</td>\n",
       "      <td>5.900559</td>\n",
       "      <td>2.467215</td>\n",
       "      <td>-5.103763</td>\n",
       "      <td>-22.328453</td>\n",
       "      <td>-64.674011</td>\n",
       "      <td>-94.265431</td>\n",
       "      <td>-66.189038</td>\n",
       "      <td>-12.228998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61435</th>\n",
       "      <td>23.432388</td>\n",
       "      <td>8.458657</td>\n",
       "      <td>5.793279</td>\n",
       "      <td>11.920832</td>\n",
       "      <td>10.546166</td>\n",
       "      <td>3.854880</td>\n",
       "      <td>-20.265253</td>\n",
       "      <td>-30.479836</td>\n",
       "      <td>-43.780163</td>\n",
       "      <td>-34.553647</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.145399</td>\n",
       "      <td>-6.779017</td>\n",
       "      <td>-14.032431</td>\n",
       "      <td>-27.248361</td>\n",
       "      <td>-41.809307</td>\n",
       "      <td>-76.203978</td>\n",
       "      <td>-86.607226</td>\n",
       "      <td>-58.634684</td>\n",
       "      <td>-17.750950</td>\n",
       "      <td>18.026751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61436</th>\n",
       "      <td>21.593321</td>\n",
       "      <td>7.493015</td>\n",
       "      <td>4.701843</td>\n",
       "      <td>10.709001</td>\n",
       "      <td>9.761437</td>\n",
       "      <td>3.889029</td>\n",
       "      <td>-19.303377</td>\n",
       "      <td>-29.105274</td>\n",
       "      <td>-41.542769</td>\n",
       "      <td>-32.141293</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.418810</td>\n",
       "      <td>-6.571751</td>\n",
       "      <td>-13.820478</td>\n",
       "      <td>-26.396635</td>\n",
       "      <td>-40.424244</td>\n",
       "      <td>-73.114258</td>\n",
       "      <td>-81.062226</td>\n",
       "      <td>-54.028594</td>\n",
       "      <td>-15.561067</td>\n",
       "      <td>17.126227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61437</th>\n",
       "      <td>19.603638</td>\n",
       "      <td>6.573561</td>\n",
       "      <td>3.601326</td>\n",
       "      <td>9.488630</td>\n",
       "      <td>8.985855</td>\n",
       "      <td>3.965517</td>\n",
       "      <td>-18.385736</td>\n",
       "      <td>-27.856705</td>\n",
       "      <td>-39.543270</td>\n",
       "      <td>-29.851616</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.643307</td>\n",
       "      <td>-6.299833</td>\n",
       "      <td>-13.592476</td>\n",
       "      <td>-25.556373</td>\n",
       "      <td>-39.242612</td>\n",
       "      <td>-70.460163</td>\n",
       "      <td>-75.735613</td>\n",
       "      <td>-49.457882</td>\n",
       "      <td>-13.522115</td>\n",
       "      <td>15.012783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61438</th>\n",
       "      <td>17.515713</td>\n",
       "      <td>5.710749</td>\n",
       "      <td>2.502656</td>\n",
       "      <td>8.268827</td>\n",
       "      <td>8.220314</td>\n",
       "      <td>4.072075</td>\n",
       "      <td>-17.505036</td>\n",
       "      <td>-26.709120</td>\n",
       "      <td>-37.733481</td>\n",
       "      <td>-27.666732</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.824955</td>\n",
       "      <td>-5.975142</td>\n",
       "      <td>-13.343379</td>\n",
       "      <td>-24.713700</td>\n",
       "      <td>-38.207230</td>\n",
       "      <td>-68.125448</td>\n",
       "      <td>-70.577384</td>\n",
       "      <td>-44.924582</td>\n",
       "      <td>-11.617095</td>\n",
       "      <td>11.994490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61439</th>\n",
       "      <td>15.380117</td>\n",
       "      <td>4.884357</td>\n",
       "      <td>1.403388</td>\n",
       "      <td>7.046877</td>\n",
       "      <td>7.457207</td>\n",
       "      <td>4.190257</td>\n",
       "      <td>-16.652627</td>\n",
       "      <td>-25.628105</td>\n",
       "      <td>-36.040807</td>\n",
       "      <td>-25.548489</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.981697</td>\n",
       "      <td>-5.621727</td>\n",
       "      <td>-13.082367</td>\n",
       "      <td>-23.869593</td>\n",
       "      <td>-37.253158</td>\n",
       "      <td>-65.965286</td>\n",
       "      <td>-65.512376</td>\n",
       "      <td>-40.410816</td>\n",
       "      <td>-9.787045</td>\n",
       "      <td>8.517162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61440 rows × 190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1          2          3          4          5    \\\n",
       "0       7.507928   2.125174   8.540212   0.357006  -4.551463 -17.110671   \n",
       "1      10.963548   4.301169  10.330361   1.503340  -3.682178 -15.489678   \n",
       "2      14.321397   6.500112  12.129850   2.689941  -2.773226 -13.861167   \n",
       "3      17.504992   8.747131  13.955796   3.954757  -1.783153 -12.209362   \n",
       "4      20.461515  11.058034  15.830545   5.326356  -0.674855 -10.512439   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "61435  23.432388   8.458657   5.793279  11.920832  10.546166   3.854880   \n",
       "61436  21.593321   7.493015   4.701843  10.709001   9.761437   3.889029   \n",
       "61437  19.603638   6.573561   3.601326   9.488630   8.985855   3.965517   \n",
       "61438  17.515713   5.710749   2.502656   8.268827   8.220314   4.072075   \n",
       "61439  15.380117   4.884357   1.403388   7.046877   7.457207   4.190257   \n",
       "\n",
       "             6          7          8          9    ...       180       181  \\\n",
       "0     -15.294157 -75.082156 -75.407262 -30.703291  ...  6.578267  5.322186   \n",
       "1     -15.263365 -77.764374 -76.767731 -31.167498  ...  7.001846  5.936817   \n",
       "2     -15.234097 -80.364181 -78.048396 -31.563032  ...  7.373700  6.475069   \n",
       "3     -15.203165 -82.801981 -79.172064 -31.829357  ...  7.645019  6.868037   \n",
       "4     -15.165433 -85.014694 -80.079047 -31.926122  ...  7.776745  7.064336   \n",
       "...          ...        ...        ...        ...  ...       ...       ...   \n",
       "61435 -20.265253 -30.479836 -43.780163 -34.553647  ... -1.145399 -6.779017   \n",
       "61436 -19.303377 -29.105274 -41.542769 -32.141293  ... -1.418810 -6.571751   \n",
       "61437 -18.385736 -27.856705 -39.543270 -29.851616  ... -1.643307 -6.299833   \n",
       "61438 -17.505036 -26.709120 -37.733481 -27.666732  ... -1.824955 -5.975142   \n",
       "61439 -16.652627 -25.628105 -36.040807 -25.548489  ... -1.981697 -5.621727   \n",
       "\n",
       "             182        183        184        185        186        187  \\\n",
       "0       4.252136   2.192042  -7.168558 -26.368686 -64.437617 -85.056307   \n",
       "1       4.790761   2.319565  -6.585044 -25.207571 -64.402307 -87.344945   \n",
       "2       5.277968   2.423922  -6.028722 -24.112919 -64.411549 -89.644190   \n",
       "3       5.662821   2.480735  -5.526403 -23.139549 -64.495517 -91.952975   \n",
       "4       5.900559   2.467215  -5.103763 -22.328453 -64.674011 -94.265431   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "61435 -14.032431 -27.248361 -41.809307 -76.203978 -86.607226 -58.634684   \n",
       "61436 -13.820478 -26.396635 -40.424244 -73.114258 -81.062226 -54.028594   \n",
       "61437 -13.592476 -25.556373 -39.242612 -70.460163 -75.735613 -49.457882   \n",
       "61438 -13.343379 -24.713700 -38.207230 -68.125448 -70.577384 -44.924582   \n",
       "61439 -13.082367 -23.869593 -37.253158 -65.965286 -65.512376 -40.410816   \n",
       "\n",
       "             188        189  \n",
       "0     -54.985452  -4.403216  \n",
       "1     -57.820404  -7.098123  \n",
       "2     -60.642614  -9.461599  \n",
       "3     -63.436568 -11.226597  \n",
       "4     -66.189038 -12.228998  \n",
       "...          ...        ...  \n",
       "61435 -17.750950  18.026751  \n",
       "61436 -15.561067  17.126227  \n",
       "61437 -13.522115  15.012783  \n",
       "61438 -11.617095  11.994490  \n",
       "61439  -9.787045   8.517162  \n",
       "\n",
       "[61440 rows x 190 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_channels_res = detect_bad_channels_optimized(ieeg_data.to_numpy(), fs)\n",
    "good_channel_indicies = good_channels_res[0]\n",
    "good_labels = labels[good_channel_indicies]\n",
    "ieeg_data = ieeg_data[good_labels]\n",
    "\n",
    "ieeg_data = common_average_montage(ieeg_data)\n",
    "\n",
    "\n",
    "def notch_filter(data, low_cut, high_cut, fs, order=4):\n",
    "    nyq = 0.5 * fs\n",
    "    low = low_cut / nyq\n",
    "    high = high_cut / nyq\n",
    "    b, a = iirnotch(w0=(low + high) / 2, Q=30, fs=fs)\n",
    "    y = filtfilt(b, a, data, axis=0)\n",
    "    return y\n",
    "\n",
    "\n",
    "def bandpass_filter(data, lowcut, highcut, fs, order=4):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype=\"band\")\n",
    "    y = filtfilt(b, a, data, axis=0)\n",
    "    return y\n",
    "\n",
    "\n",
    "# Apply the filters directly on the DataFrame\n",
    "ieeg_data = pd.DataFrame(notch_filter(ieeg_data.values, 59, 61, fs))\n",
    "ieeg_data = pd.DataFrame(bandpass_filter(ieeg_data.values, 1, 70, fs))\n",
    "\n",
    "ieeg_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erin's Spike Detector - Alfredo's Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will try to reproduce the spike detectors proposed here: https://www.sciencedirect.com/science/article/pii/S1388245707001666?via%3Dihub, which are the ones that Erin currently uses\n",
    "\n",
    "Actually, Erin's code can be accessed here: https://github.com/erinconrad/FC_toolbox/blob/main/spike_detector/clean_detector.m\n",
    "so it is just a matter of translating this matlab code into a Python code\n",
    "\n",
    "Detector based off of Erin's code - there are 3 functions that are needed for this to run: 1. function for filtering the ieeg data (`eegfilt`), 2. function for finding peaks (`findpeaks`), 3. function for ensuring that spikes are detected in more than one channel (`multi_channel_requirements`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`findpeaks` function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findpeaks(s):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        s: timeseries signal\n",
    "    Outputs:\n",
    "        p: location in the signal with an increasing signal (positive slope)\n",
    "        t: location in the signal with a decreasing signal (negative slope)\n",
    "    \"\"\"\n",
    "    ds = np.diff(s)\n",
    "    ds = np.hstack((ds[0], ds))  # pad diff\n",
    "    filt = np.where(ds[1:] == 0)[0] + 1  # find zeros\n",
    "    ds[filt] = ds[filt - 1]  # replace zeros\n",
    "    ds = np.sign(ds)\n",
    "    # compute the second derivative -  inflection points\n",
    "    ds = np.diff(ds)\n",
    "    t = np.where(ds > 0)[0]\n",
    "    p = np.where(ds < 0)[0]\n",
    "    return p, t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`eegfilt` function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eegfilt(x, fc, typ, fs):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        x: timeseries signal\n",
    "        fc: cutoff frequency\n",
    "        typ: type of filtering (lp - lowpass, hp - highpass)\n",
    "        fs: sampling rate of x\n",
    "    Outputs:\n",
    "        p: location in the signal with an increasing signal (positive slope)\n",
    "        t: location in the signal with a decreasing signal (negative slope)\n",
    "    \"\"\"\n",
    "    # filter eeg data using Butterworth filter\n",
    "    # out = eegfilt(data,cutfreq,typ);\n",
    "    # out = eegfilt(data,70,'hp'); high pass with 70Hz cutoff\n",
    "\n",
    "    # EEG_BUTTER - Butterworth filter implementation\n",
    "    # xf = eeg_butter(x,sampl_freq,cutoff_freq,filter_type,num_poles)\n",
    "\n",
    "    np = 6  # order of the butterworth filter\n",
    "\n",
    "    if np.sum(fc >= fs / 2):\n",
    "        raise ValueError(\"Cutoff frequency must be < one half the sampling rate\")\n",
    "\n",
    "    fn = fs / 2\n",
    "\n",
    "    if typ == \"bp\":\n",
    "        typ = \"lp\"\n",
    "\n",
    "    if typ == \"lp\":\n",
    "        B, A = butter(np, fc / fn)\n",
    "    elif typ == \"hp\":\n",
    "        B, A = butter(np, fc / fn, \"high\")\n",
    "    elif typ == \"st\":\n",
    "        B, A = butter(np, fc / fn, \"stop\")\n",
    "\n",
    "    out = filtfilt(B, A, x)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`multichannel_requirements` function that makes sure that the spikes occur in 2 or more channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multichannel_requirements(gdf, nchs, fs):\n",
    "    # Parameters\n",
    "    min_chs = 2  # spike should be on at least 2 channels\n",
    "    max_chs = int(nchs * 0.5)  # on no more than half the channels\n",
    "    min_time = int(100 * 1e-3 * fs)  # 100 ms to look for other spikes\n",
    "\n",
    "    final_spikes = []\n",
    "\n",
    "    s = 0\n",
    "    curr_seq = [s]\n",
    "    last_time = gdf[s, 1]\n",
    "\n",
    "    while s < gdf.shape[0] - 1:\n",
    "        # move to next spike time\n",
    "        new_time = gdf[s + 1, 1]\n",
    "\n",
    "        # if it's within the time diff\n",
    "        if new_time - last_time < min_time:\n",
    "            curr_seq.append(s + 1)  # append it to the current sequence\n",
    "\n",
    "            if s == gdf.shape[0] - 2:\n",
    "                # done with sequence, check if the number of involved chs is appropriate\n",
    "                l = len(np.unique(gdf[curr_seq, 0]))\n",
    "                if min_chs <= l <= max_chs:\n",
    "                    final_spikes.append(\n",
    "                        np.hstack(\n",
    "                            (\n",
    "                                gdf[curr_seq, :],\n",
    "                                (gdf[curr_seq, 1] - np.min(gdf[curr_seq, 1]))[\n",
    "                                    :, np.newaxis\n",
    "                                ],\n",
    "                            )\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "        else:\n",
    "            # done with sequence, check if the length of sequence is appropriate\n",
    "            l = len(np.unique(gdf[curr_seq, 0]))\n",
    "            if min_chs <= l <= max_chs:\n",
    "                final_spikes.append(\n",
    "                    np.hstack(\n",
    "                        (\n",
    "                            gdf[curr_seq, :],\n",
    "                            (gdf[curr_seq, 1] - np.min(gdf[curr_seq, 1]))[\n",
    "                                :, np.newaxis\n",
    "                            ],\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            # reset sequence\n",
    "            curr_seq = [s + 1]\n",
    "\n",
    "        # increase the last time\n",
    "        last_time = gdf[s + 1, 1]\n",
    "\n",
    "        # increase the current spike\n",
    "        s += 1\n",
    "    if len(final_spikes) > 0:\n",
    "        multichannel_spikes = np.vstack(final_spikes)\n",
    "    else:\n",
    "        print(\"No spikes meet the criteria...\")\n",
    "        multichannel_spikes = []\n",
    "    return multichannel_spikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actual Spike Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_detector(\n",
    "    eeg_df,\n",
    "    fs,\n",
    "    remove_channels=[\n",
    "        \"EEG EKG 02-Ref\",\n",
    "        \"ECG1\",\n",
    "        \"EEG EKG1-Ref\",\n",
    "        \"EKG2\",\n",
    "        \"EKG\",\n",
    "        \"EKG1\",\n",
    "        \"EKG02\",\n",
    "        \"EEG EKG2-Ref\",\n",
    "        \"EEG EKG 01-Ref\",\n",
    "        \"EEG EKG-Ref\",\n",
    "        \"ECG2\",\n",
    "        \"EKG01\",\n",
    "    ],\n",
    "):\n",
    "    # extract the data from the dataframe\n",
    "    eeg = eeg_df.values\n",
    "\n",
    "    ## Parameters\n",
    "    tmul = 19  # minimum relative amplitude (compared to baseline)\n",
    "    absthresh = 100  # minimum absolute amplitude (uV)\n",
    "    sur_time = (\n",
    "        0.5  # surround time (in s) against which to compare for relative amplitude\n",
    "    )\n",
    "    close_to_edge = 0.05  # time (in s) surrounding start and end of sample to ignore\n",
    "    too_high_abs = 1e3  # amplitude above which I reject it as artifact\n",
    "    spkdur = [15, 200]  # spike duration must be within this range (in ms)\n",
    "    spkdur = np.array(spkdur) * fs // 1000  # convert above to samples\n",
    "    lpf1 = 30  # low pass filter for artifact component\n",
    "    hpf = 7  # high pass filter for spikey component\n",
    "\n",
    "    ## Initialize things\n",
    "    all_spikes = np.empty((0, 4))\n",
    "    nchs = eeg.shape[1]\n",
    "    ch_names = list(eeg_df.columns)\n",
    "\n",
    "    ## Iterate channels and detect spikes\n",
    "    print(\"Detecting spikes through channels\")\n",
    "    for j in range(nchs):\n",
    "        if ch_names[j] not in remove_channels:\n",
    "            # initialize out array with final spike info\n",
    "            out = np.empty((0, 3))\n",
    "\n",
    "            # extract channel data\n",
    "            data = eeg[:, j]\n",
    "\n",
    "            # Skip if all nans\n",
    "            if np.sum(np.isnan(data)) > 0:\n",
    "                continue\n",
    "\n",
    "            # re-adjust the mean of the data to be zero\n",
    "            data = data - np.nanmean(data)\n",
    "\n",
    "            # initialize array with tentative spike info\n",
    "            spikes = []\n",
    "\n",
    "            # Low pass filter to remove artifact\n",
    "            b, a = butter(4, lpf1 / (fs / 2), btype=\"lowpass\")\n",
    "            lpdata = filtfilt(b, a, data)  # low pass filter\n",
    "\n",
    "            # high pass filter to get the spikey part\n",
    "            b, a = butter(4, hpf / (fs / 2), btype=\"highpass\")\n",
    "            hpdata = filtfilt(b, a, lpdata)  # high pass filter\n",
    "\n",
    "            # establish the baseline for the relative amplitude threshold\n",
    "            lthresh = np.median(np.abs(hpdata))\n",
    "            thresh = lthresh * tmul  # this is the final threshold we want to impose\n",
    "\n",
    "            # Run the spike detector to find both negative and positive spikes\n",
    "            for k in range(2):\n",
    "                if k == 1:\n",
    "                    kdata = -hpdata  # flip the sign of the data to find positive spikes\n",
    "                else:\n",
    "                    kdata = hpdata\n",
    "\n",
    "                # find peaks (spp) and troughs (spv) in the data\n",
    "                spp, spv = findpeaks(kdata)\n",
    "\n",
    "                # find peak-to-peak durations within allowable range\n",
    "                idx = np.where(np.diff(spp) <= spkdur[1])[0]\n",
    "\n",
    "                # peak before list\n",
    "                startdx = spp[idx]\n",
    "\n",
    "                # peak after list\n",
    "                startdx1 = spp[idx + 1]\n",
    "\n",
    "                # Loop over peaks\n",
    "                for i in range(len(startdx)):\n",
    "                    # find the valley that is between the two peaks\n",
    "                    spkvalley = spv[np.where((spv > startdx[i]) & (spv < startdx1[i]))]\n",
    "\n",
    "                    # If the height from valley to either peak is big enough, it could be a spike\n",
    "                    max_height = max(\n",
    "                        abs(kdata[startdx1[i]] - kdata[spkvalley]),\n",
    "                        abs(kdata[startdx[i]] - kdata[spkvalley]),\n",
    "                    )\n",
    "                    if (\n",
    "                        max_height > thresh\n",
    "                    ):  # if amplitude from peak to valley is large enough, append as a spike\n",
    "                        # add the location of the spike valley, the duration of spike from peak 1 to peak 2 and the amplitude from peak to valley\n",
    "                        spikes.append(\n",
    "                            [spkvalley[0], startdx1[i] - startdx[i], max_height]\n",
    "                        )\n",
    "\n",
    "            if len(spikes) > 0:\n",
    "                # Add channel number and convert spike time to samples\n",
    "                spikes = [[a, b, c[0]] for a, b, c in spikes]\n",
    "                spikes = np.array(spikes)\n",
    "                # print\n",
    "                # spikes[:, -1] = list(map(lambda x: x[0], spikes[:, -1]))\n",
    "                spikes = spikes.astype(float)\n",
    "\n",
    "                # check different properties for each of the detected spikes to make sure that they are truly spikes\n",
    "                # make sure they are not too small in amplitude (noise), too sharp/short in time (noise), or too large (artifact)\n",
    "                toosmall = []\n",
    "                toosharp = []\n",
    "                toobig = []\n",
    "\n",
    "                # for each spike - spikes is a n_spikes by properties array\n",
    "                for i in range(spikes.shape[0]):\n",
    "                    # re-define baseline to be period surrounding spike\n",
    "                    istart = int(\n",
    "                        max(1, round(spikes[i, 0] - sur_time * fs))\n",
    "                    )  # starting time for the surrounding timepoints is either 1 (if spike is at timepoint 0), or at the surrounding timepoint\n",
    "                    iend = int(\n",
    "                        min(len(hpdata), round(spikes[i, 0] + sur_time * fs))\n",
    "                    )  # same but for ending time. It accounts for the spike being in the last timepoint\n",
    "\n",
    "                    # define a regional local threshold within the specified time range\n",
    "                    alt_thresh = np.median(np.abs(hpdata[istart:iend])) * tmul\n",
    "\n",
    "                    if (\n",
    "                        spikes[i, 2] > alt_thresh and spikes[i, 2] > absthresh\n",
    "                    ):  # both parts together are bigger than thresh: so have some flexibility in relative sizes\n",
    "                        if (\n",
    "                            spikes[i, 1] * 1000 / fs > spkdur[0]\n",
    "                        ):  # spike wave cannot be too sharp: then it is either too small or noise\n",
    "                            if spikes[i, 2] < too_high_abs:\n",
    "                                out = np.vstack(\n",
    "                                    (out, spikes[i, :])\n",
    "                                )  # add info of spike to output list\n",
    "                            else:\n",
    "                                toobig.append(spikes[i, 0])\n",
    "                        else:\n",
    "                            toosharp.append(spikes[i, 0])\n",
    "                    else:\n",
    "                        toosmall.append(spikes[i, 0])\n",
    "\n",
    "                if out.shape[0] > 0:\n",
    "                    # Re-align spikes to peak of the spikey component\n",
    "                    timeToPeak = [\n",
    "                        -0.15,\n",
    "                        0.15,\n",
    "                    ]  # Only look 150 ms before and after the currently defined peak\n",
    "                    fullSurround = [-sur_time, sur_time] * fs\n",
    "                    idxToPeak = (np.array(timeToPeak) * fs).astype(int)\n",
    "\n",
    "                    for i in range(out.shape[0]):\n",
    "                        currIdx = out[i, 0]\n",
    "                        surround_idx = np.arange(\n",
    "                            max(1, round(currIdx + fullSurround[0])),\n",
    "                            min(round(currIdx + fullSurround[1]), len(hpdata)),\n",
    "                        ).astype(int)\n",
    "                        idxToLook = np.arange(\n",
    "                            max(1, round(currIdx + idxToPeak[0])),\n",
    "                            min(round(currIdx + idxToPeak[1]), len(hpdata)),\n",
    "                        ).astype(int)\n",
    "                        snapshot = data[idxToLook] - np.median(data[surround_idx])\n",
    "                        # Look at the high frequency data (where the mean is subtracted already)\n",
    "                        I = np.argmax(np.abs(snapshot))\n",
    "                        # The peak is the maximum absolute value of this\n",
    "                        out[i, 0] = idxToLook[0] + I - 1\n",
    "\n",
    "                    all_spikes = np.vstack(\n",
    "                        (all_spikes, np.hstack((np.full((out.shape[0], 1), j), out)))\n",
    "                    )\n",
    "\n",
    "    # convert the last column to a list of numbers instead of a list of arrays\n",
    "    # output the numpy array with the spikes\n",
    "    gdf = all_spikes\n",
    "    gdf = np.unique(gdf, axis=0)\n",
    "\n",
    "    # sort by times and put ch first\n",
    "    if gdf.size > 0:\n",
    "        gdf = gdf[gdf[:, 1].argsort(), :]  # sort by time\n",
    "\n",
    "        \"\"\"\n",
    "        times = gdf[:,0]\n",
    "        chs = gdf[:,1]\n",
    "        I = np.argsort(times)\n",
    "        chs = chs[I]\n",
    "        times = times[I]\n",
    "        gdf = np.vstack((chs, times)).T\n",
    "        \"\"\"\n",
    "    # Remove those at beginning and end\n",
    "    if gdf.size > 0:\n",
    "        close_idx = int(close_to_edge * fs)\n",
    "        gdf = gdf[gdf[:, 1] >= close_idx]\n",
    "        gdf = gdf[gdf[:, 1] <= eeg.shape[0] - close_idx]\n",
    "\n",
    "    # remove duplicates\n",
    "    if gdf.size > 0:\n",
    "        keep = np.ones(gdf.shape[0], dtype=bool)\n",
    "\n",
    "        # take diff of times\n",
    "        diff_times = np.hstack((np.inf, np.diff(gdf[:, 1])))\n",
    "\n",
    "        # take diff of chs\n",
    "        diff_chs = np.hstack((np.inf, np.diff(gdf[:, 0])))\n",
    "\n",
    "        # find those that are close in time and the same ch\n",
    "        too_close = np.logical_and(abs(diff_times) < 100e-3 * fs, diff_chs == 0)\n",
    "\n",
    "        keep[too_close] = 0\n",
    "        keep = np.array(keep)\n",
    "\n",
    "        n_removed = np.sum(~keep)\n",
    "        gdf = gdf[keep]\n",
    "\n",
    "    # execute the multichannel requirements\n",
    "    gdf = multichannel_requirements(gdf, nchs, fs)\n",
    "\n",
    "    if len(gdf) > 0:\n",
    "        # convert gdf into a pandas dataframe\n",
    "        df_spikes = pd.DataFrame()\n",
    "        df_spikes[\"Channel Number\"] = gdf[:, 0].astype(int)\n",
    "        df_spikes[\"Channel Name\"] = list(\n",
    "            map(lambda x: ch_names[x], gdf[:, 0].astype(int))\n",
    "        )\n",
    "        df_spikes[\"Spike Location\"] = gdf[:, 1].astype(int)\n",
    "        df_spikes[\"Spike Duration\"] = gdf[:, 2].astype(int)\n",
    "        df_spikes[\"Spike Amplitude\"] = gdf[:, 3]\n",
    "    else:\n",
    "        df_spikes = pd.DataFrame(\n",
    "            columns=[\n",
    "                \"Channel Number\",\n",
    "                \"Channel Name\",\n",
    "                \"Spike Location\",\n",
    "                \"Spike Duration\",\n",
    "                \"Spike Amplitude\",\n",
    "            ]\n",
    "        )\n",
    "    return df_spikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for plotting the spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spikes(ieeg_data, spike_df):\n",
    "    channels_with_spikes = list(set(spike_df[\"Channel Number\"].values))\n",
    "\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    for i, ch in enumerate(channels_with_spikes):\n",
    "        plt.subplot(len(channels_with_spikes), 1, i + 1)\n",
    "        plt.plot(ieeg_data.values[:, ch])\n",
    "        sns.despine(top=True, right=True, left=True, bottom=True)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "\n",
    "        spike_locations = spike_df[spike_df[\"Channel Number\"] == ch][\n",
    "            \"Spike Location\"\n",
    "        ].values\n",
    "        spike_amplitudes = spike_df[spike_df[\"Channel Number\"] == ch][\n",
    "            \"Spike Amplitude\"\n",
    "        ].values\n",
    "        for j, (location, amplitude) in enumerate(\n",
    "            zip(spike_locations, spike_amplitudes)\n",
    "        ):\n",
    "            plt.plot(\n",
    "                location, ieeg_data.values[location, ch], \".\", markersize=10, color=\"r\"\n",
    "            )\n",
    "        channel_name = spike_df[spike_df[\"Channel Number\"] == ch][\n",
    "            \"Channel Name\"\n",
    "        ].values[0]\n",
    "        plt.ylabel(channel_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the Spike Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_bad_channels(values, channel_indices, channel_labels, fs):\n",
    "    \"\"\"\n",
    "    Identifies 'bad' channels in an EEG dataset based on various criteria such as high variance, missing data,\n",
    "    crossing absolute threshold, high variance above baseline, and 60 Hz noise.\n",
    "\n",
    "    Parameters:\n",
    "    values (numpy.ndarray): A 2D array of EEG data where each column is a different channel and each row is a reading.\n",
    "    channel_indices (list): A list containing indices of channels to be analyzed.\n",
    "    channel_labels (list): A list of channel labels.\n",
    "    fs (float): The sampling frequency.\n",
    "\n",
    "    Returns:\n",
    "    bad (list): A list of 'bad' channel indices.\n",
    "    details (dict): A dictionary containing the reasons why each channel was marked as 'bad'. Keys are 'noisy', 'nans',\n",
    "                    'zeros', 'var', 'higher_std', and 'high_voltage'. Each key maps to a list of channel indices.\n",
    "    \"\"\"\n",
    "\n",
    "    # set parameters\n",
    "    tile = 99\n",
    "    mult = 10\n",
    "    num_above = 1\n",
    "    abs_thresh = 5e3\n",
    "    percent_60_hz = 0.99\n",
    "    mult_std = 10\n",
    "\n",
    "    bad = []\n",
    "    high_ch = []\n",
    "    nan_ch = []\n",
    "    zero_ch = []\n",
    "    high_var_ch = []\n",
    "    noisy_ch = []\n",
    "    all_std = np.full(len(channel_indices), np.nan)\n",
    "\n",
    "    for i in range(len(channel_indices)):\n",
    "        bad_ch = 0\n",
    "        ich = channel_indices[i]\n",
    "        eeg = values[:, ich]\n",
    "        bl = np.nanmedian(eeg)\n",
    "\n",
    "        all_std[i] = np.nanstd(eeg)\n",
    "\n",
    "        if np.sum(np.isnan(eeg)) > 0.5 * len(eeg):\n",
    "            bad.append(ich)\n",
    "            nan_ch.append(ich)\n",
    "            continue\n",
    "\n",
    "        if np.sum(eeg == 0) > 0.5 * len(eeg):\n",
    "            bad.append(ich)\n",
    "            zero_ch.append(ich)\n",
    "            continue\n",
    "\n",
    "        if np.sum(np.abs(eeg - bl) > abs_thresh) > 10:\n",
    "            bad.append(ich)\n",
    "            bad_ch = 1\n",
    "            high_ch.append(ich)\n",
    "\n",
    "        if bad_ch == 1:\n",
    "            continue\n",
    "\n",
    "        pct = np.percentile(eeg, [100 - tile, tile])\n",
    "        thresh = [bl - mult * (bl - pct[0]), bl + mult * (pct[1] - bl)]\n",
    "        sum_outside = np.sum((eeg > thresh[1]) | (eeg < thresh[0]))\n",
    "\n",
    "        if sum_outside >= num_above:\n",
    "            bad_ch = 1\n",
    "\n",
    "        if bad_ch == 1:\n",
    "            bad.append(ich)\n",
    "            high_var_ch.append(ich)\n",
    "            continue\n",
    "\n",
    "        Y = fft(eeg - np.nanmean(eeg))\n",
    "\n",
    "        P = np.abs(Y) ** 2\n",
    "        freqs = np.linspace(0, fs, len(P) + 1)\n",
    "        freqs = freqs[:-1]\n",
    "        P = P[: int(np.ceil(len(P) / 2))]\n",
    "        freqs = freqs[: int(np.ceil(len(freqs) / 2))]\n",
    "\n",
    "        total_P = np.sum(P)\n",
    "        if total_P != 0 and not np.isnan(total_P):\n",
    "            P_60Hz = np.sum(P[(freqs > 58) & (freqs < 62)]) / total_P\n",
    "        else:\n",
    "            P_60Hz = 0  # or any other value that makes sense in the context\n",
    "\n",
    "        if P_60Hz > percent_60_hz:\n",
    "            bad_ch = 1\n",
    "\n",
    "        if bad_ch == 1:\n",
    "            bad.append(ich)\n",
    "            noisy_ch.append(ich)\n",
    "            continue\n",
    "\n",
    "    median_std = np.nanmedian(all_std)\n",
    "    higher_std = [\n",
    "        channel_indices[i]\n",
    "        for i in range(len(all_std))\n",
    "        if all_std[i] > mult_std * median_std\n",
    "    ]\n",
    "    bad_std = [ch for ch in higher_std if ch not in bad]\n",
    "    bad.extend(bad_std)\n",
    "\n",
    "    details = {\n",
    "        \"noisy\": noisy_ch,\n",
    "        \"nans\": nan_ch,\n",
    "        \"zeros\": zero_ch,\n",
    "        \"var\": high_var_ch,\n",
    "        \"higher_std\": bad_std,\n",
    "        \"high_voltage\": high_ch,\n",
    "    }\n",
    "\n",
    "    return bad, details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_bad_channels(values, fs, channel_labels):\n",
    "    \"\"\"\n",
    "    data: raw EEG traces after filtering (i think)\n",
    "    fs: sampling frequency\n",
    "    channel_labels: string labels of channels to use\n",
    "    \"\"\"\n",
    "    which_chs = np.arange(values.shape[1])\n",
    "    chLabels = channel_labels\n",
    "    ## Parameters to reject super high variance\n",
    "    tile = 99\n",
    "    mult = 10\n",
    "    num_above = 1\n",
    "    abs_thresh = 5e3\n",
    "\n",
    "    ## Parameter to reject high 60 Hz\n",
    "    percent_60_hz = 0.7\n",
    "\n",
    "    ## Parameter to reject electrodes with much higher std than most electrodes\n",
    "    mult_std = 10\n",
    "\n",
    "    bad = []\n",
    "    high_ch = []\n",
    "    nan_ch = []\n",
    "    zero_ch = []\n",
    "    high_var_ch = []\n",
    "    noisy_ch = []\n",
    "    all_std = np.empty((len(which_chs), 1))\n",
    "    all_std[:] = np.nan\n",
    "    details = {}\n",
    "\n",
    "    for i in range(len(which_chs)):\n",
    "        # print(chLabels[i])\n",
    "\n",
    "        ich = which_chs[i]\n",
    "        eeg = values[:, ich]\n",
    "        bl = np.nanmedian(eeg)\n",
    "\n",
    "        ## Get channel standard deviation\n",
    "        all_std[i] = np.nanstd(eeg)\n",
    "\n",
    "        ## Remove channels with nans in more than half\n",
    "        if sum(np.isnan(eeg)) > 0.5 * len(eeg):\n",
    "            bad.append(ich)\n",
    "            nan_ch.append(ich)\n",
    "            continue\n",
    "\n",
    "        ## Remove channels with zeros in more than half\n",
    "        if sum(eeg == 0) > (0.5 * len(eeg)):\n",
    "            bad.append(ich)\n",
    "            zero_ch.append(ich)\n",
    "            continue\n",
    "\n",
    "        ## Remove channels with too many above absolute thresh\n",
    "\n",
    "        if sum(abs(eeg - bl) > abs_thresh) > 10:\n",
    "            bad.append(ich)\n",
    "            high_ch.append(ich)\n",
    "            continue\n",
    "\n",
    "        ## Remove channels if there are rare cases of super high variance above baseline (disconnection, moving, popping)\n",
    "        pct = np.percentile(eeg, [100 - tile, tile])\n",
    "        thresh = [bl - mult * (bl - pct[0]), bl + mult * (pct[1] - bl)]\n",
    "        sum_outside = sum(((eeg > thresh[1]) + (eeg < thresh[0])) > 0)\n",
    "        if sum_outside >= num_above:\n",
    "            bad.append(ich)\n",
    "            high_var_ch.append(ich)\n",
    "            continue\n",
    "\n",
    "        ## Remove channels with a lot of 60 Hz noise, suggesting poor impedance\n",
    "\n",
    "        # Calculate fft\n",
    "        # orig_eeg = orig_values(:,ich)\n",
    "        # Y = fft(orig_eeg-mean(orig_eeg))\n",
    "        Y = np.fft.fft(eeg - np.nanmean(eeg))\n",
    "\n",
    "        # Get power\n",
    "        P = abs(Y) ** 2\n",
    "        freqs = np.linspace(0, fs, len(P) + 1)\n",
    "        freqs = freqs[:-1]\n",
    "\n",
    "        # Take first half\n",
    "        P = P[: np.ceil(len(P) / 2).astype(int)]\n",
    "        freqs = freqs[: np.ceil(len(freqs) / 2).astype(int)]\n",
    "\n",
    "        P_60Hz = sum(P[(freqs > 58) * (freqs < 62)]) / sum(P)\n",
    "        if P_60Hz > percent_60_hz:\n",
    "            bad.append(ich)\n",
    "            noisy_ch.append(ich)\n",
    "            continue\n",
    "\n",
    "    ## Remove channels for whom the std is much larger than the baseline\n",
    "    median_std = np.nanmedian(all_std)\n",
    "    higher_std = which_chs[(all_std > (mult_std * median_std)).squeeze()]\n",
    "    bad_std = higher_std\n",
    "    for ch in bad_std:\n",
    "        if ch not in bad:\n",
    "            bad.append(ch)\n",
    "    channel_mask = [i for i in which_chs if i not in bad]\n",
    "    details[\"noisy\"] = noisy_ch\n",
    "    details[\"nans\"] = nan_ch\n",
    "    details[\"zeros\"] = zero_ch\n",
    "    details[\"var\"] = high_var_ch\n",
    "    details[\"higher_std\"] = bad_std\n",
    "    details[\"high_voltage\"] = high_ch\n",
    "\n",
    "    return channel_mask, details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artifact rejection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common average montage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save ieeg_data to a csv file\n",
    "# ieeg_data.to_csv(\"ieeg_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spike detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ieeg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = clean_detector(ieeg_data, int(fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select rows in gdf where Spike Location is between 72600 and 73600\n",
    "# gdf_selected = gdf[(gdf[\"Spike Location\"] >= 72600) & (gdf[\"Spike Location\"] <= 73600)]\n",
    "# gdf_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Randomly select 50 rows from gdf\n",
    "# gdf_random = gdf.sample(n=50, random_state=1)\n",
    "# # Sort by Spike Location\n",
    "# gdf_random = gdf_random.sort_values(by=['Spike Location'])\n",
    "# gdf_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Group by 'Channel Name' and count the number of spikes\n",
    "# grouped = gdf.groupby(\"Channel Name\").size().reset_index(name=\"Total Spikes\")\n",
    "# # Fidn the row where Channel Name is \"LA09\"\n",
    "# gdf[gdf[\"Channel Name\"] == \"LB07\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spikes(ieeg_data, gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spike(data, spike_loc, title):\n",
    "    \"\"\"\n",
    "    Plots the spike centered in the middle of its duration.\n",
    "\n",
    "    :param data: Data segment containing the spike.\n",
    "    :param spike_loc: Location of the spike in the data segment.\n",
    "    :param duration: Duration of the spike.\n",
    "    :param title: Title of the plot.\n",
    "    \"\"\"\n",
    "    plt.plot(data)\n",
    "    plt.axvline(spike_loc, color=\"r\", linestyle=\"--\")  # Spike location line\n",
    "    plt.title(title)\n",
    "    plt.rcParams[\"figure.figsize\"] = (5, 5)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Iterate through each spike in the gdf dataframe\n",
    "for _, row in gdf.iterrows():\n",
    "    channel_name = row[\"Channel Name\"]\n",
    "    spike_location = row[\"Spike Location\"]\n",
    "    duration = row[\"Spike Duration\"]\n",
    "\n",
    "    # Extract data centered around the spike from ieeg_data\n",
    "    start = int(spike_location - duration / 2 - 500)\n",
    "    end = int(spike_location + duration / 2 + 500)\n",
    "    data_segment = ieeg_data[channel_name][start:end]\n",
    "\n",
    "    # Plot the spike\n",
    "    plot_spike(data_segment, spike_location, f\"Spike in {channel_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erin's Spike Detector - Will's Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 spikes detected\n"
     ]
    }
   ],
   "source": [
    "output = spike_detector(\n",
    "    data=ieeg_data.to_numpy(),\n",
    "    fs=fs,\n",
    "    labels=labels,\n",
    ")\n",
    "print(f\"{len(np.unique(output[:, 2]))} spikes detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load expected_output.npy as expected_output\n",
    "expected_output = np.load(\"expected_output.npy\")\n",
    "# Assert that expected_output and output are equal\n",
    "np.testing.assert_equal(expected_output, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique spike sequence indices\n",
    "unique_sequences = np.unique(output[:, 2])\n",
    "\n",
    "# For each unique spike sequence index\n",
    "for seq_index in unique_sequences:\n",
    "    # Filter rows (spikes) that belong to this sequence\n",
    "    spikes_in_sequence = output[output[:, 2] == seq_index]\n",
    "\n",
    "    # Create a new figure for this sequence\n",
    "    fig, axs = plt.subplots(\n",
    "        len(spikes_in_sequence),\n",
    "        1,\n",
    "        sharex=True,\n",
    "        figsize=(8, len(spikes_in_sequence) * 2),\n",
    "    )\n",
    "\n",
    "    # Add a title to the figure\n",
    "    fig.suptitle(f\"Spike sequence {int(seq_index)}\", fontsize=12)\n",
    "\n",
    "    # If there's only one spike in the sequence, axs will not be an array. Convert it to one for consistency.\n",
    "    if len(spikes_in_sequence) == 1:\n",
    "        axs = [axs]\n",
    "\n",
    "    # Plot each spike in this sequence\n",
    "    for i, spike in enumerate(spikes_in_sequence):\n",
    "        peak_location = int(spike[0])\n",
    "        channel_index = int(spike[1])\n",
    "\n",
    "        # Extract the data around the spike peak (500 samples before and after)\n",
    "        start_idx = max(0, peak_location - 200)  # Ensure we don't go below 0\n",
    "        end_idx = min(\n",
    "            len(ieeg_data), peak_location + 200\n",
    "        )  # Ensure we don't exceed dataframe length\n",
    "        data_to_plot = ieeg_data.iloc[start_idx:end_idx, channel_index]\n",
    "\n",
    "        # Plot this spike data\n",
    "        axs[i].plot(data_to_plot.index, data_to_plot.values)\n",
    "\n",
    "        # Add a red vertical dashed line at the location of the peak of the spike\n",
    "        axs[i].axvline(x=peak_location, color=\"red\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "        axs[i].set_title(f\"Channel {labels[channel_index]}\")\n",
    "\n",
    "    # Set shared x-label\n",
    "    axs[-1].set_xlabel(\"Sample Number\")\n",
    "\n",
    "    # Adjust layout for the suptitle\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.95)  # Adjust this value for best appearance\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line Length Spike Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lleventdetector import *\n",
    "from lltransform import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ieeg_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ieeg_data_transposed = ieeg_data.to_numpy().T\n",
    "ieeg_data_transposed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_length_transform = lltransform(ieeg_data_transposed, int(fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_length_detector_result = lleventdetector(line_length_transform, int(fs), 99.9, 15)\n",
    "line_length_detector_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_length_detector_result[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_windows, electrodes_list = line_length_detector_result\n",
    "\n",
    "# Setup colors - if there are more electrodes than colors, they will be reused.\n",
    "colors = plt.cm.jet(np.linspace(0, 1, 200))\n",
    "\n",
    "for window, electrodes in zip(spike_windows, electrodes_list):\n",
    "    start, end = window\n",
    "    start -= 50  # Enlarge window by 50 at the start\n",
    "    end += 50  # and 50 at the end\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Get each electrode number from the comma-separated string, and plot its data.\n",
    "    for elec in electrodes.split(\",\"):\n",
    "        if elec:  # Check if not an empty string\n",
    "            elec_num = int(elec)\n",
    "            plt.plot(\n",
    "                ieeg_data_transposed[elec_num, int(start) : int(end)],\n",
    "                color=colors[elec_num],\n",
    "                label=f\"Electrode {elec_num}\",\n",
    "            )\n",
    "\n",
    "    plt.title(f\"Spike Window: {start}-{end}\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Time (samples)\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for window, electrodes in zip(spike_windows[:15], electrodes_list[:15]):\n",
    "    start, end = window\n",
    "    start -= 100  # Enlarge window by 50 at the start\n",
    "    end += 100  # and 50 at the end\n",
    "\n",
    "    electrode_nums = [int(elec) for elec in electrodes.split(\",\") if elec]\n",
    "\n",
    "    fig, axs = plt.subplots(\n",
    "        len(electrode_nums), 1, sharex=True, figsize=(5, 2 * len(electrode_nums))\n",
    "    )\n",
    "\n",
    "    # If there's only one electrode for this window, axs will not be an array. Convert it to a list for consistency.\n",
    "    if not isinstance(axs, np.ndarray):\n",
    "        axs = [axs]\n",
    "\n",
    "    for ax, elec_num in zip(axs, electrode_nums):\n",
    "        ax.plot(\n",
    "            ieeg_data_transposed[elec_num, int(start) : int(end)],\n",
    "            color=colors[elec_num],\n",
    "        )\n",
    "        ax.set_title(f\"Electrode {good_labels[elec_num]}\")\n",
    "        ax.set_ylabel(\"Amplitude\")\n",
    "\n",
    "    plt.xlabel(\"Time (samples)\")\n",
    "    plt.tight_layout()\n",
    "    fig.suptitle(f\"Spike Window: {start}-{end}\", y=1.02)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
