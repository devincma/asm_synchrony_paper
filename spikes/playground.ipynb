{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground for Interictal Spike Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf __pycache__\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from ieeg.auth import Session\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from get_iEEG_data import *\n",
    "from spike_detector import *\n",
    "from spike_morphology import *\n",
    "from iEEG_helper_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- -- IEEG password file saved -- --\n"
     ]
    }
   ],
   "source": [
    "def create_pwd_file(username, password, fname=None):\n",
    "    if fname is None:\n",
    "        fname = \"{}_ieeglogin.bin\".format(username[:3])\n",
    "    with open(fname, \"wb\") as f:\n",
    "        f.write(password.encode())\n",
    "    print(\"-- -- IEEG password file saved -- --\")\n",
    "\n",
    "\n",
    "create_pwd_file(\"dma\", \"mycqEv-pevfo4-roqfan\")\n",
    "\n",
    "with open(\"dma_ieeglogin.bin\", \"r\") as f:\n",
    "    s = Session(\"dma\", f.read())\n",
    "\n",
    "ds = s.open_dataset(\"HUP210_phaseII\")\n",
    "all_channel_labels = np.array(ds.get_channel_labels())\n",
    "label_idxs = electrode_selection(all_channel_labels)\n",
    "labels = all_channel_labels[label_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ieeg_data, fs = get_iEEG_data(\n",
    "    \"dma\",\n",
    "    \"dma_ieeglogin.bin\",\n",
    "    \"HUP210_phaseII\",\n",
    "    (179677 + (72600 / 1024)) * 1e6,\n",
    "    (179677 + (72600 / 1024) + 60) * 1e6,\n",
    "    labels,\n",
    ")\n",
    "\n",
    "# ieeg_data, fs = get_iEEG_data(\n",
    "#     \"dma\",\n",
    "#     \"dma_ieeglogin.bin\",\n",
    "#     \"HUP210_phaseII\",\n",
    "#     720000000.0,\n",
    "#     840000000.0,\n",
    "#     labels,\n",
    "# )\n",
    "\n",
    "fs = int(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_channels_res = detect_bad_channels_optimized(ieeg_data.to_numpy(), fs)\n",
    "good_channel_indicies = good_channels_res[0]\n",
    "good_channel_labels = labels[good_channel_indicies]\n",
    "ieeg_data = ieeg_data[good_channel_labels].to_numpy()\n",
    "\n",
    "ieeg_data = common_average_montage(ieeg_data)\n",
    "\n",
    "# Apply the filters directly on the DataFrame\n",
    "ieeg_data = notch_filter(ieeg_data, 59, 61, fs)\n",
    "ieeg_data = bandpass_filter(ieeg_data, 1, 70, fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erin's Spike Detector - Alfredo's Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will try to reproduce the spike detectors proposed here: https://www.sciencedirect.com/science/article/pii/S1388245707001666?via%3Dihub, which are the ones that Erin currently uses\n",
    "\n",
    "Actually, Erin's code can be accessed here: https://github.com/erinconrad/FC_toolbox/blob/main/spike_detector/clean_detector.m\n",
    "so it is just a matter of translating this matlab code into a Python code\n",
    "\n",
    "Detector based off of Erin's code - there are 3 functions that are needed for this to run: 1. function for filtering the ieeg data (`eegfilt`), 2. function for finding peaks (`findpeaks`), 3. function for ensuring that spikes are detected in more than one channel (`multi_channel_requirements`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`findpeaks` function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findpeaks(s):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        s: timeseries signal\n",
    "    Outputs:\n",
    "        p: location in the signal with an increasing signal (positive slope)\n",
    "        t: location in the signal with a decreasing signal (negative slope)\n",
    "    \"\"\"\n",
    "    ds = np.diff(s)\n",
    "    ds = np.hstack((ds[0], ds))  # pad diff\n",
    "    filt = np.where(ds[1:] == 0)[0] + 1  # find zeros\n",
    "    ds[filt] = ds[filt - 1]  # replace zeros\n",
    "    ds = np.sign(ds)\n",
    "    # compute the second derivative -  inflection points\n",
    "    ds = np.diff(ds)\n",
    "    t = np.where(ds > 0)[0]\n",
    "    p = np.where(ds < 0)[0]\n",
    "    return p, t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`eegfilt` function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eegfilt(x, fc, typ, fs):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        x: timeseries signal\n",
    "        fc: cutoff frequency\n",
    "        typ: type of filtering (lp - lowpass, hp - highpass)\n",
    "        fs: sampling rate of x\n",
    "    Outputs:\n",
    "        p: location in the signal with an increasing signal (positive slope)\n",
    "        t: location in the signal with a decreasing signal (negative slope)\n",
    "    \"\"\"\n",
    "    # filter eeg data using Butterworth filter\n",
    "    # out = eegfilt(data,cutfreq,typ);\n",
    "    # out = eegfilt(data,70,'hp'); high pass with 70Hz cutoff\n",
    "\n",
    "    # EEG_BUTTER - Butterworth filter implementation\n",
    "    # xf = eeg_butter(x,sampl_freq,cutoff_freq,filter_type,num_poles)\n",
    "\n",
    "    np = 6  # order of the butterworth filter\n",
    "\n",
    "    if np.sum(fc >= fs / 2):\n",
    "        raise ValueError(\"Cutoff frequency must be < one half the sampling rate\")\n",
    "\n",
    "    fn = fs / 2\n",
    "\n",
    "    if typ == \"bp\":\n",
    "        typ = \"lp\"\n",
    "\n",
    "    if typ == \"lp\":\n",
    "        B, A = butter(np, fc / fn)\n",
    "    elif typ == \"hp\":\n",
    "        B, A = butter(np, fc / fn, \"high\")\n",
    "    elif typ == \"st\":\n",
    "        B, A = butter(np, fc / fn, \"stop\")\n",
    "\n",
    "    out = filtfilt(B, A, x)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`multichannel_requirements` function that makes sure that the spikes occur in 2 or more channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multichannel_requirements(gdf, nchs, fs):\n",
    "    # Parameters\n",
    "    min_chs = 2  # spike should be on at least 2 channels\n",
    "    max_chs = int(nchs * 0.5)  # on no more than half the channels\n",
    "    min_time = int(100 * 1e-3 * fs)  # 100 ms to look for other spikes\n",
    "\n",
    "    final_spikes = []\n",
    "\n",
    "    s = 0\n",
    "    curr_seq = [s]\n",
    "    last_time = gdf[s, 1]\n",
    "\n",
    "    while s < gdf.shape[0] - 1:\n",
    "        # move to next spike time\n",
    "        new_time = gdf[s + 1, 1]\n",
    "\n",
    "        # if it's within the time diff\n",
    "        if new_time - last_time < min_time:\n",
    "            curr_seq.append(s + 1)  # append it to the current sequence\n",
    "\n",
    "            if s == gdf.shape[0] - 2:\n",
    "                # done with sequence, check if the number of involved chs is appropriate\n",
    "                l = len(np.unique(gdf[curr_seq, 0]))\n",
    "                if min_chs <= l <= max_chs:\n",
    "                    final_spikes.append(\n",
    "                        np.hstack(\n",
    "                            (\n",
    "                                gdf[curr_seq, :],\n",
    "                                (gdf[curr_seq, 1] - np.min(gdf[curr_seq, 1]))[\n",
    "                                    :, np.newaxis\n",
    "                                ],\n",
    "                            )\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "        else:\n",
    "            # done with sequence, check if the length of sequence is appropriate\n",
    "            l = len(np.unique(gdf[curr_seq, 0]))\n",
    "            if min_chs <= l <= max_chs:\n",
    "                final_spikes.append(\n",
    "                    np.hstack(\n",
    "                        (\n",
    "                            gdf[curr_seq, :],\n",
    "                            (gdf[curr_seq, 1] - np.min(gdf[curr_seq, 1]))[\n",
    "                                :, np.newaxis\n",
    "                            ],\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            # reset sequence\n",
    "            curr_seq = [s + 1]\n",
    "\n",
    "        # increase the last time\n",
    "        last_time = gdf[s + 1, 1]\n",
    "\n",
    "        # increase the current spike\n",
    "        s += 1\n",
    "    if len(final_spikes) > 0:\n",
    "        multichannel_spikes = np.vstack(final_spikes)\n",
    "    else:\n",
    "        print(\"No spikes meet the criteria...\")\n",
    "        multichannel_spikes = []\n",
    "    return multichannel_spikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actual Spike Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_detector(\n",
    "    eeg_df,\n",
    "    fs,\n",
    "    remove_channels=[\n",
    "        \"EEG EKG 02-Ref\",\n",
    "        \"ECG1\",\n",
    "        \"EEG EKG1-Ref\",\n",
    "        \"EKG2\",\n",
    "        \"EKG\",\n",
    "        \"EKG1\",\n",
    "        \"EKG02\",\n",
    "        \"EEG EKG2-Ref\",\n",
    "        \"EEG EKG 01-Ref\",\n",
    "        \"EEG EKG-Ref\",\n",
    "        \"ECG2\",\n",
    "        \"EKG01\",\n",
    "    ],\n",
    "):\n",
    "    # extract the data from the dataframe\n",
    "    eeg = eeg_df.values\n",
    "\n",
    "    ## Parameters\n",
    "    tmul = 19  # minimum relative amplitude (compared to baseline)\n",
    "    absthresh = 100  # minimum absolute amplitude (uV)\n",
    "    sur_time = (\n",
    "        0.5  # surround time (in s) against which to compare for relative amplitude\n",
    "    )\n",
    "    close_to_edge = 0.05  # time (in s) surrounding start and end of sample to ignore\n",
    "    too_high_abs = 1e3  # amplitude above which I reject it as artifact\n",
    "    spkdur = [15, 200]  # spike duration must be within this range (in ms)\n",
    "    spkdur = np.array(spkdur) * fs // 1000  # convert above to samples\n",
    "    lpf1 = 30  # low pass filter for artifact component\n",
    "    hpf = 7  # high pass filter for spikey component\n",
    "\n",
    "    ## Initialize things\n",
    "    all_spikes = np.empty((0, 4))\n",
    "    nchs = eeg.shape[1]\n",
    "    ch_names = list(eeg_df.columns)\n",
    "\n",
    "    ## Iterate channels and detect spikes\n",
    "    print(\"Detecting spikes through channels\")\n",
    "    for j in range(nchs):\n",
    "        if ch_names[j] not in remove_channels:\n",
    "            # initialize out array with final spike info\n",
    "            out = np.empty((0, 3))\n",
    "\n",
    "            # extract channel data\n",
    "            data = eeg[:, j]\n",
    "\n",
    "            # Skip if all nans\n",
    "            if np.sum(np.isnan(data)) > 0:\n",
    "                continue\n",
    "\n",
    "            # re-adjust the mean of the data to be zero\n",
    "            data = data - np.nanmean(data)\n",
    "\n",
    "            # initialize array with tentative spike info\n",
    "            spikes = []\n",
    "\n",
    "            # Low pass filter to remove artifact\n",
    "            b, a = butter(4, lpf1 / (fs / 2), btype=\"lowpass\")\n",
    "            lpdata = filtfilt(b, a, data)  # low pass filter\n",
    "\n",
    "            # high pass filter to get the spikey part\n",
    "            b, a = butter(4, hpf / (fs / 2), btype=\"highpass\")\n",
    "            hpdata = filtfilt(b, a, lpdata)  # high pass filter\n",
    "\n",
    "            # establish the baseline for the relative amplitude threshold\n",
    "            lthresh = np.median(np.abs(hpdata))\n",
    "            thresh = lthresh * tmul  # this is the final threshold we want to impose\n",
    "\n",
    "            # Run the spike detector to find both negative and positive spikes\n",
    "            for k in range(2):\n",
    "                if k == 1:\n",
    "                    kdata = -hpdata  # flip the sign of the data to find positive spikes\n",
    "                else:\n",
    "                    kdata = hpdata\n",
    "\n",
    "                # find peaks (spp) and troughs (spv) in the data\n",
    "                spp, spv = findpeaks(kdata)\n",
    "\n",
    "                # find peak-to-peak durations within allowable range\n",
    "                idx = np.where(np.diff(spp) <= spkdur[1])[0]\n",
    "\n",
    "                # peak before list\n",
    "                startdx = spp[idx]\n",
    "\n",
    "                # peak after list\n",
    "                startdx1 = spp[idx + 1]\n",
    "\n",
    "                # Loop over peaks\n",
    "                for i in range(len(startdx)):\n",
    "                    # find the valley that is between the two peaks\n",
    "                    spkvalley = spv[np.where((spv > startdx[i]) & (spv < startdx1[i]))]\n",
    "\n",
    "                    # If the height from valley to either peak is big enough, it could be a spike\n",
    "                    max_height = max(\n",
    "                        abs(kdata[startdx1[i]] - kdata[spkvalley]),\n",
    "                        abs(kdata[startdx[i]] - kdata[spkvalley]),\n",
    "                    )\n",
    "                    if (\n",
    "                        max_height > thresh\n",
    "                    ):  # if amplitude from peak to valley is large enough, append as a spike\n",
    "                        # add the location of the spike valley, the duration of spike from peak 1 to peak 2 and the amplitude from peak to valley\n",
    "                        spikes.append(\n",
    "                            [spkvalley[0], startdx1[i] - startdx[i], max_height]\n",
    "                        )\n",
    "\n",
    "            if len(spikes) > 0:\n",
    "                # Add channel number and convert spike time to samples\n",
    "                spikes = [[a, b, c[0]] for a, b, c in spikes]\n",
    "                spikes = np.array(spikes)\n",
    "                # print\n",
    "                # spikes[:, -1] = list(map(lambda x: x[0], spikes[:, -1]))\n",
    "                spikes = spikes.astype(float)\n",
    "\n",
    "                # check different properties for each of the detected spikes to make sure that they are truly spikes\n",
    "                # make sure they are not too small in amplitude (noise), too sharp/short in time (noise), or too large (artifact)\n",
    "                toosmall = []\n",
    "                toosharp = []\n",
    "                toobig = []\n",
    "\n",
    "                # for each spike - spikes is a n_spikes by properties array\n",
    "                for i in range(spikes.shape[0]):\n",
    "                    # re-define baseline to be period surrounding spike\n",
    "                    istart = int(\n",
    "                        max(1, round(spikes[i, 0] - sur_time * fs))\n",
    "                    )  # starting time for the surrounding timepoints is either 1 (if spike is at timepoint 0), or at the surrounding timepoint\n",
    "                    iend = int(\n",
    "                        min(len(hpdata), round(spikes[i, 0] + sur_time * fs))\n",
    "                    )  # same but for ending time. It accounts for the spike being in the last timepoint\n",
    "\n",
    "                    # define a regional local threshold within the specified time range\n",
    "                    alt_thresh = np.median(np.abs(hpdata[istart:iend])) * tmul\n",
    "\n",
    "                    if (\n",
    "                        spikes[i, 2] > alt_thresh and spikes[i, 2] > absthresh\n",
    "                    ):  # both parts together are bigger than thresh: so have some flexibility in relative sizes\n",
    "                        if (\n",
    "                            spikes[i, 1] * 1000 / fs > spkdur[0]\n",
    "                        ):  # spike wave cannot be too sharp: then it is either too small or noise\n",
    "                            if spikes[i, 2] < too_high_abs:\n",
    "                                out = np.vstack(\n",
    "                                    (out, spikes[i, :])\n",
    "                                )  # add info of spike to output list\n",
    "                            else:\n",
    "                                toobig.append(spikes[i, 0])\n",
    "                        else:\n",
    "                            toosharp.append(spikes[i, 0])\n",
    "                    else:\n",
    "                        toosmall.append(spikes[i, 0])\n",
    "\n",
    "                if out.shape[0] > 0:\n",
    "                    # Re-align spikes to peak of the spikey component\n",
    "                    timeToPeak = [\n",
    "                        -0.15,\n",
    "                        0.15,\n",
    "                    ]  # Only look 150 ms before and after the currently defined peak\n",
    "                    fullSurround = [-sur_time, sur_time] * fs\n",
    "                    idxToPeak = (np.array(timeToPeak) * fs).astype(int)\n",
    "\n",
    "                    for i in range(out.shape[0]):\n",
    "                        currIdx = out[i, 0]\n",
    "                        surround_idx = np.arange(\n",
    "                            max(1, round(currIdx + fullSurround[0])),\n",
    "                            min(round(currIdx + fullSurround[1]), len(hpdata)),\n",
    "                        ).astype(int)\n",
    "                        idxToLook = np.arange(\n",
    "                            max(1, round(currIdx + idxToPeak[0])),\n",
    "                            min(round(currIdx + idxToPeak[1]), len(hpdata)),\n",
    "                        ).astype(int)\n",
    "                        snapshot = data[idxToLook] - np.median(data[surround_idx])\n",
    "                        # Look at the high frequency data (where the mean is subtracted already)\n",
    "                        I = np.argmax(np.abs(snapshot))\n",
    "                        # The peak is the maximum absolute value of this\n",
    "                        out[i, 0] = idxToLook[0] + I - 1\n",
    "\n",
    "                    all_spikes = np.vstack(\n",
    "                        (all_spikes, np.hstack((np.full((out.shape[0], 1), j), out)))\n",
    "                    )\n",
    "\n",
    "    # convert the last column to a list of numbers instead of a list of arrays\n",
    "    # output the numpy array with the spikes\n",
    "    gdf = all_spikes\n",
    "    gdf = np.unique(gdf, axis=0)\n",
    "\n",
    "    # sort by times and put ch first\n",
    "    if gdf.size > 0:\n",
    "        gdf = gdf[gdf[:, 1].argsort(), :]  # sort by time\n",
    "\n",
    "        \"\"\"\n",
    "        times = gdf[:,0]\n",
    "        chs = gdf[:,1]\n",
    "        I = np.argsort(times)\n",
    "        chs = chs[I]\n",
    "        times = times[I]\n",
    "        gdf = np.vstack((chs, times)).T\n",
    "        \"\"\"\n",
    "    # Remove those at beginning and end\n",
    "    if gdf.size > 0:\n",
    "        close_idx = int(close_to_edge * fs)\n",
    "        gdf = gdf[gdf[:, 1] >= close_idx]\n",
    "        gdf = gdf[gdf[:, 1] <= eeg.shape[0] - close_idx]\n",
    "\n",
    "    # remove duplicates\n",
    "    if gdf.size > 0:\n",
    "        keep = np.ones(gdf.shape[0], dtype=bool)\n",
    "\n",
    "        # take diff of times\n",
    "        diff_times = np.hstack((np.inf, np.diff(gdf[:, 1])))\n",
    "\n",
    "        # take diff of chs\n",
    "        diff_chs = np.hstack((np.inf, np.diff(gdf[:, 0])))\n",
    "\n",
    "        # find those that are close in time and the same ch\n",
    "        too_close = np.logical_and(abs(diff_times) < 100e-3 * fs, diff_chs == 0)\n",
    "\n",
    "        keep[too_close] = 0\n",
    "        keep = np.array(keep)\n",
    "\n",
    "        n_removed = np.sum(~keep)\n",
    "        gdf = gdf[keep]\n",
    "\n",
    "    # execute the multichannel requirements\n",
    "    gdf = multichannel_requirements(gdf, nchs, fs)\n",
    "\n",
    "    if len(gdf) > 0:\n",
    "        # convert gdf into a pandas dataframe\n",
    "        df_spikes = pd.DataFrame()\n",
    "        df_spikes[\"Channel Number\"] = gdf[:, 0].astype(int)\n",
    "        df_spikes[\"Channel Name\"] = list(\n",
    "            map(lambda x: ch_names[x], gdf[:, 0].astype(int))\n",
    "        )\n",
    "        df_spikes[\"Spike Location\"] = gdf[:, 1].astype(int)\n",
    "        df_spikes[\"Spike Duration\"] = gdf[:, 2].astype(int)\n",
    "        df_spikes[\"Spike Amplitude\"] = gdf[:, 3]\n",
    "    else:\n",
    "        df_spikes = pd.DataFrame(\n",
    "            columns=[\n",
    "                \"Channel Number\",\n",
    "                \"Channel Name\",\n",
    "                \"Spike Location\",\n",
    "                \"Spike Duration\",\n",
    "                \"Spike Amplitude\",\n",
    "            ]\n",
    "        )\n",
    "    return df_spikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for plotting the spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spikes(ieeg_data, spike_df):\n",
    "    channels_with_spikes = list(set(spike_df[\"Channel Number\"].values))\n",
    "\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    for i, ch in enumerate(channels_with_spikes):\n",
    "        plt.subplot(len(channels_with_spikes), 1, i + 1)\n",
    "        plt.plot(ieeg_data.values[:, ch])\n",
    "        sns.despine(top=True, right=True, left=True, bottom=True)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "\n",
    "        spike_locations = spike_df[spike_df[\"Channel Number\"] == ch][\n",
    "            \"Spike Location\"\n",
    "        ].values\n",
    "        spike_amplitudes = spike_df[spike_df[\"Channel Number\"] == ch][\n",
    "            \"Spike Amplitude\"\n",
    "        ].values\n",
    "        for j, (location, amplitude) in enumerate(\n",
    "            zip(spike_locations, spike_amplitudes)\n",
    "        ):\n",
    "            plt.plot(\n",
    "                location, ieeg_data.values[location, ch], \".\", markersize=10, color=\"r\"\n",
    "            )\n",
    "        channel_name = spike_df[spike_df[\"Channel Number\"] == ch][\n",
    "            \"Channel Name\"\n",
    "        ].values[0]\n",
    "        plt.ylabel(channel_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the Spike Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_bad_channels(values, channel_indices, channel_labels, fs):\n",
    "    \"\"\"\n",
    "    Identifies 'bad' channels in an EEG dataset based on various criteria such as high variance, missing data,\n",
    "    crossing absolute threshold, high variance above baseline, and 60 Hz noise.\n",
    "\n",
    "    Parameters:\n",
    "    values (numpy.ndarray): A 2D array of EEG data where each column is a different channel and each row is a reading.\n",
    "    channel_indices (list): A list containing indices of channels to be analyzed.\n",
    "    channel_labels (list): A list of channel labels.\n",
    "    fs (float): The sampling frequency.\n",
    "\n",
    "    Returns:\n",
    "    bad (list): A list of 'bad' channel indices.\n",
    "    details (dict): A dictionary containing the reasons why each channel was marked as 'bad'. Keys are 'noisy', 'nans',\n",
    "                    'zeros', 'var', 'higher_std', and 'high_voltage'. Each key maps to a list of channel indices.\n",
    "    \"\"\"\n",
    "\n",
    "    # set parameters\n",
    "    tile = 99\n",
    "    mult = 10\n",
    "    num_above = 1\n",
    "    abs_thresh = 5e3\n",
    "    percent_60_hz = 0.99\n",
    "    mult_std = 10\n",
    "\n",
    "    bad = []\n",
    "    high_ch = []\n",
    "    nan_ch = []\n",
    "    zero_ch = []\n",
    "    high_var_ch = []\n",
    "    noisy_ch = []\n",
    "    all_std = np.full(len(channel_indices), np.nan)\n",
    "\n",
    "    for i in range(len(channel_indices)):\n",
    "        bad_ch = 0\n",
    "        ich = channel_indices[i]\n",
    "        eeg = values[:, ich]\n",
    "        bl = np.nanmedian(eeg)\n",
    "\n",
    "        all_std[i] = np.nanstd(eeg)\n",
    "\n",
    "        if np.sum(np.isnan(eeg)) > 0.5 * len(eeg):\n",
    "            bad.append(ich)\n",
    "            nan_ch.append(ich)\n",
    "            continue\n",
    "\n",
    "        if np.sum(eeg == 0) > 0.5 * len(eeg):\n",
    "            bad.append(ich)\n",
    "            zero_ch.append(ich)\n",
    "            continue\n",
    "\n",
    "        if np.sum(np.abs(eeg - bl) > abs_thresh) > 10:\n",
    "            bad.append(ich)\n",
    "            bad_ch = 1\n",
    "            high_ch.append(ich)\n",
    "\n",
    "        if bad_ch == 1:\n",
    "            continue\n",
    "\n",
    "        pct = np.percentile(eeg, [100 - tile, tile])\n",
    "        thresh = [bl - mult * (bl - pct[0]), bl + mult * (pct[1] - bl)]\n",
    "        sum_outside = np.sum((eeg > thresh[1]) | (eeg < thresh[0]))\n",
    "\n",
    "        if sum_outside >= num_above:\n",
    "            bad_ch = 1\n",
    "\n",
    "        if bad_ch == 1:\n",
    "            bad.append(ich)\n",
    "            high_var_ch.append(ich)\n",
    "            continue\n",
    "\n",
    "        Y = fft(eeg - np.nanmean(eeg))\n",
    "\n",
    "        P = np.abs(Y) ** 2\n",
    "        freqs = np.linspace(0, fs, len(P) + 1)\n",
    "        freqs = freqs[:-1]\n",
    "        P = P[: int(np.ceil(len(P) / 2))]\n",
    "        freqs = freqs[: int(np.ceil(len(freqs) / 2))]\n",
    "\n",
    "        total_P = np.sum(P)\n",
    "        if total_P != 0 and not np.isnan(total_P):\n",
    "            P_60Hz = np.sum(P[(freqs > 58) & (freqs < 62)]) / total_P\n",
    "        else:\n",
    "            P_60Hz = 0  # or any other value that makes sense in the context\n",
    "\n",
    "        if P_60Hz > percent_60_hz:\n",
    "            bad_ch = 1\n",
    "\n",
    "        if bad_ch == 1:\n",
    "            bad.append(ich)\n",
    "            noisy_ch.append(ich)\n",
    "            continue\n",
    "\n",
    "    median_std = np.nanmedian(all_std)\n",
    "    higher_std = [\n",
    "        channel_indices[i]\n",
    "        for i in range(len(all_std))\n",
    "        if all_std[i] > mult_std * median_std\n",
    "    ]\n",
    "    bad_std = [ch for ch in higher_std if ch not in bad]\n",
    "    bad.extend(bad_std)\n",
    "\n",
    "    details = {\n",
    "        \"noisy\": noisy_ch,\n",
    "        \"nans\": nan_ch,\n",
    "        \"zeros\": zero_ch,\n",
    "        \"var\": high_var_ch,\n",
    "        \"higher_std\": bad_std,\n",
    "        \"high_voltage\": high_ch,\n",
    "    }\n",
    "\n",
    "    return bad, details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_bad_channels(values, fs, channel_labels):\n",
    "    \"\"\"\n",
    "    data: raw EEG traces after filtering (i think)\n",
    "    fs: sampling frequency\n",
    "    channel_labels: string labels of channels to use\n",
    "    \"\"\"\n",
    "    which_chs = np.arange(values.shape[1])\n",
    "    chLabels = channel_labels\n",
    "    ## Parameters to reject super high variance\n",
    "    tile = 99\n",
    "    mult = 10\n",
    "    num_above = 1\n",
    "    abs_thresh = 5e3\n",
    "\n",
    "    ## Parameter to reject high 60 Hz\n",
    "    percent_60_hz = 0.7\n",
    "\n",
    "    ## Parameter to reject electrodes with much higher std than most electrodes\n",
    "    mult_std = 10\n",
    "\n",
    "    bad = []\n",
    "    high_ch = []\n",
    "    nan_ch = []\n",
    "    zero_ch = []\n",
    "    high_var_ch = []\n",
    "    noisy_ch = []\n",
    "    all_std = np.empty((len(which_chs), 1))\n",
    "    all_std[:] = np.nan\n",
    "    details = {}\n",
    "\n",
    "    for i in range(len(which_chs)):\n",
    "        # print(chLabels[i])\n",
    "\n",
    "        ich = which_chs[i]\n",
    "        eeg = values[:, ich]\n",
    "        bl = np.nanmedian(eeg)\n",
    "\n",
    "        ## Get channel standard deviation\n",
    "        all_std[i] = np.nanstd(eeg)\n",
    "\n",
    "        ## Remove channels with nans in more than half\n",
    "        if sum(np.isnan(eeg)) > 0.5 * len(eeg):\n",
    "            bad.append(ich)\n",
    "            nan_ch.append(ich)\n",
    "            continue\n",
    "\n",
    "        ## Remove channels with zeros in more than half\n",
    "        if sum(eeg == 0) > (0.5 * len(eeg)):\n",
    "            bad.append(ich)\n",
    "            zero_ch.append(ich)\n",
    "            continue\n",
    "\n",
    "        ## Remove channels with too many above absolute thresh\n",
    "\n",
    "        if sum(abs(eeg - bl) > abs_thresh) > 10:\n",
    "            bad.append(ich)\n",
    "            high_ch.append(ich)\n",
    "            continue\n",
    "\n",
    "        ## Remove channels if there are rare cases of super high variance above baseline (disconnection, moving, popping)\n",
    "        pct = np.percentile(eeg, [100 - tile, tile])\n",
    "        thresh = [bl - mult * (bl - pct[0]), bl + mult * (pct[1] - bl)]\n",
    "        sum_outside = sum(((eeg > thresh[1]) + (eeg < thresh[0])) > 0)\n",
    "        if sum_outside >= num_above:\n",
    "            bad.append(ich)\n",
    "            high_var_ch.append(ich)\n",
    "            continue\n",
    "\n",
    "        ## Remove channels with a lot of 60 Hz noise, suggesting poor impedance\n",
    "\n",
    "        # Calculate fft\n",
    "        # orig_eeg = orig_values(:,ich)\n",
    "        # Y = fft(orig_eeg-mean(orig_eeg))\n",
    "        Y = np.fft.fft(eeg - np.nanmean(eeg))\n",
    "\n",
    "        # Get power\n",
    "        P = abs(Y) ** 2\n",
    "        freqs = np.linspace(0, fs, len(P) + 1)\n",
    "        freqs = freqs[:-1]\n",
    "\n",
    "        # Take first half\n",
    "        P = P[: np.ceil(len(P) / 2).astype(int)]\n",
    "        freqs = freqs[: np.ceil(len(freqs) / 2).astype(int)]\n",
    "\n",
    "        P_60Hz = sum(P[(freqs > 58) * (freqs < 62)]) / sum(P)\n",
    "        if P_60Hz > percent_60_hz:\n",
    "            bad.append(ich)\n",
    "            noisy_ch.append(ich)\n",
    "            continue\n",
    "\n",
    "    ## Remove channels for whom the std is much larger than the baseline\n",
    "    median_std = np.nanmedian(all_std)\n",
    "    higher_std = which_chs[(all_std > (mult_std * median_std)).squeeze()]\n",
    "    bad_std = higher_std\n",
    "    for ch in bad_std:\n",
    "        if ch not in bad:\n",
    "            bad.append(ch)\n",
    "    channel_mask = [i for i in which_chs if i not in bad]\n",
    "    details[\"noisy\"] = noisy_ch\n",
    "    details[\"nans\"] = nan_ch\n",
    "    details[\"zeros\"] = zero_ch\n",
    "    details[\"var\"] = high_var_ch\n",
    "    details[\"higher_std\"] = bad_std\n",
    "    details[\"high_voltage\"] = high_ch\n",
    "\n",
    "    return channel_mask, details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artifact rejection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common average montage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save ieeg_data to a csv file\n",
    "# ieeg_data.to_csv(\"ieeg_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spike detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ieeg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = clean_detector(ieeg_data, int(fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select rows in gdf where Spike Location is between 72600 and 73600\n",
    "# gdf_selected = gdf[(gdf[\"Spike Location\"] >= 72600) & (gdf[\"Spike Location\"] <= 73600)]\n",
    "# gdf_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Randomly select 50 rows from gdf\n",
    "# gdf_random = gdf.sample(n=50, random_state=1)\n",
    "# # Sort by Spike Location\n",
    "# gdf_random = gdf_random.sort_values(by=['Spike Location'])\n",
    "# gdf_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Group by 'Channel Name' and count the number of spikes\n",
    "# grouped = gdf.groupby(\"Channel Name\").size().reset_index(name=\"Total Spikes\")\n",
    "# # Fidn the row where Channel Name is \"LA09\"\n",
    "# gdf[gdf[\"Channel Name\"] == \"LB07\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spikes(ieeg_data, gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spike(data, spike_loc, title):\n",
    "    \"\"\"\n",
    "    Plots the spike centered in the middle of its duration.\n",
    "\n",
    "    :param data: Data segment containing the spike.\n",
    "    :param spike_loc: Location of the spike in the data segment.\n",
    "    :param duration: Duration of the spike.\n",
    "    :param title: Title of the plot.\n",
    "    \"\"\"\n",
    "    plt.plot(data)\n",
    "    plt.axvline(spike_loc, color=\"r\", linestyle=\"--\")  # Spike location line\n",
    "    plt.title(title)\n",
    "    plt.rcParams[\"figure.figsize\"] = (5, 5)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Iterate through each spike in the gdf dataframe\n",
    "for _, row in gdf.iterrows():\n",
    "    channel_name = row[\"Channel Name\"]\n",
    "    spike_location = row[\"Spike Location\"]\n",
    "    duration = row[\"Spike Duration\"]\n",
    "\n",
    "    # Extract data centered around the spike from ieeg_data\n",
    "    start = int(spike_location - duration / 2 - 500)\n",
    "    end = int(spike_location + duration / 2 + 500)\n",
    "    data_segment = ieeg_data[channel_name][start:end]\n",
    "\n",
    "    # Plot the spike\n",
    "    plot_spike(data_segment, spike_location, f\"Spike in {channel_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erin's Spike Detector - Will's Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using optimized spike detector...\n",
      "Returning early to skip multi_channel_requirement\n",
      "Detected 419 spikes.\n"
     ]
    }
   ],
   "source": [
    "spike_output = spike_detector(\n",
    "    data=ieeg_data,\n",
    "    fs=fs,\n",
    "    labels=good_channel_labels,\n",
    ")\n",
    "print(f\"Detected {len(spike_output)} spikes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  619,   154],\n",
       "       [  633,    69],\n",
       "       [  644,    39],\n",
       "       [  646,    43],\n",
       "       [  646,    41],\n",
       "       [  646,    44],\n",
       "       [  646,   153],\n",
       "       [  646,   163],\n",
       "       [  646,    40],\n",
       "       [  646,    42],\n",
       "       [  651,    13],\n",
       "       [  653,    12],\n",
       "       [  679,   161],\n",
       "       [  680,   162],\n",
       "       [ 1222,   124],\n",
       "       [ 1247,   120],\n",
       "       [ 1256,    96],\n",
       "       [ 1257,    95],\n",
       "       [ 1268,    71],\n",
       "       [ 2157,    57],\n",
       "       [ 2158,     7],\n",
       "       [ 2159,     9],\n",
       "       [ 2162,     8],\n",
       "       [ 2188,   155],\n",
       "       [ 2209,   157],\n",
       "       [ 2211,   156],\n",
       "       [ 2640,    94],\n",
       "       [ 4227,   111],\n",
       "       [ 4231,   186],\n",
       "       [ 4232,    94],\n",
       "       [ 4235,    69],\n",
       "       [ 4235,   125],\n",
       "       [ 4242,    72],\n",
       "       [ 4264,     8],\n",
       "       [ 4274,    18],\n",
       "       [ 4275,     5],\n",
       "       [ 4282,     4],\n",
       "       [ 4287,     3],\n",
       "       [ 4287,     2],\n",
       "       [ 4295,   157],\n",
       "       [ 4295,   156],\n",
       "       [ 6877,     8],\n",
       "       [ 6884,   153],\n",
       "       [ 6888,   154],\n",
       "       [ 6897,   155],\n",
       "       [ 6902,     1],\n",
       "       [ 6915,   157],\n",
       "       [ 6916,   156],\n",
       "       [10001,    72],\n",
       "       [10005,     8],\n",
       "       [10005,     7],\n",
       "       [11046,     9],\n",
       "       [11048,     8],\n",
       "       [11787,    94],\n",
       "       [11995,    72],\n",
       "       [13406,    94],\n",
       "       [14701,     7],\n",
       "       [14705,    70],\n",
       "       [14716,    71],\n",
       "       [14717,    72],\n",
       "       [14728,    21],\n",
       "       [14730,    69],\n",
       "       [14738,    44],\n",
       "       [14738,    43],\n",
       "       [14739,    42],\n",
       "       [14739,    41],\n",
       "       [14739,    94],\n",
       "       [14743,   186],\n",
       "       [16979,   106],\n",
       "       [19302,    69],\n",
       "       [19310,    43],\n",
       "       [19311,    44],\n",
       "       [19311,    40],\n",
       "       [19311,    42],\n",
       "       [19311,    41],\n",
       "       [19866,    94],\n",
       "       [19879,   124],\n",
       "       [19889,    71],\n",
       "       [20481,    69],\n",
       "       [20661,   106],\n",
       "       [21944,   147],\n",
       "       [23759,     4],\n",
       "       [23848,    57],\n",
       "       [23856,    72],\n",
       "       [23856,    17],\n",
       "       [23856,    71],\n",
       "       [23876,    20],\n",
       "       [23876,    19],\n",
       "       [23876,    18],\n",
       "       [23877,    21],\n",
       "       [23879,   110],\n",
       "       [23879,    38],\n",
       "       [23880,    94],\n",
       "       [23881,    93],\n",
       "       [23881,     9],\n",
       "       [23884,   155],\n",
       "       [23885,   127],\n",
       "       [23886,   128],\n",
       "       [23886,   126],\n",
       "       [23888,    36],\n",
       "       [23888,    39],\n",
       "       [23889,   127],\n",
       "       [23892,     0],\n",
       "       [23900,   153],\n",
       "       [23902,    37],\n",
       "       [23907,    35],\n",
       "       [23907,   157],\n",
       "       [23908,   156],\n",
       "       [23909,     4],\n",
       "       [23910,     3],\n",
       "       [23912,     2],\n",
       "       [23916,     1],\n",
       "       [23989,   136],\n",
       "       [23995,   147],\n",
       "       [24002,    72],\n",
       "       [24009,   124],\n",
       "       [24011,   109],\n",
       "       [24012,   119],\n",
       "       [24013,   109],\n",
       "       [24014,   124],\n",
       "       [24016,   126],\n",
       "       [24017,   125],\n",
       "       [24019,    94],\n",
       "       [24025,   120],\n",
       "       [24036,    95],\n",
       "       [24038,   117],\n",
       "       [24039,    85],\n",
       "       [24039,    96],\n",
       "       [24040,    84],\n",
       "       [24040,   118],\n",
       "       [24040,    83],\n",
       "       [24040,    97],\n",
       "       [24041,    98],\n",
       "       [25302,   161],\n",
       "       [27246,    94],\n",
       "       [27262,   126],\n",
       "       [27263,   125],\n",
       "       [27265,   124],\n",
       "       [27293,    86],\n",
       "       [27307,    96],\n",
       "       [27403,    70],\n",
       "       [27418,    94],\n",
       "       [27422,   147],\n",
       "       [27423,   124],\n",
       "       [27423,     7],\n",
       "       [27424,     8],\n",
       "       [27425,    21],\n",
       "       [27432,    69],\n",
       "       [27438,   185],\n",
       "       [27438,    36],\n",
       "       [27439,   186],\n",
       "       [27439,   155],\n",
       "       [27439,   153],\n",
       "       [27440,    13],\n",
       "       [27441,   187],\n",
       "       [27445,   126],\n",
       "       [27445,    95],\n",
       "       [27446,    96],\n",
       "       [27447,    98],\n",
       "       [27447,    86],\n",
       "       [27447,   125],\n",
       "       [27448,    83],\n",
       "       [27453,     4],\n",
       "       [27456,   157],\n",
       "       [27456,     3],\n",
       "       [27457,     2],\n",
       "       [27458,   156],\n",
       "       [27461,   120],\n",
       "       [27472,    97],\n",
       "       [27473,    98],\n",
       "       [27474,    99],\n",
       "       [27474,   100],\n",
       "       [27475,   101],\n",
       "       [27479,   117],\n",
       "       [27479,   118],\n",
       "       [27784,    71],\n",
       "       [29279,     8],\n",
       "       [30306,     1],\n",
       "       [30309,     0],\n",
       "       [32923,     9],\n",
       "       [32931,     8],\n",
       "       [32933,    70],\n",
       "       [32938,    21],\n",
       "       [32939,    69],\n",
       "       [32942,   147],\n",
       "       [32950,    39],\n",
       "       [32950,    42],\n",
       "       [32950,    41],\n",
       "       [32950,    40],\n",
       "       [32950,    43],\n",
       "       [32950,    44],\n",
       "       [32952,    94],\n",
       "       [32952,   186],\n",
       "       [32954,   187],\n",
       "       [33299,    98],\n",
       "       [33300,    97],\n",
       "       [33302,    96],\n",
       "       [33303,    95],\n",
       "       [33654,   147],\n",
       "       [33682,    94],\n",
       "       [34757,    94],\n",
       "       [36115,    72],\n",
       "       [36120,   112],\n",
       "       [36120,   111],\n",
       "       [36120,   136],\n",
       "       [36120,   137],\n",
       "       [36121,   110],\n",
       "       [36123,    94],\n",
       "       [36131,   124],\n",
       "       [36131,   126],\n",
       "       [36134,   125],\n",
       "       [36161,    95],\n",
       "       [38176,    71],\n",
       "       [39232,    69],\n",
       "       [39248,    72],\n",
       "       [39249,   136],\n",
       "       [39249,    57],\n",
       "       [39251,    71],\n",
       "       [39254,    94],\n",
       "       [39265,   127],\n",
       "       [39267,   114],\n",
       "       [39267,   126],\n",
       "       [39269,   125],\n",
       "       [39269,   124],\n",
       "       [39271,   137],\n",
       "       [39284,   120],\n",
       "       [39294,    86],\n",
       "       [39294,   102],\n",
       "       [39295,   101],\n",
       "       [39295,    85],\n",
       "       [39296,    84],\n",
       "       [39296,   100],\n",
       "       [39297,    99],\n",
       "       [39297,    83],\n",
       "       [39298,    98],\n",
       "       [39299,   117],\n",
       "       [39299,    97],\n",
       "       [39300,    96],\n",
       "       [39301,    95],\n",
       "       [39304,   118],\n",
       "       [39311,   119],\n",
       "       [40235,    47],\n",
       "       [41805,    18],\n",
       "       [41808,    20],\n",
       "       [41814,    70],\n",
       "       [41816,    57],\n",
       "       [41824,     8],\n",
       "       [41834,   153],\n",
       "       [41837,   154],\n",
       "       [41841,    14],\n",
       "       [41844,   155],\n",
       "       [41844,    12],\n",
       "       [41846,   158],\n",
       "       [41849,     1],\n",
       "       [41864,     3],\n",
       "       [41865,   157],\n",
       "       [41866,   156],\n",
       "       [41869,   162],\n",
       "       [41871,    98],\n",
       "       [41875,    96],\n",
       "       [42866,    45],\n",
       "       [43428,   147],\n",
       "       [44287,    20],\n",
       "       [44732,    71],\n",
       "       [44737,    72],\n",
       "       [45363,   147],\n",
       "       [45364,    70],\n",
       "       [45365,    69],\n",
       "       [45366,     8],\n",
       "       [45371,   186],\n",
       "       [45373,    39],\n",
       "       [45374,    42],\n",
       "       [45374,    41],\n",
       "       [45374,    44],\n",
       "       [45374,    43],\n",
       "       [45374,    40],\n",
       "       [45375,    36],\n",
       "       [45375,   153],\n",
       "       [45375,   154],\n",
       "       [45376,     5],\n",
       "       [45382,    12],\n",
       "       [45588,    60],\n",
       "       [45589,    59],\n",
       "       [47711,    94],\n",
       "       [47849,   112],\n",
       "       [47852,   109],\n",
       "       [47853,   127],\n",
       "       [47854,   124],\n",
       "       [47854,    94],\n",
       "       [47854,   126],\n",
       "       [47855,   108],\n",
       "       [47856,   125],\n",
       "       [47864,    98],\n",
       "       [47874,   120],\n",
       "       [47885,    86],\n",
       "       [47885,    96],\n",
       "       [47885,    97],\n",
       "       [47886,    95],\n",
       "       [47886,    85],\n",
       "       [47888,    84],\n",
       "       [47889,   100],\n",
       "       [47889,    95],\n",
       "       [47890,    83],\n",
       "       [47890,    99],\n",
       "       [47891,    96],\n",
       "       [47892,    97],\n",
       "       [47893,   117],\n",
       "       [47893,    98],\n",
       "       [47894,   118],\n",
       "       [48037,    86],\n",
       "       [48038,    87],\n",
       "       [49631,   124],\n",
       "       [49634,   125],\n",
       "       [49635,    94],\n",
       "       [49635,   109],\n",
       "       [49636,   126],\n",
       "       [49655,   120],\n",
       "       [49658,   153],\n",
       "       [49658,    95],\n",
       "       [49659,    84],\n",
       "       [49660,    83],\n",
       "       [49661,    96],\n",
       "       [49661,    97],\n",
       "       [49662,    98],\n",
       "       [49666,   155],\n",
       "       [49668,   117],\n",
       "       [49670,   118],\n",
       "       [49670,     1],\n",
       "       [49673,    12],\n",
       "       [49673,    13],\n",
       "       [49684,     3],\n",
       "       [49687,   157],\n",
       "       [49688,     2],\n",
       "       [49689,   156],\n",
       "       [49696,     1],\n",
       "       [49706,    14],\n",
       "       [50603,    94],\n",
       "       [51517,    94],\n",
       "       [51534,    71],\n",
       "       [51577,   119],\n",
       "       [52486,   124],\n",
       "       [52491,   120],\n",
       "       [52501,    96],\n",
       "       [53561,    94],\n",
       "       [54056,    70],\n",
       "       [54056,    69],\n",
       "       [54062,    39],\n",
       "       [54062,   154],\n",
       "       [54063,   153],\n",
       "       [54065,    43],\n",
       "       [54065,    44],\n",
       "       [54065,    41],\n",
       "       [54065,    42],\n",
       "       [54065,    40],\n",
       "       [54068,   164],\n",
       "       [54068,   161],\n",
       "       [54069,   163],\n",
       "       [54069,   162],\n",
       "       [54069,    12],\n",
       "       [54070,     1],\n",
       "       [54085,     3],\n",
       "       [54090,     2],\n",
       "       [54093,    13],\n",
       "       [54096,    14],\n",
       "       [54295,    59],\n",
       "       [54299,    62],\n",
       "       [54299,    48],\n",
       "       [54299,    63],\n",
       "       [54300,    49],\n",
       "       [54584,   125],\n",
       "       [54587,   124],\n",
       "       [54713,     8],\n",
       "       [54722,   153],\n",
       "       [54725,   154],\n",
       "       [54728,   155],\n",
       "       [54735,    13],\n",
       "       [54736,    12],\n",
       "       [54750,   156],\n",
       "       [54751,   157],\n",
       "       [54754,   117],\n",
       "       [54768,    14],\n",
       "       [54823,    72],\n",
       "       [54832,   124],\n",
       "       [54837,   125],\n",
       "       [54839,   123],\n",
       "       [55671,    94],\n",
       "       [55687,   124],\n",
       "       [55690,   108],\n",
       "       [55691,   125],\n",
       "       [55692,   126],\n",
       "       [56988,   124],\n",
       "       [57004,    94],\n",
       "       [57015,    99],\n",
       "       [57016,    95],\n",
       "       [57016,    98],\n",
       "       [57016,    96],\n",
       "       [57017,    97],\n",
       "       [57169,   154],\n",
       "       [57170,   153],\n",
       "       [57174,    85],\n",
       "       [57175,    86],\n",
       "       [57176,    87],\n",
       "       [57199,   147],\n",
       "       [57200,    72],\n",
       "       [57203,    71],\n",
       "       [60140,    20],\n",
       "       [60140,    21],\n",
       "       [60151,   158],\n",
       "       [60155,     8],\n",
       "       [60157,   186],\n",
       "       [60159,    39],\n",
       "       [60160,    43],\n",
       "       [60160,    44],\n",
       "       [60160,    40],\n",
       "       [60160,    41],\n",
       "       [60160,    42],\n",
       "       [60163,   154],\n",
       "       [60164,   153],\n",
       "       [60291,   106]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spike_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.19000000e+02  1.54000000e+02             nan ...             nan\n",
      "              nan             nan]\n",
      " [ 6.33000000e+02  6.90000000e+01             nan ...             nan\n",
      "              nan             nan]\n",
      " [ 6.44000000e+02  3.90000000e+01             nan ...             nan\n",
      "              nan             nan]\n",
      " ...\n",
      " [ 6.01630000e+04  1.54000000e+02  9.97000000e+02 ... -1.05675050e+01\n",
      "   5.52986513e+02  8.82855345e+02]\n",
      " [ 6.01640000e+04  1.53000000e+02  9.98000000e+02 ... -1.42797819e+01\n",
      "   7.01050775e+02  1.13987770e+03]\n",
      " [ 6.02910000e+04  1.06000000e+02  9.94000000e+02 ...  2.21320926e+00\n",
      "   3.26309749e+02  4.98952521e+02]]\n"
     ]
    }
   ],
   "source": [
    "# Preallocate the result array\n",
    "spike_output_to_save = np.empty((spike_output.shape[0], 15), dtype=np.float64)\n",
    "spike_output_to_save[:, :] = np.NaN  # Fill with NaNs\n",
    "\n",
    "for i, spike in enumerate(spike_output):\n",
    "    peak_index, channel_index = spike\n",
    "    spike_signal = ieeg_data[peak_index - 1000 : peak_index + 1000, channel_index]\n",
    "\n",
    "    basic_features, advanced_features, is_valid, bad_reason = extract_spike_morphology(\n",
    "        spike_signal\n",
    "    )\n",
    "\n",
    "    # Fill the first two columns with peak_index and channel_index\n",
    "    spike_output_to_save[i, 0] = peak_index\n",
    "    spike_output_to_save[i, 1] = channel_index\n",
    "\n",
    "    if is_valid:\n",
    "        peak, left_point, right_point, slow_end, slow_max = basic_features\n",
    "        (\n",
    "            rise_amp,\n",
    "            decay_amp,\n",
    "            slow_width,\n",
    "            slow_amp,\n",
    "            rise_slope,\n",
    "            decay_slope,\n",
    "            average_amp,\n",
    "            linelen,\n",
    "        ) = advanced_features\n",
    "\n",
    "        # Fill the rest of the columns with computed features\n",
    "        spike_output_to_save[i, 2:7] = basic_features\n",
    "        spike_output_to_save[i, 7:15] = advanced_features\n",
    "\n",
    "spike_output_to_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(spike_output_to_save[:, :2].astype(int), spike_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both sorted arrays are close in value!\n"
     ]
    }
   ],
   "source": [
    "# Load expected_output.npy as expected_output\n",
    "expected_output = np.load(\"expected_output.npy\")\n",
    "\n",
    "# Sort the arrays\n",
    "output_sorted = output[output[:, 0].argsort(kind=\"mergesort\")]\n",
    "output_sorted = output_sorted[output_sorted[:, 1].argsort(kind=\"mergesort\")]\n",
    "\n",
    "expected_output_sorted = expected_output[\n",
    "    expected_output[:, 0].argsort(kind=\"mergesort\")\n",
    "]\n",
    "expected_output_sorted = expected_output_sorted[\n",
    "    expected_output_sorted[:, 1].argsort(kind=\"mergesort\")\n",
    "]\n",
    "\n",
    "# Check if the sorted arrays are close in value\n",
    "if not np.allclose(output_sorted, expected_output_sorted):\n",
    "    for i, (row_out, row_expected) in enumerate(\n",
    "        zip(output_sorted, expected_output_sorted)\n",
    "    ):\n",
    "        if not np.allclose(row_out, row_expected):\n",
    "            print(f\"First differing row after sorting is at index {i}:\")\n",
    "            print(f\"Output: {row_out}\")\n",
    "            print(f\"Expected Output: {row_expected}\")\n",
    "            break\n",
    "else:\n",
    "    print(\"Both sorted arrays are close in value!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique spike sequence indices\n",
    "unique_sequences = np.unique(output[:, 2])\n",
    "\n",
    "# For each unique spike sequence index\n",
    "for seq_index in unique_sequences:\n",
    "    # Filter rows (spikes) that belong to this sequence\n",
    "    spikes_in_sequence = output[output[:, 2] == seq_index]\n",
    "\n",
    "    # Create a new figure for this sequence\n",
    "    fig, axs = plt.subplots(\n",
    "        len(spikes_in_sequence),\n",
    "        1,\n",
    "        sharex=True,\n",
    "        figsize=(8, len(spikes_in_sequence) * 2),\n",
    "    )\n",
    "\n",
    "    # Add a title to the figure\n",
    "    fig.suptitle(f\"Spike sequence {int(seq_index)}\", fontsize=12)\n",
    "\n",
    "    # If there's only one spike in the sequence, axs will not be an array. Convert it to one for consistency.\n",
    "    if len(spikes_in_sequence) == 1:\n",
    "        axs = [axs]\n",
    "\n",
    "    # Plot each spike in this sequence\n",
    "    for i, spike in enumerate(spikes_in_sequence):\n",
    "        peak_location = int(spike[0])\n",
    "        channel_index = int(spike[1])\n",
    "\n",
    "        # Extract the data around the spike peak (500 samples before and after)\n",
    "        start_idx = max(0, peak_location - 200)  # Ensure we don't go below 0\n",
    "        end_idx = min(\n",
    "            len(ieeg_data), peak_location + 200\n",
    "        )  # Ensure we don't exceed dataframe length\n",
    "        data_to_plot = ieeg_data.iloc[start_idx:end_idx, channel_index]\n",
    "\n",
    "        # Plot this spike data\n",
    "        axs[i].plot(data_to_plot.index, data_to_plot.values)\n",
    "\n",
    "        # Add a red vertical dashed line at the location of the peak of the spike\n",
    "        axs[i].axvline(x=peak_location, color=\"red\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "        axs[i].set_title(f\"Channel {labels[channel_index]}\")\n",
    "\n",
    "    # Set shared x-label\n",
    "    axs[-1].set_xlabel(\"Sample Number\")\n",
    "\n",
    "    # Adjust layout for the suptitle\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.95)  # Adjust this value for best appearance\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line Length Spike Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lleventdetector import *\n",
    "from lltransform import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ieeg_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ieeg_data_transposed = ieeg_data.to_numpy().T\n",
    "ieeg_data_transposed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_length_transform = lltransform(ieeg_data_transposed, int(fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_length_detector_result = lleventdetector(line_length_transform, int(fs), 99.9, 15)\n",
    "line_length_detector_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_length_detector_result[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_windows, electrodes_list = line_length_detector_result\n",
    "\n",
    "# Setup colors - if there are more electrodes than colors, they will be reused.\n",
    "colors = plt.cm.jet(np.linspace(0, 1, 200))\n",
    "\n",
    "for window, electrodes in zip(spike_windows, electrodes_list):\n",
    "    start, end = window\n",
    "    start -= 50  # Enlarge window by 50 at the start\n",
    "    end += 50  # and 50 at the end\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Get each electrode number from the comma-separated string, and plot its data.\n",
    "    for elec in electrodes.split(\",\"):\n",
    "        if elec:  # Check if not an empty string\n",
    "            elec_num = int(elec)\n",
    "            plt.plot(\n",
    "                ieeg_data_transposed[elec_num, int(start) : int(end)],\n",
    "                color=colors[elec_num],\n",
    "                label=f\"Electrode {elec_num}\",\n",
    "            )\n",
    "\n",
    "    plt.title(f\"Spike Window: {start}-{end}\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Time (samples)\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for window, electrodes in zip(spike_windows[:15], electrodes_list[:15]):\n",
    "    start, end = window\n",
    "    start -= 100  # Enlarge window by 50 at the start\n",
    "    end += 100  # and 50 at the end\n",
    "\n",
    "    electrode_nums = [int(elec) for elec in electrodes.split(\",\") if elec]\n",
    "\n",
    "    fig, axs = plt.subplots(\n",
    "        len(electrode_nums), 1, sharex=True, figsize=(5, 2 * len(electrode_nums))\n",
    "    )\n",
    "\n",
    "    # If there's only one electrode for this window, axs will not be an array. Convert it to a list for consistency.\n",
    "    if not isinstance(axs, np.ndarray):\n",
    "        axs = [axs]\n",
    "\n",
    "    for ax, elec_num in zip(axs, electrode_nums):\n",
    "        ax.plot(\n",
    "            ieeg_data_transposed[elec_num, int(start) : int(end)],\n",
    "            color=colors[elec_num],\n",
    "        )\n",
    "        ax.set_title(f\"Electrode {good_labels[elec_num]}\")\n",
    "        ax.set_ylabel(\"Amplitude\")\n",
    "\n",
    "    plt.xlabel(\"Time (samples)\")\n",
    "    plt.tight_layout()\n",
    "    fig.suptitle(f\"Spike Window: {start}-{end}\", y=1.02)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
