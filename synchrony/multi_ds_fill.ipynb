{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from ieeg.auth import Session\n",
    "from scipy.signal import resample_poly\n",
    "\n",
    "\n",
    "from get_iEEG_data import *\n",
    "from iEEG_helper_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYNCHRONY_BROADBAND_DIRECTORY = \"../../Data/synchrony/all/broadband_multi_dataset\"\n",
    "SYNCHRONY_BROADBAND_FILL_DIRECTORY = (\n",
    "    \"../../Data/synchrony/all/broadband_multi_dataset_fill\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ../../Data/multi_dataset_batches.csv as a pandas dataframe\n",
    "multi_ds_df = pd.read_csv(\"../../Data/multi_dataset_batches.csv\")\n",
    "# Remove the columns \"batch\", \"size_estimate\"\n",
    "multi_ds_df = multi_ds_df.drop([\"batch\", \"size_estimate\"], axis=1)\n",
    "multi_ds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nan_segments(arr, min_length=240):\n",
    "    nan_segments = []\n",
    "    start_index = None\n",
    "    nan_count = 0\n",
    "\n",
    "    for i, value in enumerate(arr):\n",
    "        if np.isnan(value):\n",
    "            nan_count += 1\n",
    "            if start_index is None:\n",
    "                start_index = i\n",
    "        else:\n",
    "            if nan_count >= min_length:\n",
    "                nan_segments.append((start_index, i - 1))\n",
    "            start_index = None\n",
    "            nan_count = 0\n",
    "\n",
    "    # Check for the case where the array ends with a NaN segment\n",
    "    if nan_count >= min_length:\n",
    "        nan_segments.append((start_index, len(arr) - 1))\n",
    "\n",
    "    return nan_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Using Carlos session\")\n",
    "with open(\"agu_ieeglogin.bin\", \"r\") as f:\n",
    "    session = Session(\"aguilac\", f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through all files in SYNCHRONY_BROADBAND_DIRECTORY\n",
    "for filename in os.listdir(SYNCHRONY_BROADBAND_DIRECTORY):\n",
    "    # load only .npy files\n",
    "    if filename.endswith(\".npy\"):\n",
    "        # Filenames are in the format of HUP_{hup_id}_ds_{ds_index}.npy\n",
    "        hup_id = filename.split(\"_\")[1]\n",
    "        if int(hup_id) % 4 == 0:\n",
    "            # Find the row in multi_ds_df that has the same hup_id\n",
    "            row = multi_ds_df.loc[multi_ds_df[\"hup_id\"] == int(hup_id)]\n",
    "            min_sampling_rate = int(row[\"min_sampling_rate\"])\n",
    "            ds_index = filename.split(\"_\")[3].split(\".\")[0]\n",
    "            # Load the data\n",
    "            og_data = np.load(os.path.join(SYNCHRONY_BROADBAND_DIRECTORY, filename))\n",
    "            # Find NaN segments\n",
    "            nan_segments = find_nan_segments(og_data)\n",
    "            # If the first element of the first tuple in nan_segments is 0, then delete the first tuple\n",
    "            if nan_segments[0][0] == 0:\n",
    "                nan_segments = nan_segments[1:]\n",
    "            if len(nan_segments) == 1:\n",
    "                print(f\"Filling incomplete data for HUP {hup_id} DS {ds_index}...\")\n",
    "                print(nan_segments)\n",
    "                for segment in nan_segments:\n",
    "                    print(f\"Segment: {segment}\")\n",
    "                    segment_start = segment[0]\n",
    "                    segment_end = segment[1]\n",
    "                    dataset_name = f\"HUP{hup_id}_phaseII_D0{ds_index}\"\n",
    "                    dataset = session.open_dataset(dataset_name)\n",
    "\n",
    "                    all_channel_labels = np.array(dataset.get_channel_labels())\n",
    "                    channel_labels_to_download = all_channel_labels[\n",
    "                        electrode_selection(all_channel_labels)\n",
    "                    ]\n",
    "\n",
    "                    duration_usec = dataset.get_time_series_details(\n",
    "                        channel_labels_to_download[0]\n",
    "                    ).duration\n",
    "                    duration_hours = int(duration_usec / 1000000 / 60 / 60)\n",
    "                    enlarged_duration_hours = duration_hours + 24\n",
    "\n",
    "                    print(\n",
    "                        f\"Opening {dataset_name} with duration {duration_hours} hours\"\n",
    "                    )\n",
    "\n",
    "                    # Calculate the total number of 2-minute intervals in the enlarged duration\n",
    "                    total_intervals = (\n",
    "                        enlarged_duration_hours * 30\n",
    "                    )  # 60min/hour / 2min = 30\n",
    "\n",
    "                    synchrony_broadband_vector_to_save = np.full(\n",
    "                        total_intervals, np.nan\n",
    "                    )\n",
    "\n",
    "                    # Loop through each 2-minute interval\n",
    "                    for interval in range(segment_start, segment_end + 1):\n",
    "                        print(\n",
    "                            f\"Getting iEEG data for interval {interval} out of {total_intervals}\"\n",
    "                        )\n",
    "                        duration_usec = 1.2e8  # 2 minutes\n",
    "                        start_time_usec = (\n",
    "                            interval * 2 * 60 * 1e6\n",
    "                        )  # 2 minutes in microseconds\n",
    "                        stop_time_usec = start_time_usec + duration_usec\n",
    "\n",
    "                        try:\n",
    "                            ieeg_data, fs = get_iEEG_data(\n",
    "                                \"aguilac\",\n",
    "                                \"agu_ieeglogin.bin\",\n",
    "                                dataset_name,\n",
    "                                start_time_usec,\n",
    "                                stop_time_usec,\n",
    "                                channel_labels_to_download,\n",
    "                            )\n",
    "                            fs = int(fs)\n",
    "                        except Exception as e:\n",
    "                            # handle the exception\n",
    "                            print(f\"Error: {e}\")\n",
    "                            break\n",
    "\n",
    "                        # Drop rows that has any nan\n",
    "                        ieeg_data = ieeg_data.dropna(axis=0, how=\"any\")\n",
    "                        if ieeg_data.empty:\n",
    "                            print(\"Empty dataframe after dropping nan, skip...\")\n",
    "                            continue\n",
    "\n",
    "                        good_channels_res = detect_bad_channels_optimized(\n",
    "                            ieeg_data.to_numpy(), fs\n",
    "                        )\n",
    "                        good_channel_indicies = good_channels_res[0]\n",
    "                        good_channel_labels = channel_labels_to_download[\n",
    "                            good_channel_indicies\n",
    "                        ]\n",
    "                        ieeg_data = ieeg_data[good_channel_labels].to_numpy()\n",
    "\n",
    "                        if fs > min_sampling_rate:\n",
    "                            up = min_sampling_rate  # Upsampling rate\n",
    "                            down = fs  # Downsampling rate\n",
    "                            ieeg_data = resample_poly(ieeg_data, up, down, axis=1)\n",
    "                            fs = min_sampling_rate\n",
    "\n",
    "                        # Check if ieeg_data is empty after dropping bad channels\n",
    "                        if ieeg_data.size == 0:\n",
    "                            print(\n",
    "                                \"Empty dataframe after dropping bad channels, skip...\"\n",
    "                            )\n",
    "                            continue\n",
    "\n",
    "                        ieeg_data = common_average_montage(ieeg_data)\n",
    "\n",
    "                        # Apply the filters directly on the DataFrame\n",
    "                        ieeg_data = notch_filter(ieeg_data, 59, 61, fs)\n",
    "\n",
    "                        ##############################\n",
    "                        # Calculate synchrony (broadband)\n",
    "                        ##############################\n",
    "                        _, R = calculate_synchrony(ieeg_data.T)\n",
    "                        synchrony_broadband_vector_to_save[interval] = R\n",
    "\n",
    "                        print(f\"Finished calculating synchrony for interval {interval}\")\n",
    "\n",
    "                    ##############################\n",
    "                    # Save the synchrony output\n",
    "                    ##############################\n",
    "                    np.save(\n",
    "                        os.path.join(\n",
    "                            SYNCHRONY_BROADBAND_FILL_DIRECTORY,\n",
    "                            f\"HUP_{hup_id}_ds_{ds_index}_{segment_start}_{segment_end}.npy\",\n",
    "                        ),\n",
    "                        synchrony_broadband_vector_to_save,\n",
    "                    )\n",
    "                    print(\n",
    "                        f\"Saved HUP_{hup_id}_ds_{ds_index}_{segment_start}_{segment_end}.npy\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook multi_ds_fill.ipynb to python\n",
      "[NbConvertApp] Writing 7780 bytes to multi_ds_fill.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to python multi_ds_fill.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
