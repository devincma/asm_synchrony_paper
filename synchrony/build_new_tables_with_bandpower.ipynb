{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build giant tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scipy.io\n",
    "from scipy.stats import iqr\n",
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load HUP_implant_dates.xlsx\n",
    "patients_df = pd.read_excel(\"../../Data/HUP_implant_dates.xlsx\")\n",
    "patients_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping between patient ids and the index of the patient in the patients_df dataframe\n",
    "patient_hup_id_to_index = {}\n",
    "for i, patient_id in enumerate(patients_df[\"hup_id\"]):\n",
    "    patient_hup_id_to_index[patient_id] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patient_hup_ids(directory):\n",
    "    # List all files in the directory\n",
    "    files = os.listdir(directory)\n",
    "\n",
    "    # Filter out files based on the given pattern and extract patient_hup_id as integers\n",
    "    patient_hup_ids = [\n",
    "        int(f.split(\"_\")[1].split(\".\")[0])\n",
    "        for f in files\n",
    "        if f.startswith(\"HUP_\") and f.endswith(\".npy\")\n",
    "    ]\n",
    "\n",
    "    return patient_hup_ids\n",
    "\n",
    "\n",
    "directory = \"../../Data/synchrony/all/broadband/\"\n",
    "completed_hup_ids = get_patient_hup_ids(directory)\n",
    "completed_hup_ids.sort()\n",
    "print(completed_hup_ids)\n",
    "len(completed_hup_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep the rows in patients_df that correspond to the completed_hup_ids\n",
    "patients_df = patients_df[patients_df[\"hup_id\"].isin(completed_hup_ids)]\n",
    "# reset the index of patients_df\n",
    "patients_df = patients_df.reset_index(drop=True)\n",
    "patients_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ieeg_offset_df = pd.read_excel(\"../../Data/ieeg_offset_new.xlsx\")\n",
    "ieeg_offset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_med_names = []\n",
    "\n",
    "for i, row in patients_df.iterrows():\n",
    "    # Get patient id and weight\n",
    "    patient_hup_id = row.hup_id\n",
    "\n",
    "    # Load HUP_{patient_hup_id}.npy from ../../Data/medications\n",
    "    aed_np_file = np.load(\n",
    "        f\"../../Data/medications/HUP_{patient_hup_id}.npy\", allow_pickle=True\n",
    "    )\n",
    "\n",
    "    all_dose_curves_plot = aed_np_file[0]\n",
    "    all_tHr_plot = aed_np_file[1]\n",
    "    all_med_names_plot = aed_np_file[2]\n",
    "\n",
    "    # Plot dose curves\n",
    "    for med_name in all_med_names_plot:\n",
    "        all_med_names.append(med_name)\n",
    "\n",
    "all_med_names = np.unique(np.array(all_med_names, dtype=str))\n",
    "all_med_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load aed_ref_ranges.xlsx from ./data/\n",
    "aed_ref_ranges_df = pd.read_excel(\"../../Data/aed_ref_ranges.xlsx\")\n",
    "# Lowercase Drug column\n",
    "aed_ref_ranges_df[\"Drug\"] = aed_ref_ranges_df[\"Drug\"].str.lower()\n",
    "# show unique units\n",
    "print(aed_ref_ranges_df[\"Unit\"].unique())\n",
    "# mg/L and ug/mL are the same\n",
    "# If Unit is ng/mL, convert to ug/mL\n",
    "aed_ref_ranges_df.loc[aed_ref_ranges_df[\"Unit\"] == \"ng/mL\", \"Min\"] = (\n",
    "    aed_ref_ranges_df[\"Min\"] / 1000\n",
    ")\n",
    "aed_ref_ranges_df.loc[aed_ref_ranges_df[\"Unit\"] == \"ng/mL\", \"Max\"] = (\n",
    "    aed_ref_ranges_df[\"Max\"] / 1000\n",
    ")\n",
    "# Add a column that takes the average of Min and Max\n",
    "aed_ref_ranges_df[\"Avg\"] = (aed_ref_ranges_df[\"Min\"] + aed_ref_ranges_df[\"Max\"]) / 2\n",
    "aed_ref_ranges_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency_bands = [\"broadband\", \"60_100\", \"100_125\"]\n",
    "frequency_bands = [\"broadband\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in patients_df.iterrows():\n",
    "    # Get patient id and weight\n",
    "    patient_hup_id, patient_weight = row.hup_id, row.weight_kg\n",
    "    patient_idx = patient_hup_id_to_index[patient_hup_id]\n",
    "    print(f\"Processing HUP {patient_hup_id}\")\n",
    "\n",
    "    # Find the ieeg_offset_1 value for patient_hup_id in ieeg_offset_df and convert it into float\n",
    "    ieeg_offset_seconds = float(\n",
    "        ieeg_offset_df.loc[\n",
    "            ieeg_offset_df[\"hup_id\"] == patient_hup_id, \"ieeg_offset_1\"\n",
    "        ].values[0]\n",
    "    )\n",
    "    print(f\"ieeg_offset_seconds: {ieeg_offset_seconds}\")\n",
    "    ieeg_offset_minutes = ieeg_offset_seconds / 60\n",
    "\n",
    "    ##############################################\n",
    "    # MEDICATIONS\n",
    "    ##############################################\n",
    "    # Load HUP_{patient_hup_id}.npy from ../../Data/medications\n",
    "    aed_np_file = np.load(\n",
    "        f\"../../Data/medications/HUP_{patient_hup_id}.npy\", allow_pickle=True\n",
    "    )\n",
    "\n",
    "    all_dose_curves_plot = aed_np_file[0]\n",
    "    all_tHr_plot = aed_np_file[1]\n",
    "    all_med_names_plot = aed_np_file[2]\n",
    "\n",
    "    # Construct the time axis\n",
    "    emu_start_time_hrs = min([all_tHr_plot[i][0] for i in range(len(all_tHr_plot))])\n",
    "    emu_end_time_hrs = all_tHr_plot[0][-1]\n",
    "    max_length = max([len(all_tHr_plot[i]) for i in range(len(all_tHr_plot))])\n",
    "    time_axis = np.linspace(emu_start_time_hrs, emu_end_time_hrs, max_length)\n",
    "\n",
    "    first_emu_hr = time_axis[0]\n",
    "\n",
    "    # Create a dataframe that will hold the dose curves for all patients\n",
    "    hourly_patient_features_df = pd.DataFrame(columns=[\"emu_time\"])\n",
    "    hourly_patient_features_df[\"emu_time\"] = time_axis\n",
    "\n",
    "    for potential_med_name in all_med_names:\n",
    "        hourly_patient_features_df[f\"med_{potential_med_name}_raw\"] = np.zeros(\n",
    "            len(time_axis)\n",
    "        )\n",
    "\n",
    "    sum_array = []\n",
    "\n",
    "    ##############################################\n",
    "    # MEDICATIONS Normalize to 1\n",
    "    ##############################################\n",
    "    for med_idx, med_name in enumerate(all_med_names_plot):\n",
    "        dose_times = all_tHr_plot[med_idx].flatten()\n",
    "        dose = all_dose_curves_plot[med_idx].flatten()\n",
    "\n",
    "        interp_func = interpolate.interp1d(\n",
    "            dose_times, dose, bounds_error=False, fill_value=0\n",
    "        )\n",
    "        dose_interp = interp_func(time_axis)\n",
    "\n",
    "        if med_name != \"lorazepam\":\n",
    "            sum_array.append(dose_interp)\n",
    "\n",
    "        hourly_patient_features_df[f\"med_{med_name}_raw\"] = dose_interp\n",
    "\n",
    "    cumulative_dose_curve = np.sum(sum_array, axis=0)\n",
    "    cumulative_dose_curve = cumulative_dose_curve / np.max(cumulative_dose_curve)\n",
    "\n",
    "    assert len(cumulative_dose_curve) == len(\n",
    "        time_axis\n",
    "    ), \"cumulative_dose_curve and time_axis should have the same length\"\n",
    "\n",
    "    hourly_patient_features_df[\"med_sum_no_lorazepam_raw\"] = cumulative_dose_curve\n",
    "\n",
    "    ##############################################\n",
    "    # MEDICATIONS Normalize with DDD\n",
    "    ##############################################\n",
    "    for med_idx, med_name in enumerate(all_med_names_plot):\n",
    "        dose_times = all_tHr_plot[med_idx].flatten()\n",
    "\n",
    "        # Find Avg for medication med_name in aed_ref_ranges_df\n",
    "        if med_name != \"lorazepam\":\n",
    "            ref_range = float(\n",
    "                aed_ref_ranges_df.loc[\n",
    "                    aed_ref_ranges_df[\"Drug\"] == med_name, \"Avg\"\n",
    "                ].values[0]\n",
    "            )\n",
    "        else:\n",
    "            ref_range = 1\n",
    "\n",
    "        dose = all_dose_curves_plot[med_idx].flatten()\n",
    "        dose = dose / ref_range\n",
    "\n",
    "        interp_func = interpolate.interp1d(\n",
    "            dose_times, dose, bounds_error=False, fill_value=0\n",
    "        )\n",
    "        dose_interp = interp_func(time_axis)\n",
    "\n",
    "        if med_name != \"lorazepam\":\n",
    "            sum_array.append(dose_interp)\n",
    "\n",
    "        hourly_patient_features_df[f\"med_{med_name}_raw\"] = dose_interp\n",
    "\n",
    "    cumulative_dose_curve = np.sum(sum_array, axis=0)\n",
    "\n",
    "    assert len(cumulative_dose_curve) == len(\n",
    "        time_axis\n",
    "    ), \"cumulative_dose_curve and time_axis should have the same length\"\n",
    "\n",
    "    hourly_patient_features_df[\"med_sum_no_lorazepam_ddd\"] = cumulative_dose_curve\n",
    "\n",
    "    ##############################################\n",
    "    # Group by 2 minutes and compute mean\n",
    "    ##############################################\n",
    "    hourly_patient_features_df[\"emu_minute\"] = (\n",
    "        (hourly_patient_features_df[\"emu_time\"] * 60).astype(int) // 2 * 2\n",
    "    )\n",
    "    hourly_patient_features_df = hourly_patient_features_df.groupby(\"emu_minute\").mean()\n",
    "    hourly_patient_features_df = hourly_patient_features_df.reset_index()\n",
    "    hourly_patient_features_df = hourly_patient_features_df.drop(columns=[\"emu_time\"])\n",
    "\n",
    "    ##############################################\n",
    "    # SEIZURE COUNT\n",
    "    ##############################################\n",
    "    seizure_times_sec = np.load(\n",
    "        f\"../../Data/seizures/source_mat/HUP_{patient_hup_id}.npy\"\n",
    "    )\n",
    "    seizure_times_sec = seizure_times_sec + ieeg_offset_seconds\n",
    "\n",
    "    # Convert seizure times from seconds to minutes\n",
    "    seizure_times_min = seizure_times_sec / 60\n",
    "\n",
    "    hourly_patient_features_df[\"had_seizure\"] = np.zeros(\n",
    "        len(hourly_patient_features_df), dtype=int\n",
    "    )\n",
    "\n",
    "    for sz_min in seizure_times_min[:, 0]:\n",
    "        hourly_patient_features_df.loc[\n",
    "            hourly_patient_features_df[\"emu_minute\"] == int(sz_min) // 2 * 2,\n",
    "            \"had_seizure\",\n",
    "        ] += 1\n",
    "\n",
    "    ##############################################\n",
    "    # Time since last seizure\n",
    "    ##############################################\n",
    "    # Initialize the list and timer\n",
    "    time_since_last_seizure = []\n",
    "    timer = None\n",
    "\n",
    "    # Loop through the dataframe and calculate the time since the last seizure\n",
    "    for had_seizure in hourly_patient_features_df[\"had_seizure\"]:\n",
    "        if had_seizure == 1:\n",
    "            timer = 0\n",
    "        elif timer is not None:  # if there has been a seizure before\n",
    "            timer += 2\n",
    "        else:\n",
    "            timer = None\n",
    "        time_since_last_seizure.append(timer)\n",
    "\n",
    "    # Add the list as a new column\n",
    "    hourly_patient_features_df[\"time_since_last_seizure\"] = time_since_last_seizure\n",
    "\n",
    "    ##########################################\n",
    "    # SYNCHRONY\n",
    "    ##########################################\n",
    "\n",
    "    # Determine the starting index for the synchrony data\n",
    "    start_index = None\n",
    "    for i, emu_min in enumerate(hourly_patient_features_df[\"emu_minute\"]):\n",
    "        if i < len(hourly_patient_features_df[\"emu_minute\"]) - 1:\n",
    "            next_emu_min = hourly_patient_features_df[\"emu_minute\"].iloc[i + 1]\n",
    "        else:\n",
    "            next_emu_min = emu_min + 2\n",
    "\n",
    "        if emu_min <= ieeg_offset_minutes < next_emu_min:\n",
    "            start_index = i\n",
    "            break\n",
    "\n",
    "    if start_index is None:\n",
    "        print(\"start_index is actually 0...\")\n",
    "        start_index = 0\n",
    "\n",
    "    for frequency_band in frequency_bands:\n",
    "        synchrony_np = np.load(\n",
    "            f\"../../Data/synchrony/all/{frequency_band}/HUP_{patient_hup_id}.npy\"\n",
    "        )\n",
    "\n",
    "        # Initialize the synchrony column with NaNs\n",
    "        hourly_patient_features_df[f\"synchrony_{frequency_band}\"] = np.nan\n",
    "\n",
    "        # Insert synchrony values starting from the appropriate index\n",
    "        end_index = min(\n",
    "            start_index + len(synchrony_np), len(hourly_patient_features_df)\n",
    "        )\n",
    "        hourly_patient_features_df.iloc[\n",
    "            start_index:end_index,\n",
    "            hourly_patient_features_df.columns.get_loc(f\"synchrony_{frequency_band}\"),\n",
    "        ] = synchrony_np[: end_index - start_index]\n",
    "\n",
    "    ##########################################\n",
    "    # AD Ratio\n",
    "    ##########################################\n",
    "    mat_file = scipy.io.loadmat(\n",
    "        f\"../../../erinconr/projects/fc_toolbox/results/analysis/intermediate/HUP{patient_hup_id}.mat\"\n",
    "    )\n",
    "    mat_file = mat_file[\"summ\"][0][0]\n",
    "    ad_ratio = mat_file[17]\n",
    "    num_channels = mat_file[6].shape[0]\n",
    "    assert ad_ratio.shape[0] == num_channels\n",
    "\n",
    "    ad_ratio = np.nanmean(ad_ratio, axis=0)\n",
    "    ad_ratio = (ad_ratio - np.nanmedian(ad_ratio)) / iqr(ad_ratio, nan_policy=\"omit\")\n",
    "    assert np.nansum(ad_ratio) != 0\n",
    "\n",
    "    # Reshape ad_ratio to match the granularity of the dataframe\n",
    "    reshaped_ad_ratio = np.repeat(ad_ratio, 5)\n",
    "\n",
    "    # Initialize the ad_ratio column with NaNs\n",
    "    hourly_patient_features_df[\"ad_ratio\"] = np.nan\n",
    "\n",
    "    # Insert reshaped_ad_ratio values starting from the appropriate index\n",
    "    end_index_ad_ratio = min(\n",
    "        start_index + len(reshaped_ad_ratio), len(hourly_patient_features_df)\n",
    "    )\n",
    "    hourly_patient_features_df.iloc[\n",
    "        start_index:end_index_ad_ratio,\n",
    "        hourly_patient_features_df.columns.get_loc(\"ad_ratio\"),\n",
    "    ] = reshaped_ad_ratio[: end_index_ad_ratio - start_index]\n",
    "\n",
    "    ##########################################\n",
    "    # EEG time\n",
    "    ##########################################\n",
    "    # Create the eeg_time column with NaN values\n",
    "    hourly_patient_features_df[\"eeg_time\"] = np.nan\n",
    "\n",
    "    # Define the eeg_time values starting from start_index\n",
    "    eeg_time_values = np.arange(\n",
    "        0, (end_index_ad_ratio - start_index) * 2, 2\n",
    "    )  # incrementing by 2 since the time is grouped by 2 minutes\n",
    "    hourly_patient_features_df.iloc[\n",
    "        start_index:end_index_ad_ratio,\n",
    "        hourly_patient_features_df.columns.get_loc(\"eeg_time\"),\n",
    "    ] = eeg_time_values\n",
    "\n",
    "    ##############################################\n",
    "    # SAVE TO CSV\n",
    "    ##############################################\n",
    "\n",
    "    hourly_patient_features_df.to_csv(\n",
    "        f\"../../Data/giant_new_tables/HUP_{patient_hup_id}.csv\", index=False\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
