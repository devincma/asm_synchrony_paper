{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For HUP 146 and 162"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from ieeg.auth import Session\n",
    "\n",
    "from get_iEEG_data import *\n",
    "from iEEG_helper_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYNCHRONY_BROADBAND_DIRECTORY = \"../../Data/synchrony/all/broadband\"\n",
    "SYNCHRONY_BROADBAND_FILL_DIRECTORY = \"../../Data/synchrony/all/broadband_fill\"\n",
    "KEEP_FILLING_DIRECTORY = \"../../Data/synchrony/all/keep_filling\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nan_segments(arr, min_length=240):\n",
    "    nan_segments = []\n",
    "    start_index = None\n",
    "    nan_count = 0\n",
    "\n",
    "    for i, value in enumerate(arr):\n",
    "        if np.isnan(value):\n",
    "            nan_count += 1\n",
    "            if start_index is None:\n",
    "                start_index = i\n",
    "        else:\n",
    "            if nan_count >= min_length:\n",
    "                nan_segments.append((start_index, i - 1))\n",
    "            start_index = None\n",
    "            nan_count = 0\n",
    "\n",
    "    # Check for the case where the array ends with a NaN segment\n",
    "    if nan_count >= min_length:\n",
    "        nan_segments.append((start_index, len(arr) - 1))\n",
    "\n",
    "    return nan_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Using Carlos session\")\n",
    "with open(\"agu_ieeglogin.bin\", \"r\") as f:\n",
    "    session = Session(\"aguilac\", f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hup_id = 146\n",
    "filename = f\"HUP_{hup_id}.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "array_to_fill = np.load(os.path.join(SYNCHRONY_BROADBAND_DIRECTORY, filename))\n",
    "# Find NaN segments\n",
    "nan_segments = find_nan_segments(array_to_fill)\n",
    "# If the first element of the first tuple in nan_segments is 0, then delete the first tuple\n",
    "if nan_segments[0][0] == 0:\n",
    "    nan_segments = nan_segments[1:]\n",
    "\n",
    "while len(nan_segments) == 1:\n",
    "    print(f\"Filling incomplete data for HUP {hup_id}...\")\n",
    "    print(nan_segments)\n",
    "    for segment in nan_segments:\n",
    "        print(f\"Segment: {segment}\")\n",
    "        segment_start = segment[0]\n",
    "        segment_end = segment[1]\n",
    "        if os.path.exists(\n",
    "            os.path.join(\n",
    "                SYNCHRONY_BROADBAND_FILL_DIRECTORY,\n",
    "                f\"HUP_{hup_id}_{segment_start}_{segment_end}.npy\",\n",
    "            )\n",
    "        ):\n",
    "            print(f\"HUP_{hup_id}_{segment_start}_{segment_end}.npy exists, skip...\")\n",
    "            continue\n",
    "        dataset_name = f\"HUP{hup_id}_phaseII\"\n",
    "        dataset = session.open_dataset(dataset_name)\n",
    "\n",
    "        all_channel_labels = np.array(dataset.get_channel_labels())\n",
    "        channel_labels_to_download = all_channel_labels[\n",
    "            electrode_selection(all_channel_labels)\n",
    "        ]\n",
    "\n",
    "        duration_usec = dataset.get_time_series_details(\n",
    "            channel_labels_to_download[0]\n",
    "        ).duration\n",
    "        duration_hours = int(duration_usec / 1000000 / 60 / 60)\n",
    "        enlarged_duration_hours = duration_hours + 24\n",
    "\n",
    "        print(f\"Opening {dataset_name} with duration {duration_hours} hours\")\n",
    "\n",
    "        # Calculate the total number of 2-minute intervals in the enlarged duration\n",
    "        total_intervals = enlarged_duration_hours * 30  # 60min/hour / 2min = 30\n",
    "\n",
    "        fill_chunck = np.full(total_intervals, np.nan)\n",
    "\n",
    "        # Loop through each 2-minute interval\n",
    "        for interval in range(segment_start, segment_end + 1):\n",
    "            print(f\"Getting iEEG data for interval {interval} out of {total_intervals}\")\n",
    "            duration_usec = 1.2e8  # 2 minutes\n",
    "            start_time_usec = interval * 2 * 60 * 1e6  # 2 minutes in microseconds\n",
    "            stop_time_usec = start_time_usec + duration_usec\n",
    "\n",
    "            try:\n",
    "                ieeg_data, fs = get_iEEG_data(\n",
    "                    \"aguilac\",\n",
    "                    \"agu_ieeglogin.bin\",\n",
    "                    dataset_name,\n",
    "                    start_time_usec,\n",
    "                    stop_time_usec,\n",
    "                    channel_labels_to_download,\n",
    "                )\n",
    "                fs = int(fs)\n",
    "            except Exception as e:\n",
    "                # handle the exception\n",
    "                print(f\"Error: {e}\")\n",
    "                break\n",
    "\n",
    "            # Drop rows that has any nan\n",
    "            ieeg_data = ieeg_data.dropna(axis=0, how=\"any\")\n",
    "            if ieeg_data.empty:\n",
    "                print(\"Empty dataframe after dropping nan, skip...\")\n",
    "                continue\n",
    "\n",
    "            good_channels_res = detect_bad_channels_optimized(ieeg_data.to_numpy(), fs)\n",
    "            good_channel_indicies = good_channels_res[0]\n",
    "            good_channel_labels = channel_labels_to_download[good_channel_indicies]\n",
    "            ieeg_data = ieeg_data[good_channel_labels].to_numpy()\n",
    "\n",
    "            # Check if ieeg_data is empty after dropping bad channels\n",
    "            if ieeg_data.size == 0:\n",
    "                print(\"Empty dataframe after dropping bad channels, skip...\")\n",
    "                continue\n",
    "\n",
    "            ieeg_data = common_average_montage(ieeg_data)\n",
    "\n",
    "            # Apply the filters directly on the DataFrame\n",
    "            ieeg_data = notch_filter(ieeg_data, 59, 61, fs)\n",
    "\n",
    "            ##############################\n",
    "            # Calculate synchrony (broadband)\n",
    "            ##############################\n",
    "            _, R = calculate_synchrony(ieeg_data.T)\n",
    "            fill_chunck[interval] = R\n",
    "\n",
    "            print(f\"Finished calculating synchrony for interval {interval}\")\n",
    "\n",
    "        ##############################\n",
    "        # Save the synchrony output\n",
    "        ##############################\n",
    "\n",
    "        print(f\"Finished HUP_{hup_id}_{segment_start}_{segment_end}.npy\")\n",
    "\n",
    "        if np.isnan(fill_chunck).all():\n",
    "            continue\n",
    "\n",
    "        # Count number of non-nan values\n",
    "        num_non_nan = np.count_nonzero(~np.isnan(fill_chunck))\n",
    "\n",
    "        # count the number of non-nan values in the original array\n",
    "        num_non_nan_og = np.count_nonzero(~np.isnan(array_to_fill))\n",
    "        assert array_to_fill.shape == fill_chunck.shape\n",
    "\n",
    "        array_to_fill[np.isnan(array_to_fill)] = fill_chunck[np.isnan(array_to_fill)]\n",
    "        assert (\n",
    "            np.count_nonzero(~np.isnan(array_to_fill)) == num_non_nan_og + num_non_nan\n",
    "        )\n",
    "\n",
    "        # Find NaN segments\n",
    "        nan_segments = find_nan_segments(array_to_fill)\n",
    "        # If the first element of the first tuple in nan_segments is 0, then delete the first tuple\n",
    "        if nan_segments[0][0] == 0:\n",
    "            nan_segments = nan_segments[1:]\n",
    "\n",
    "print(f\"Saving HUP_{hup_id}.npy\")\n",
    "np.save(os.path.join(KEEP_FILLING_DIRECTORY, filename), array_to_fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook keep_filling.ipynb to python\n",
      "[NbConvertApp] Writing 6157 bytes to keep_filling.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to python keep_filling.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
