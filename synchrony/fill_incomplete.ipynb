{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from ieeg.auth import Session\n",
    "\n",
    "from get_iEEG_data import *\n",
    "from iEEG_helper_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYNCHRONY_BROADBAND_DIRECTORY = \"../../Data/synchrony/all/broadband\"\n",
    "SYNCHRONY_BROADBAND_FILL_DIRECTORY = \"../../Data/synchrony/all/broadband_fill\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nan_segments(arr, min_length=240):\n",
    "    nan_segments = []\n",
    "    start_index = None\n",
    "    nan_count = 0\n",
    "\n",
    "    for i, value in enumerate(arr):\n",
    "        if np.isnan(value):\n",
    "            nan_count += 1\n",
    "            if start_index is None:\n",
    "                start_index = i\n",
    "        else:\n",
    "            if nan_count >= min_length:\n",
    "                nan_segments.append((start_index, i - 1))\n",
    "            start_index = None\n",
    "            nan_count = 0\n",
    "\n",
    "    # Check for the case where the array ends with a NaN segment\n",
    "    if nan_count >= min_length:\n",
    "        nan_segments.append((start_index, len(arr) - 1))\n",
    "\n",
    "    return nan_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Carlos session\n"
     ]
    }
   ],
   "source": [
    "print(\"Using Carlos session\")\n",
    "with open(\"agu_ieeglogin.bin\", \"r\") as f:\n",
    "    session = Session(\"aguilac\", f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling incomplete data for HUP 178...\n",
      "[(3312, 6269)]\n",
      "Filling incomplete data for HUP 171...\n",
      "[(718, 9299)]\n",
      "Filling incomplete data for HUP 192...\n",
      "[(5459, 6419)]\n",
      "Filling incomplete data for HUP 143...\n",
      "[(545, 7889)]\n",
      "Filling incomplete data for HUP 144...\n",
      "[(4917, 5609)]\n",
      "Filling incomplete data for HUP 138...\n",
      "[(5174, 5879)]\n",
      "Filling incomplete data for HUP 221...\n",
      "[(4164, 4859)]\n",
      "Filling incomplete data for HUP 155...\n",
      "[(1276, 5939)]\n",
      "Filling incomplete data for HUP 184...\n",
      "[(4384, 5099)]\n",
      "Filling incomplete data for HUP 160...\n",
      "[(8175, 10769)]\n",
      "Filling incomplete data for HUP 169...\n",
      "[(5933, 7049)]\n",
      "Filling incomplete data for HUP 145...\n",
      "[(7808, 8579)]\n",
      "Filling incomplete data for HUP 139...\n",
      "[(4119, 8489)]\n",
      "Filling incomplete data for HUP 142...\n",
      "[(9324, 10049)]\n",
      "Filling incomplete data for HUP 177...\n",
      "[(5236, 6479)]\n",
      "Filling incomplete data for HUP 170...\n",
      "[(4238, 4949)]\n",
      "Filling incomplete data for HUP 204...\n",
      "[(3667, 4379)]\n",
      "Filling incomplete data for HUP 161...\n",
      "[(2999, 9389)]\n",
      "Filling incomplete data for HUP 166...\n",
      "[(4916, 5609)]\n",
      "Filling incomplete data for HUP 154...\n",
      "[(2078, 2789)]\n",
      "Filling incomplete data for HUP 207...\n",
      "[(9890, 10589)]\n",
      "Filling incomplete data for HUP 165...\n",
      "[(6046, 14489)]\n",
      "Filling incomplete data for HUP 162...\n",
      "[(537, 9809)]\n",
      "Filling incomplete data for HUP 157...\n",
      "[(1737, 6419)]\n",
      "Filling incomplete data for HUP 186...\n",
      "[(6313, 7199)]\n",
      "Filling incomplete data for HUP 150...\n",
      "[(3400, 4109)]\n",
      "Filling incomplete data for HUP 188...\n",
      "[(2753, 4889)]\n",
      "Filling incomplete data for HUP 199...\n",
      "[(4441, 5159)]\n",
      "Filling incomplete data for HUP 223...\n",
      "[(4054, 4769)]\n",
      "Filling incomplete data for HUP 190...\n",
      "[(9188, 9899)]\n",
      "Filling incomplete data for HUP 141...\n",
      "[(4392, 5099)]\n",
      "Filling incomplete data for HUP 146...\n",
      "[(706, 11639)]\n",
      "Filling incomplete data for HUP 173...\n",
      "[(7120, 7829)]\n",
      "Filling incomplete data for HUP 158...\n",
      "[(5114, 5819)]\n",
      "Filling incomplete data for HUP 189...\n",
      "[(2299, 2999)]\n",
      "Filling incomplete data for HUP 151...\n",
      "[(5619, 6329)]\n",
      "Filling incomplete data for HUP 187...\n",
      "[(5215, 6029)]\n",
      "Filling incomplete data for HUP 163...\n",
      "[(4120, 9539)]\n",
      "Filling incomplete data for HUP 164...\n",
      "[(2194, 5549)]\n",
      "Filling incomplete data for HUP 206...\n",
      "[(1065, 11249)]\n",
      "Filling incomplete data for HUP 217...\n",
      "[(5797, 12659)]\n",
      "Filling incomplete data for HUP 175...\n",
      "[(1440, 2159)]\n",
      "Filling incomplete data for HUP 219...\n",
      "[(1829, 2549)]\n",
      "Filling incomplete data for HUP 225...\n",
      "[(2514, 5759)]\n"
     ]
    }
   ],
   "source": [
    "# Iterate through all files in SYNCHRONY_BROADBAND_DIRECTORY\n",
    "for filename in os.listdir(SYNCHRONY_BROADBAND_DIRECTORY):\n",
    "    # load only .npy files\n",
    "    if filename.endswith(\".npy\"):\n",
    "        # Filenames are in the format of HUP_{patient_id}.npy\n",
    "        hup_id = filename.split(\"_\")[1].split(\".\")[0]\n",
    "        # Load the data\n",
    "        og_data = np.load(os.path.join(SYNCHRONY_BROADBAND_DIRECTORY, filename))\n",
    "        # Find NaN segments\n",
    "        nan_segments = find_nan_segments(og_data)\n",
    "        # If the first element of the first tuple in nan_segments is 0, then delete the first tuple\n",
    "        if nan_segments[0][0] == 0:\n",
    "            nan_segments = nan_segments[1:]\n",
    "        if len(nan_segments) == 1:\n",
    "            print(f\"Filling incomplete data for HUP {hup_id}...\")\n",
    "            print(nan_segments)\n",
    "            # for segment in nan_segments:\n",
    "            #     print(f\"Segment: {segment}\")\n",
    "            #     segment_start = segment[0]\n",
    "            #     segment_end = segment[1]\n",
    "            #     dataset_name = f\"HUP{hup_id}_phaseII\"\n",
    "            #     dataset = session.open_dataset(dataset_name)\n",
    "\n",
    "            #     all_channel_labels = np.array(dataset.get_channel_labels())\n",
    "            #     channel_labels_to_download = all_channel_labels[\n",
    "            #         electrode_selection(all_channel_labels)\n",
    "            #     ]\n",
    "\n",
    "            #     duration_usec = dataset.get_time_series_details(\n",
    "            #         channel_labels_to_download[0]\n",
    "            #     ).duration\n",
    "            #     duration_hours = int(duration_usec / 1000000 / 60 / 60)\n",
    "            #     enlarged_duration_hours = duration_hours + 24\n",
    "\n",
    "            #     print(f\"Opening {dataset_name} with duration {duration_hours} hours\")\n",
    "\n",
    "            #     # Calculate the total number of 2-minute intervals in the enlarged duration\n",
    "            #     total_intervals = enlarged_duration_hours * 30  # 60min/hour / 2min = 30\n",
    "\n",
    "            #     synchrony_broadband_vector_to_save = np.full(total_intervals, np.nan)\n",
    "\n",
    "            #     # Loop through each 2-minute interval\n",
    "            #     for interval in range(segment_start, segment_end + 1):\n",
    "            #         print(\n",
    "            #             f\"Getting iEEG data for interval {interval} out of {total_intervals}\"\n",
    "            #         )\n",
    "            #         duration_usec = 1.2e8  # 2 minutes\n",
    "            #         start_time_usec = (\n",
    "            #             interval * 2 * 60 * 1e6\n",
    "            #         )  # 2 minutes in microseconds\n",
    "            #         stop_time_usec = start_time_usec + duration_usec\n",
    "\n",
    "            #         try:\n",
    "            #             ieeg_data, fs = get_iEEG_data(\n",
    "            #                 \"aguilac\",\n",
    "            #                 \"agu_ieeglogin.bin\",\n",
    "            #                 dataset_name,\n",
    "            #                 start_time_usec,\n",
    "            #                 stop_time_usec,\n",
    "            #                 channel_labels_to_download,\n",
    "            #             )\n",
    "            #             fs = int(fs)\n",
    "            #         except Exception as e:\n",
    "            #             # handle the exception\n",
    "            #             print(f\"Error: {e}\")\n",
    "            #             break\n",
    "\n",
    "            #         # Drop rows that has any nan\n",
    "            #         ieeg_data = ieeg_data.dropna(axis=0, how=\"any\")\n",
    "            #         if ieeg_data.empty:\n",
    "            #             print(\"Empty dataframe after dropping nan, skip...\")\n",
    "            #             continue\n",
    "\n",
    "            #         good_channels_res = detect_bad_channels_optimized(\n",
    "            #             ieeg_data.to_numpy(), fs\n",
    "            #         )\n",
    "            #         good_channel_indicies = good_channels_res[0]\n",
    "            #         good_channel_labels = channel_labels_to_download[\n",
    "            #             good_channel_indicies\n",
    "            #         ]\n",
    "            #         ieeg_data = ieeg_data[good_channel_labels].to_numpy()\n",
    "\n",
    "            #         # Check if ieeg_data is empty after dropping bad channels\n",
    "            #         if ieeg_data.size == 0:\n",
    "            #             print(\"Empty dataframe after dropping bad channels, skip...\")\n",
    "            #             continue\n",
    "\n",
    "            #         ieeg_data = common_average_montage(ieeg_data)\n",
    "\n",
    "            #         # Apply the filters directly on the DataFrame\n",
    "            #         ieeg_data = notch_filter(ieeg_data, 59, 61, fs)\n",
    "\n",
    "            #         ##############################\n",
    "            #         # Calculate synchrony (broadband)\n",
    "            #         ##############################\n",
    "            #         _, R = calculate_synchrony(ieeg_data.T)\n",
    "            #         synchrony_broadband_vector_to_save[interval] = R\n",
    "\n",
    "            #         print(f\"Finished calculating synchrony for interval {interval}\")\n",
    "\n",
    "            #     ##############################\n",
    "            #     # Save the synchrony output\n",
    "            #     ##############################\n",
    "            #     np.save(\n",
    "            #         os.path.join(\n",
    "            #             SYNCHRONY_BROADBAND_FILL_DIRECTORY,\n",
    "            #             f\"HUP_{hup_id}_{segment_start}_{segment_end}.npy\",\n",
    "            #         ),\n",
    "            #         synchrony_broadband_vector_to_save,\n",
    "            #     )\n",
    "            #     print(f\"Saved HUP_{hup_id}_{segment_start}_{segment_end}.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
