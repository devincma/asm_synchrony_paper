{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ieeg.auth import Session\n",
    "\n",
    "from get_iEEG_data import *\n",
    "from iEEG_helper_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYNCHRONY_BROADBAND_DIRECTORY = \"../../Data/synchrony/all/broadband\"\n",
    "SYNCHRONY_BROADBAND_FILL_DIRECTORY = \"../../Data/synchrony/all/broadband_fill\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nan_segments(arr, min_length=240):\n",
    "    nan_segments = []\n",
    "    start_index = None\n",
    "    nan_count = 0\n",
    "\n",
    "    for i, value in enumerate(arr):\n",
    "        if np.isnan(value):\n",
    "            nan_count += 1\n",
    "            if start_index is None:\n",
    "                start_index = i\n",
    "        else:\n",
    "            if nan_count >= min_length:\n",
    "                nan_segments.append((start_index, i - 1))\n",
    "            start_index = None\n",
    "            nan_count = 0\n",
    "\n",
    "    # Check for the case where the array ends with a NaN segment\n",
    "    if nan_count >= min_length:\n",
    "        nan_segments.append((start_index, len(arr) - 1))\n",
    "\n",
    "    return nan_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Carlos session\n"
     ]
    }
   ],
   "source": [
    "print(\"Using Carlos session\")\n",
    "with open(\"agu_ieeglogin.bin\", \"r\") as f:\n",
    "    session = Session(\"aguilac\", f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling incomplete data for HUP 205...\n",
      "[(23, 619), (5931, 6629)]\n",
      "Filling incomplete data for HUP 202...\n",
      "[(3827, 4117), (5720, 6419)]\n",
      "Filling incomplete data for HUP 182...\n",
      "[(990, 1308), (6630, 8489)]\n",
      "Filling incomplete data for HUP 185...\n",
      "[(975, 1229), (6985, 7679)]\n",
      "Filling incomplete data for HUP 174...\n",
      "[(4529, 4871), (7811, 8519)]\n",
      "Filling incomplete data for HUP 180...\n",
      "[(2291, 2666), (5015, 5729)]\n",
      "Filling incomplete data for HUP 210...\n",
      "[(20, 550), (4040, 8519)]\n",
      "Filling incomplete data for HUP 172...\n",
      "[(6728, 7046), (7191, 7889)]\n",
      "Filling incomplete data for HUP 196...\n",
      "[(4304, 4848), (5570, 6269)]\n",
      "Filling incomplete data for HUP 191...\n",
      "[(488, 757), (6472, 7199)]\n"
     ]
    }
   ],
   "source": [
    "# Iterate through all files in SYNCHRONY_BROADBAND_DIRECTORY\n",
    "for filename in os.listdir(SYNCHRONY_BROADBAND_DIRECTORY):\n",
    "    # load only .npy files\n",
    "    if filename.endswith(\".npy\"):\n",
    "        # Filenames are in the format of HUP_{patient_id}.npy\n",
    "        hup_id = filename.split(\"_\")[1].split(\".\")[0]\n",
    "        # Load the data\n",
    "        og_data = np.load(os.path.join(SYNCHRONY_BROADBAND_DIRECTORY, filename))\n",
    "        # Find NaN segments\n",
    "        nan_segments = find_nan_segments(og_data)\n",
    "        # If the first element of the first tuple in nan_segments is 0, then delete the first tuple\n",
    "        if nan_segments[0][0] == 0:\n",
    "            nan_segments = nan_segments[1:]\n",
    "        if len(nan_segments) > 1:\n",
    "            print(f\"Filling incomplete data for HUP {hup_id}...\")\n",
    "            print(nan_segments)\n",
    "            # for segment in nan_segments:\n",
    "            #     print(f\"Segment: {segment}\")\n",
    "            #     segment_start = segment[0]\n",
    "            #     segment_end = segment[1]\n",
    "            #     dataset_name = f\"HUP{hup_id}_phaseII\"\n",
    "            #     dataset = session.open_dataset(dataset_name)\n",
    "\n",
    "            #     all_channel_labels = np.array(dataset.get_channel_labels())\n",
    "            #     channel_labels_to_download = all_channel_labels[\n",
    "            #         electrode_selection(all_channel_labels)\n",
    "            #     ]\n",
    "\n",
    "            #     duration_usec = dataset.get_time_series_details(\n",
    "            #         channel_labels_to_download[0]\n",
    "            #     ).duration\n",
    "            #     duration_hours = int(duration_usec / 1000000 / 60 / 60)\n",
    "            #     enlarged_duration_hours = duration_hours + 24\n",
    "\n",
    "            #     print(f\"Opening {dataset_name} with duration {duration_hours} hours\")\n",
    "\n",
    "            #     # Calculate the total number of 2-minute intervals in the enlarged duration\n",
    "            #     total_intervals = enlarged_duration_hours * 30  # 60min/hour / 2min = 30\n",
    "\n",
    "            #     synchrony_broadband_vector_to_save = np.full(total_intervals, np.nan)\n",
    "\n",
    "            #     # Loop through each 2-minute interval\n",
    "            #     for interval in range(segment_start, segment_end + 1):\n",
    "            #         print(\n",
    "            #             f\"Getting iEEG data for interval {interval} out of {total_intervals}\"\n",
    "            #         )\n",
    "            #         duration_usec = 1.2e8  # 2 minutes\n",
    "            #         start_time_usec = (\n",
    "            #             interval * 2 * 60 * 1e6\n",
    "            #         )  # 2 minutes in microseconds\n",
    "            #         stop_time_usec = start_time_usec + duration_usec\n",
    "\n",
    "            #         try:\n",
    "            #             ieeg_data, fs = get_iEEG_data(\n",
    "            #                 \"aguilac\",\n",
    "            #                 \"agu_ieeglogin.bin\",\n",
    "            #                 dataset_name,\n",
    "            #                 start_time_usec,\n",
    "            #                 stop_time_usec,\n",
    "            #                 channel_labels_to_download,\n",
    "            #             )\n",
    "            #             fs = int(fs)\n",
    "            #         except Exception as e:\n",
    "            #             # handle the exception\n",
    "            #             print(f\"Error: {e}\")\n",
    "            #             break\n",
    "\n",
    "            #         # Drop rows that has any nan\n",
    "            #         ieeg_data = ieeg_data.dropna(axis=0, how=\"any\")\n",
    "            #         if ieeg_data.empty:\n",
    "            #             print(\"Empty dataframe after dropping nan, skip...\")\n",
    "            #             continue\n",
    "\n",
    "            #         good_channels_res = detect_bad_channels_optimized(\n",
    "            #             ieeg_data.to_numpy(), fs\n",
    "            #         )\n",
    "            #         good_channel_indicies = good_channels_res[0]\n",
    "            #         good_channel_labels = channel_labels_to_download[\n",
    "            #             good_channel_indicies\n",
    "            #         ]\n",
    "            #         ieeg_data = ieeg_data[good_channel_labels].to_numpy()\n",
    "\n",
    "            #         # Check if ieeg_data is empty after dropping bad channels\n",
    "            #         if ieeg_data.size == 0:\n",
    "            #             print(\"Empty dataframe after dropping bad channels, skip...\")\n",
    "            #             continue\n",
    "\n",
    "            #         ieeg_data = common_average_montage(ieeg_data)\n",
    "\n",
    "            #         # Apply the filters directly on the DataFrame\n",
    "            #         ieeg_data = notch_filter(ieeg_data, 59, 61, fs)\n",
    "\n",
    "            #         ##############################\n",
    "            #         # Calculate synchrony (broadband)\n",
    "            #         ##############################\n",
    "            #         _, R = calculate_synchrony(ieeg_data.T)\n",
    "            #         synchrony_broadband_vector_to_save[interval] = R\n",
    "\n",
    "            #         print(f\"Finished calculating synchrony for interval {interval}\")\n",
    "\n",
    "            #     ##############################\n",
    "            #     # Save the synchrony output\n",
    "            #     ##############################\n",
    "            #     np.save(\n",
    "            #         os.path.join(\n",
    "            #             SYNCHRONY_BROADBAND_FILL_DIRECTORY,\n",
    "            #             f\"HUP_{hup_id}_{segment_start}_{segment_end}.npy\",\n",
    "            #         ),\n",
    "            #         synchrony_broadband_vector_to_save,\n",
    "            #     )\n",
    "            #     print(f\"Saved HUP_{hup_id}_{segment_start}_{segment_end}.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
