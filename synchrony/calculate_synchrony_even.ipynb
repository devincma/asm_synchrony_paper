{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf __pycache__\n",
    "import numpy as np\n",
    "import os, pickle\n",
    "import pandas as pd\n",
    "from scipy.signal import hilbert\n",
    "from iEEG_helper_functions import *\n",
    "\n",
    "IEEG_DIRECTORY = \"../../Data/ieeg/all/2_min\"\n",
    "SYNCHRONY_1_70_DIRECTORY = \"../../Data/synchrony/1_70\"\n",
    "SYNCHRONY_BROADBAND_DIRECTORY = \"../../Data/synchrony/broadband\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_synchrony(time_series):\n",
    "    \"\"\"\n",
    "    Calculate the Kuramoto order parameter for a set of time series\n",
    "    Args:\n",
    "        time_series (np.array): 2D array where each row is a time series\n",
    "    Returns:\n",
    "        np.array: Kuramoto order parameter for each time point\n",
    "    \"\"\"\n",
    "    # Extract the number of time series and the number of time points\n",
    "    N, _ = time_series.shape\n",
    "    # Apply the Hilbert Transform to get an analytical signal\n",
    "    analytical_signals = hilbert(time_series)\n",
    "    assert analytical_signals.shape == time_series.shape\n",
    "    # Extract the instantaneous phase for each time series using np.angle\n",
    "    phases = np.angle(analytical_signals, deg=False)\n",
    "    assert phases.shape == time_series.shape\n",
    "    # Compute the Kuramoto order parameter for each time point\n",
    "    # 1j*1j == -1\n",
    "    r_t = np.abs(np.sum(np.exp(1j * phases), axis=0)) / N\n",
    "    R = np.mean(r_t)\n",
    "    return r_t, R\n",
    "\n",
    "\n",
    "# def calculate_entropy(synchrony, num_bins=24):\n",
    "#     # Calculate the probability distribution by binning the synchrony values\n",
    "#     hist, _ = np.histogram(synchrony, bins=num_bins)\n",
    "#     probabilities = hist / np.sum(hist)\n",
    "\n",
    "#     # Calculate the entropy\n",
    "#     entropy = -sum(p * np.log2(p) for p in probabilities if p > 0)\n",
    "#     return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([225, 224, 223, 221, 219, 217, 216, 215, 214, 213, 211, 210, 209,\n",
       "       208, 207, 206, 205, 204, 202, 201, 199, 197, 196, 195, 194, 193,\n",
       "       192, 191, 190, 189, 188, 187, 186, 185, 184, 182, 181, 180, 179,\n",
       "       178, 177, 175, 174, 173, 172, 171, 170, 169, 168, 167, 166, 165,\n",
       "       164, 163, 162, 161, 160, 159, 158, 157, 156, 155, 154, 153, 152,\n",
       "       151, 150, 149, 148, 147, 146, 145, 144, 143, 142, 141, 140, 139,\n",
       "       138, 137])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nina_patient_hup_ids = pd.read_excel(\"../../Data/HUP_implant_dates.xlsx\")\n",
    "nina_patient_hup_ids = nina_patient_hup_ids[\"hup_id\"].to_numpy()\n",
    "nina_patient_hup_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping between patient ids and the index of the patient in the patients_df dataframe\n",
    "patient_hup_id_to_index = {}\n",
    "for i, patient_id in enumerate(nina_patient_hup_ids):\n",
    "    patient_hup_id_to_index[patient_id] = i\n",
    "# patient_hup_id_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ieeg_offset_row1_df = pd.read_excel(\"../../Data/ieeg_offset/row_1.xlsx\", header=None)\n",
    "ieeg_offset_row2_df = pd.read_excel(\"../../Data/ieeg_offset/row_2.xlsx\", header=None)\n",
    "ieeg_offset_row3_df = pd.read_excel(\"../../Data/ieeg_offset/row_3.xlsx\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rid</th>\n",
       "      <th>name</th>\n",
       "      <th>vox_x</th>\n",
       "      <th>vox_y</th>\n",
       "      <th>vox_z</th>\n",
       "      <th>label</th>\n",
       "      <th>soz</th>\n",
       "      <th>resected</th>\n",
       "      <th>spike_rate</th>\n",
       "      <th>engel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>LST01</td>\n",
       "      <td>80.6116</td>\n",
       "      <td>106.5480</td>\n",
       "      <td>64.5941</td>\n",
       "      <td>left inferior temporal</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.091902</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>LST02</td>\n",
       "      <td>72.0779</td>\n",
       "      <td>109.4150</td>\n",
       "      <td>63.1223</td>\n",
       "      <td>left inferior temporal</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.091902</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>LST03</td>\n",
       "      <td>64.9060</td>\n",
       "      <td>112.3760</td>\n",
       "      <td>68.7455</td>\n",
       "      <td>EmptyLabel</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.419472</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>LST04</td>\n",
       "      <td>65.0210</td>\n",
       "      <td>114.6600</td>\n",
       "      <td>78.2339</td>\n",
       "      <td>left middle temporal</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.655141</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>MST01</td>\n",
       "      <td>131.7410</td>\n",
       "      <td>64.3756</td>\n",
       "      <td>70.4205</td>\n",
       "      <td>right lingual</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3.439490</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14212</th>\n",
       "      <td>785</td>\n",
       "      <td>RB08</td>\n",
       "      <td>154.2550</td>\n",
       "      <td>114.2730</td>\n",
       "      <td>136.7560</td>\n",
       "      <td>EmptyLabel</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.369914</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14213</th>\n",
       "      <td>785</td>\n",
       "      <td>RB09</td>\n",
       "      <td>159.1350</td>\n",
       "      <td>111.9920</td>\n",
       "      <td>136.6960</td>\n",
       "      <td>EmptyLabel</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.665845</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14214</th>\n",
       "      <td>785</td>\n",
       "      <td>RB10</td>\n",
       "      <td>164.7520</td>\n",
       "      <td>109.9030</td>\n",
       "      <td>137.7640</td>\n",
       "      <td>right middle temporal</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.586930</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14215</th>\n",
       "      <td>785</td>\n",
       "      <td>RB11</td>\n",
       "      <td>169.6320</td>\n",
       "      <td>107.6220</td>\n",
       "      <td>137.7040</td>\n",
       "      <td>right middle temporal</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.071517</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14216</th>\n",
       "      <td>785</td>\n",
       "      <td>RB12</td>\n",
       "      <td>175.1210</td>\n",
       "      <td>105.8310</td>\n",
       "      <td>137.7080</td>\n",
       "      <td>EmptyLabel</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.104809</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14217 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rid   name     vox_x     vox_y     vox_z                   label  \\\n",
       "0       13  LST01   80.6116  106.5480   64.5941  left inferior temporal   \n",
       "1       13  LST02   72.0779  109.4150   63.1223  left inferior temporal   \n",
       "2       13  LST03   64.9060  112.3760   68.7455              EmptyLabel   \n",
       "3       13  LST04   65.0210  114.6600   78.2339    left middle temporal   \n",
       "4       13  MST01  131.7410   64.3756   70.4205           right lingual   \n",
       "...    ...    ...       ...       ...       ...                     ...   \n",
       "14212  785   RB08  154.2550  114.2730  136.7560              EmptyLabel   \n",
       "14213  785   RB09  159.1350  111.9920  136.6960              EmptyLabel   \n",
       "14214  785   RB10  164.7520  109.9030  137.7640   right middle temporal   \n",
       "14215  785   RB11  169.6320  107.6220  137.7040   right middle temporal   \n",
       "14216  785   RB12  175.1210  105.8310  137.7080              EmptyLabel   \n",
       "\n",
       "         soz resected  spike_rate  engel  \n",
       "0      False    False    1.091902    1.0  \n",
       "1      False    False    1.091902    1.0  \n",
       "2      False    False    1.419472    1.0  \n",
       "3      False    False    0.655141    1.0  \n",
       "4       True    False    3.439490    1.0  \n",
       "...      ...      ...         ...    ...  \n",
       "14212  False      NaN    0.369914    1.0  \n",
       "14213  False      NaN    0.665845    1.0  \n",
       "14214  False      NaN    4.586930    1.0  \n",
       "14215  False      NaN    2.071517    1.0  \n",
       "14216  False      NaN    5.104809    1.0  \n",
       "\n",
       "[14217 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load master_elecs.csv from ./data/\n",
    "master_elecs_df = pd.read_csv(\"../../Data/master_elecs.csv\")\n",
    "\n",
    "# only take the numbers in rid column\n",
    "master_elecs_df[\"rid\"] = master_elecs_df[\"rid\"].str.extract(\"(\\d+)\", expand=False)\n",
    "master_elecs_df[\"rid\"] = master_elecs_df[\"rid\"].astype(int)\n",
    "\n",
    "# Drop mni_x, mni_y, mni_z, mm_x, mm_y, mm_z columns\n",
    "master_elecs_df = master_elecs_df.drop(\n",
    "    columns=[\"mni_x\", \"mni_y\", \"mni_z\", \"mm_x\", \"mm_y\", \"mm_z\"]\n",
    ")\n",
    "\n",
    "master_elecs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>hupsubjno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>623</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>624</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>625</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>626</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>627</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>534</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>923</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>918</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>864</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>675</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>217 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     record_id  hupsubjno\n",
       "0          623         35\n",
       "1          624         36\n",
       "2          625         37\n",
       "3          626         38\n",
       "4          627         39\n",
       "..         ...        ...\n",
       "212        534        250\n",
       "213        923        251\n",
       "214        918        252\n",
       "215        864        253\n",
       "216        675        254\n",
       "\n",
       "[217 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load rid_hup_table.csv from ./data/\n",
    "rid_hup_table_df = pd.read_csv(\"../../Data/rid_hup_table.csv\")\n",
    "# Drop the t3_subject_id and ieegportalsubjno columns\n",
    "rid_hup_table_df = rid_hup_table_df.drop(columns=[\"t3_subject_id\", \"ieegportalsubjno\"])\n",
    "rid_hup_table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>max_hour</th>\n",
       "      <th>sample_rate</th>\n",
       "      <th>hup_id</th>\n",
       "      <th>max_hour_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HUP138_phaseII</td>\n",
       "      <td>172</td>\n",
       "      <td>1024</td>\n",
       "      <td>138</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HUP140_phaseII_D02</td>\n",
       "      <td>128</td>\n",
       "      <td>1024</td>\n",
       "      <td>140</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HUP140_phaseII_D01</td>\n",
       "      <td>19</td>\n",
       "      <td>1024</td>\n",
       "      <td>140</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HUP141_phaseII</td>\n",
       "      <td>146</td>\n",
       "      <td>512</td>\n",
       "      <td>141</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HUP142_phaseII</td>\n",
       "      <td>311</td>\n",
       "      <td>512</td>\n",
       "      <td>142</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>HUP215_phaseII_D01</td>\n",
       "      <td>14</td>\n",
       "      <td>2048</td>\n",
       "      <td>215</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>HUP216_phaseII_D01</td>\n",
       "      <td>143</td>\n",
       "      <td>512</td>\n",
       "      <td>216</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>HUP216_phaseII_D02</td>\n",
       "      <td>144</td>\n",
       "      <td>512</td>\n",
       "      <td>216</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>HUP223_phaseII</td>\n",
       "      <td>135</td>\n",
       "      <td>1024</td>\n",
       "      <td>223</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>HUP224_phaseII</td>\n",
       "      <td>145</td>\n",
       "      <td>1024</td>\n",
       "      <td>224</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          dataset_name  max_hour  sample_rate  hup_id  max_hour_count\n",
       "0       HUP138_phaseII       172         1024     138             173\n",
       "1   HUP140_phaseII_D02       128         1024     140             129\n",
       "2   HUP140_phaseII_D01        19         1024     140              20\n",
       "3       HUP141_phaseII       146          512     141             147\n",
       "4       HUP142_phaseII       311          512     142             312\n",
       "..                 ...       ...          ...     ...             ...\n",
       "81  HUP215_phaseII_D01        14         2048     215              15\n",
       "82  HUP216_phaseII_D01       143          512     216             144\n",
       "83  HUP216_phaseII_D02       144          512     216             145\n",
       "84      HUP223_phaseII       135         1024     223             136\n",
       "85      HUP224_phaseII       145         1024     224             146\n",
       "\n",
       "[86 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an empty dictionary to store all the data\n",
    "data_dict = {\"dataset_name\": [], \"max_hour\": [], \"sample_rate\": [], \"hup_id\": []}\n",
    "\n",
    "# Iterate through the directory\n",
    "for filename in os.listdir(IEEG_DIRECTORY):\n",
    "    if filename.endswith(\".pkl\"):  # Only process .pkl files\n",
    "        # Split the filename to get the dataset_name, hour, and sample_rate\n",
    "        parts = filename.split(\"_\")\n",
    "        dataset_name = \"_\".join(parts[:-4])  # Exclude the '_hr' from the dataset_name\n",
    "        hour = int(parts[-3])\n",
    "        fs = int(parts[-1].split(\".\")[0])\n",
    "\n",
    "        # Extract hup_id from dataset_name\n",
    "        hup_id = dataset_name.split(\"_\")[0].split(\"HUP\")[1]\n",
    "\n",
    "        # If the dataset_name is already in the dictionary, update the max_hour\n",
    "        if dataset_name in data_dict[\"dataset_name\"]:\n",
    "            index = data_dict[\"dataset_name\"].index(dataset_name)\n",
    "            data_dict[\"max_hour\"][index] = max(data_dict[\"max_hour\"][index], hour)\n",
    "        else:\n",
    "            # Else, add the dataset_name, hour, sample_rate and hup_id to the dictionary\n",
    "            data_dict[\"dataset_name\"].append(dataset_name)\n",
    "            data_dict[\"max_hour\"].append(hour)\n",
    "            data_dict[\"sample_rate\"].append(fs)\n",
    "            data_dict[\"hup_id\"].append(hup_id)\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "datasets_df = pd.DataFrame(data_dict)\n",
    "# Make max_hour and sample_rate and hup_id integers\n",
    "datasets_df[\"max_hour\"] = datasets_df[\"max_hour\"].astype(int)\n",
    "datasets_df[\"sample_rate\"] = datasets_df[\"sample_rate\"].astype(int)\n",
    "datasets_df[\"hup_id\"] = datasets_df[\"hup_id\"].astype(int)\n",
    "# Sort by hup_id\n",
    "datasets_df = datasets_df.sort_values(by=[\"hup_id\"])\n",
    "# Reset the index\n",
    "datasets_df = datasets_df.reset_index(drop=True)\n",
    "# Create a column called max_hour_count that is the max_hour + 1\n",
    "datasets_df[\"max_hour_count\"] = datasets_df[\"max_hour\"] + 1\n",
    "datasets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = datasets_df[\"hup_id\"].unique()[11:]\n",
    "# odd ids\n",
    "even_ids = ids[ids % 2 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HUP 150, rid 322\n",
      "HUP150_phaseII\n",
      "Processing hour 0 in HUP150_phaseII, that's hour 0 out of 114 for HUP 150\n",
      "Processing hour 1 in HUP150_phaseII, that's hour 1 out of 114 for HUP 150\n",
      "Processing hour 2 in HUP150_phaseII, that's hour 2 out of 114 for HUP 150\n",
      "Processing hour 3 in HUP150_phaseII, that's hour 3 out of 114 for HUP 150\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(full_path, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m---> 40\u001b[0m         ieeg_data \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mload(f)\n\u001b[1;32m     41\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSkipping \u001b[39m\u001b[39m{\u001b[39;00mhour\u001b[39m}\u001b[39;00m\u001b[39m for \u001b[39m\u001b[39m{\u001b[39;00mdataset_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/mnt/leif/littlab/users/devinma/Libraries/miniconda3/lib/python3.11/site-packages/pandas/_libs/internals.pyx:575\u001b[0m, in \u001b[0;36mpandas._libs.internals._unpickle_block\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/mnt/leif/littlab/users/devinma/Libraries/miniconda3/lib/python3.11/site-packages/pandas/core/internals/blocks.py:2172\u001b[0m, in \u001b[0;36mnew_block\u001b[0;34m(values, placement, ndim)\u001b[0m\n\u001b[1;32m   2168\u001b[0m     values \u001b[39m=\u001b[39m maybe_coerce_values(values)\n\u001b[1;32m   2169\u001b[0m     \u001b[39mreturn\u001b[39;00m klass(values, ndim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, placement\u001b[39m=\u001b[39mplacement)\n\u001b[0;32m-> 2172\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnew_block\u001b[39m(values, placement, \u001b[39m*\u001b[39m, ndim: \u001b[39mint\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Block:\n\u001b[1;32m   2173\u001b[0m     \u001b[39m# caller is responsible for ensuring values is NOT a PandasArray\u001b[39;00m\n\u001b[1;32m   2175\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(placement, BlockPlacement):\n\u001b[1;32m   2176\u001b[0m         placement \u001b[39m=\u001b[39m BlockPlacement(placement)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for patient_hup_id in even_ids:\n",
    "    # Find the value of record_id in rid_hup_table_df where hupsubjno == patient_hup_id\n",
    "    patient_rid = rid_hup_table_df[rid_hup_table_df[\"hupsubjno\"] == patient_hup_id][\n",
    "        \"record_id\"\n",
    "    ].values[0]\n",
    "    # Get the row in datasets_df corresponding to the patient_hup_id\n",
    "    rows_df = datasets_df[datasets_df[\"hup_id\"] == patient_hup_id]\n",
    "    # Sort rows_df by dataset_name\n",
    "    rows_df = rows_df.sort_values(by=[\"dataset_name\"])\n",
    "    rows_df = rows_df.reset_index(drop=True)\n",
    "    patient_electrodes_df = master_elecs_df.loc[master_elecs_df[\"rid\"] == patient_rid]\n",
    "    print(f\"HUP {patient_hup_id}, rid {patient_rid}\")\n",
    "\n",
    "    # Add up all the max_hours for rows_df\n",
    "    total_max_hour_count = rows_df[\"max_hour_count\"].sum()\n",
    "\n",
    "    ##########################################\n",
    "    # Create empty vectors to save the data\n",
    "    ##########################################\n",
    "    synchrony_1_70_vector_to_save = np.zeros(total_max_hour_count)\n",
    "    synchrony_broadband_vector_to_save = np.zeros(total_max_hour_count)\n",
    "    current_hour = 0\n",
    "\n",
    "    for dataset_idx, dataset_row in rows_df.iterrows():\n",
    "        # Get the dataset_name, max_hour, and sample_rate\n",
    "        dataset_name = dataset_row[\"dataset_name\"]\n",
    "        max_hour_count = dataset_row[\"max_hour_count\"]\n",
    "        fs = dataset_row[\"sample_rate\"]\n",
    "        print(dataset_name)\n",
    "\n",
    "        for hour in range(max_hour_count):\n",
    "            # Get the filename\n",
    "            filename = f\"{dataset_name}_hr_{hour}_fs_{fs}.pkl\"\n",
    "            # Get the full path to the file\n",
    "            full_path = os.path.join(IEEG_DIRECTORY, filename)\n",
    "\n",
    "            # Load the data\n",
    "            try:\n",
    "                with open(full_path, \"rb\") as f:\n",
    "                    ieeg_data = pickle.load(f)\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Skipping {hour} for {dataset_name}\")\n",
    "                synchrony_1_70_vector_to_save[current_hour] = np.nan\n",
    "                synchrony_broadband_vector_to_save[current_hour] = np.nan\n",
    "                current_hour += 1\n",
    "                continue\n",
    "\n",
    "            print(\n",
    "                f\"Processing hour {hour} in {dataset_name}, that's hour {current_hour} out of {total_max_hour_count} for HUP {patient_hup_id}\"\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                all_channel_labels = ieeg_data.columns.values.astype(str)\n",
    "                label_idxs = electrode_selection(all_channel_labels)\n",
    "                labels = all_channel_labels[label_idxs]\n",
    "                ieeg_data = ieeg_data[labels]\n",
    "                good_channels_res = detect_bad_channels_optimized(\n",
    "                    ieeg_data.to_numpy(), fs\n",
    "                )\n",
    "                good_channel_indicies = good_channels_res[0]\n",
    "                good_labels = labels[good_channel_indicies]\n",
    "                ieeg_data = ieeg_data[good_labels]\n",
    "\n",
    "                ieeg_data = common_average_montage(ieeg_data)\n",
    "\n",
    "                # Broadband\n",
    "                ieeg_data = pd.DataFrame(notch_filter(ieeg_data.values, 59, 61, fs))\n",
    "                _, R = calculate_synchrony((ieeg_data.T).to_numpy())\n",
    "                synchrony_broadband_vector_to_save[current_hour] = R\n",
    "\n",
    "                # 1-70 Hz\n",
    "                ieeg_data = pd.DataFrame(bandpass_filter(ieeg_data.values, 1, 70, fs))\n",
    "                _, R = calculate_synchrony((ieeg_data.T).to_numpy())\n",
    "                synchrony_1_70_vector_to_save[current_hour] = R\n",
    "\n",
    "                # Increment current_hour\n",
    "                current_hour += 1\n",
    "\n",
    "            except:\n",
    "                print(f\"Skipping {hour} for {dataset_name} due to unknown error\")\n",
    "                synchrony_1_70_vector_to_save[current_hour] = np.nan\n",
    "                synchrony_broadband_vector_to_save[current_hour] = np.nan\n",
    "                current_hour += 1\n",
    "                continue\n",
    "\n",
    "    ##########################################\n",
    "    # Save files\n",
    "    ##########################################\n",
    "    np.save(\n",
    "        f\"{SYNCHRONY_1_70_DIRECTORY}/HUP_{patient_hup_id}.npy\",\n",
    "        synchrony_1_70_vector_to_save,\n",
    "    )\n",
    "    np.save(\n",
    "        f\"{SYNCHRONY_BROADBAND_DIRECTORY}/HUP_{patient_hup_id}.npy\",\n",
    "        synchrony_broadband_vector_to_save,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
