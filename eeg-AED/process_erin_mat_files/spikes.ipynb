{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Erin's .mat files for spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "SPIKES_DIRECTORY = \"../../Data/spikes\"\n",
    "ERIN_DIRECTORY = \"../../../erinconr/projects/fc_toolbox/results/analysis/intermediate/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 soz (1, 1)\n",
    "1 name (1,)\n",
    "2 times (2392, 1)\n",
    "3 spikes (161, 2392)\n",
    "4 coi_global (2392, 1)\n",
    "5 rl (161, 2392)\n",
    "6 labels (161, 1)\n",
    "7 bipolar_labels (161, 1)\n",
    "8 bipolar_pair (148, 2)\n",
    "9 locs (161, 3)\n",
    "10 bipolar_locs (161, 3)\n",
    "11 anatomy (161, 1)\n",
    "12 bad_anatomy_flag (1, 1)\n",
    "13 ana_loc (161, 1)\n",
    "14 ana_lat (161, 1)\n",
    "15 file_times (2392, 1)\n",
    "16 file_index (2392, 1)\n",
    "17 ad (161, 2392)\n",
    "18 block_dur (1, 1)\n",
    "19 ns (161, 2392)\n",
    "20 n_rm_ictal (1, 1)\n",
    "21 sz_times (3, 2)\n",
    "22 sz_semiology (3, 1)\n",
    "23 rid (1, 1)\n",
    "24 avg_fc (161, 161)\n",
    "25 seq_info (2, 2392)\n",
    "26 clinical (1, 1)\n",
    "27 leader (161, 2392)\n",
    "28 mod_midnight (2392, 1)\n",
    "29 ns_car (161, 2392)\n",
    "30 avg_fc_car (161, 161)\n",
    "31 ns_bi (161, 2392)\n",
    "32 avg_fc_bi (161, 161)\n",
    "33 bp (161, 5, 2392)\n",
    "34 bp_bi (161, 5, 2392)\n",
    "35 avg_coh (12880, 6)\n",
    "36 avg_coh_bi (12880, 6)\n",
    "37 good_spikes (1, 1)\n",
    "38 native_locs (161, 3)\n",
    "39 native_bipolar_locs (161, 3)\n",
    "40 fc_car_ws (2, 1)\n",
    "41 fc_bi_ws (2, 1)\n",
    "42 spikes_ws (2, 1)\n",
    "43 rl_ws (2, 1)\n",
    "44 coh_car_ws (2, 1)\n",
    "45 coh_bi_ws (2, 1)\n",
    "46 bp_bi_ws (2, 1)\n",
    "47 bp_car_ws (2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "# Iterate through all .mat files in ../../../erinconr/projects/fc_toolbox/results/analysis/intermediate/\n",
    "for filename in os.listdir(ERIN_DIRECTORY):\n",
    "    mat_file = scipy.io.loadmat(\n",
    "        f\"../../../erinconr/projects/fc_toolbox/results/analysis/intermediate/{filename}\"\n",
    "    )\n",
    "    mat_file = mat_file[\"summ\"][0]\n",
    "    for index, key in enumerate(mat_file.dtype.names):\n",
    "        # print(index, key, mat_file[0][index].shape)\n",
    "        if key == \"spikes\":\n",
    "            temp.append(index)\n",
    "spikes_index = np.unique(np.array(temp, dtype=int))\n",
    "assert spikes_index.shape[0] == 1\n",
    "spikes_index = spikes_index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hourly alpha-delta ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_samples(patient_ad_ratio):\n",
    "    # Get the shape of the original array\n",
    "    original_shape = patient_ad_ratio.shape\n",
    "\n",
    "    # Calculate new shape\n",
    "    num_channels = original_shape[0]\n",
    "    num_samples = original_shape[1]\n",
    "    num_whole_groups = num_samples // 6\n",
    "    num_remaining_samples = num_samples % 6\n",
    "\n",
    "    # Reshape the array to average every 6 samples\n",
    "    whole_groups_array = patient_ad_ratio[:, : num_whole_groups * 6].reshape(\n",
    "        num_channels, num_whole_groups, 6\n",
    "    )\n",
    "    averaged_array = whole_groups_array.mean(axis=2)\n",
    "\n",
    "    if num_remaining_samples > 0:\n",
    "        remaining_array = patient_ad_ratio[:, num_whole_groups * 6 :].mean(\n",
    "            axis=1, keepdims=True\n",
    "        )\n",
    "        averaged_array = np.concatenate((averaged_array, remaining_array), axis=1)\n",
    "\n",
    "    return averaged_array\n",
    "\n",
    "\n",
    "# # Test function with some random data\n",
    "# # Create a 4x31 numpy array, i.e. 4 channels with 31 samples each\n",
    "# patient_ad_ratio = np.random.rand(4, 32)\n",
    "# averaged_array = average_samples(patient_ad_ratio)\n",
    "# print(patient_ad_ratio, averaged_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(ERIN_DIRECTORY):\n",
    "    patient_hup_id = int(filename[3:6])\n",
    "    mat_file = scipy.io.loadmat(\n",
    "        f\"../../../erinconr/projects/fc_toolbox/results/analysis/intermediate/{filename}\"\n",
    "    )\n",
    "    mat_file = mat_file[\"summ\"][0][0]\n",
    "    patient_spikes = mat_file[spikes_index]\n",
    "    num_channels = mat_file[spikes_index].shape[0]\n",
    "    assert patient_spikes.shape[0] == num_channels\n",
    "    hourly_spikes = average_samples(patient_spikes)\n",
    "    num_hours = hourly_spikes.shape[1]\n",
    "    assert hourly_spikes.shape[0] == num_channels\n",
    "\n",
    "    # # Save hourly_ad_ratio to a .npy file named hup_{patient_hup_id}.npy\n",
    "    # np.save(f\"{SPIKES_DIRECTORY}/raw/HUP_{patient_hup_id}.npy\", hourly_spikes)\n",
    "\n",
    "    # hourly_spikes_avg = np.nanmean(hourly_spikes, axis=0)\n",
    "    # assert hourly_spikes_avg.shape[0] == num_hours\n",
    "\n",
    "    # # Save hourly_ad_ratio_avg to a .npy file named HUP_{patient_hup_id}.npy\n",
    "    # np.save(\n",
    "    #     f\"{SPIKES_DIRECTORY}/hourly_all/HUP_{patient_hup_id}.npy\",\n",
    "    #     hourly_spikes_avg,\n",
    "    # )\n",
    "\n",
    "    # hourly_spikes_sum = np.nansum(hourly_spikes, axis=0)\n",
    "    # assert hourly_spikes_sum.shape[0] == num_hours\n",
    "\n",
    "    # # Save hourly_ad_ratio_avg to a .npy file named HUP_{patient_hup_id}.npy\n",
    "    # np.save(\n",
    "    #     f\"{SPIKES_DIRECTORY}/hourly_sum_all/HUP_{patient_hup_id}.npy\",\n",
    "    #     hourly_spikes_sum,\n",
    "    # )\n",
    "    # print(\n",
    "    #     f\"HUP{patient_hup_id}\",\n",
    "    #     patient_spikes.shape,\n",
    "    #     hourly_spikes.shape,\n",
    "    # )\n",
    "\n",
    "    soz_channel_indices = mat_file[0][0][0][1].flatten().astype(int) - 1\n",
    "    hourly_spikes_soz = hourly_spikes[soz_channel_indices, :]\n",
    "    # print(hourly_spikes_soz.shape)\n",
    "    assert hourly_spikes_soz.shape == (len(soz_channel_indices), num_hours)\n",
    "\n",
    "    # Save hourly_ad_ratio to a .npy file named hup_{patient_hup_id}.npy\n",
    "    np.save(\n",
    "        f\"{SPIKES_DIRECTORY}/hourly_raw/soz/HUP_{patient_hup_id}.npy\", hourly_spikes_soz\n",
    "    )\n",
    "\n",
    "    hourly_spikes_avg_soz = np.nanmean(hourly_spikes_soz, axis=0)\n",
    "    assert hourly_spikes_avg_soz.shape[0] == num_hours\n",
    "\n",
    "    # Save hourly_ad_ratio_avg to a .npy file named HUP_{patient_hup_id}.npy\n",
    "    np.save(\n",
    "        f\"{SPIKES_DIRECTORY}/hourly_avg/soz/HUP_{patient_hup_id}.npy\",\n",
    "        hourly_spikes_avg_soz,\n",
    "    )\n",
    "\n",
    "    hourly_spikes_sum_soz = np.nansum(hourly_spikes_soz, axis=0)\n",
    "    assert hourly_spikes_sum_soz.shape[0] == num_hours\n",
    "\n",
    "    # Save hourly_ad_ratio_avg to a .npy file named HUP_{patient_hup_id}.npy\n",
    "    np.save(\n",
    "        f\"{SPIKES_DIRECTORY}/hourly_sum/soz/HUP_{patient_hup_id}.npy\",\n",
    "        hourly_spikes_sum_soz,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
