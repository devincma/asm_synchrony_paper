{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build giant tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "from scipy.stats import iqr\n",
    "from scipy import interpolate\n",
    "from ieeg.auth import Session\n",
    "from iEEG_helper_functions import *\n",
    "\n",
    "SPIKES_OUTPUT_DIR = \"../../Data/spikes/devin_spikes/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hup_id</th>\n",
       "      <th>IEEG_Portal_Number</th>\n",
       "      <th>Implant_Date</th>\n",
       "      <th>implant_time</th>\n",
       "      <th>Explant_Date</th>\n",
       "      <th>weight_kg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>225</td>\n",
       "      <td>HUP225_phaseII</td>\n",
       "      <td>2021-10-18</td>\n",
       "      <td>07:15:00</td>\n",
       "      <td>2021-10-26 17:30:00</td>\n",
       "      <td>58.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>224</td>\n",
       "      <td>HUP224_phaseII</td>\n",
       "      <td>2021-10-13</td>\n",
       "      <td>07:15:00</td>\n",
       "      <td>2021-10-20 00:00:00</td>\n",
       "      <td>85.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>223</td>\n",
       "      <td>HUP223_phaseII</td>\n",
       "      <td>2021-09-29</td>\n",
       "      <td>07:15:00</td>\n",
       "      <td>2021-10-08 08:21:00</td>\n",
       "      <td>101.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>221</td>\n",
       "      <td>HUP221_phaseII</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>07:15:00</td>\n",
       "      <td>2021-08-23 00:00:00</td>\n",
       "      <td>124.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>219</td>\n",
       "      <td>HUP219_phaseII</td>\n",
       "      <td>2021-07-12</td>\n",
       "      <td>07:15:00</td>\n",
       "      <td>2021-07-16 08:18:00</td>\n",
       "      <td>101.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>141</td>\n",
       "      <td>HUP141_phaseII</td>\n",
       "      <td>2017-05-24</td>\n",
       "      <td>07:15:00</td>\n",
       "      <td>2017-06-01 00:00:00</td>\n",
       "      <td>85.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>140</td>\n",
       "      <td>HUP140_phaseII_D01-D02</td>\n",
       "      <td>2017-05-10</td>\n",
       "      <td>07:15:00</td>\n",
       "      <td>2017-05-19 00:00:00</td>\n",
       "      <td>56.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>139</td>\n",
       "      <td>HUP139_phaseII</td>\n",
       "      <td>2017-04-26</td>\n",
       "      <td>07:15:00</td>\n",
       "      <td>2017-05-09 00:00:00</td>\n",
       "      <td>69.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>138</td>\n",
       "      <td>HUP138_phaseII</td>\n",
       "      <td>2017-04-12</td>\n",
       "      <td>07:15:00</td>\n",
       "      <td>2017-04-20 00:00:00</td>\n",
       "      <td>84.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>137</td>\n",
       "      <td>HUP137_phaseII_D01-D03</td>\n",
       "      <td>2017-03-22</td>\n",
       "      <td>07:15:00</td>\n",
       "      <td>2017-03-29 13:30:00</td>\n",
       "      <td>141.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    hup_id      IEEG_Portal_Number Implant_Date implant_time  \\\n",
       "0      225          HUP225_phaseII   2021-10-18     07:15:00   \n",
       "1      224          HUP224_phaseII   2021-10-13     07:15:00   \n",
       "2      223          HUP223_phaseII   2021-09-29     07:15:00   \n",
       "3      221          HUP221_phaseII   2021-08-16     07:15:00   \n",
       "4      219          HUP219_phaseII   2021-07-12     07:15:00   \n",
       "..     ...                     ...          ...          ...   \n",
       "75     141          HUP141_phaseII   2017-05-24     07:15:00   \n",
       "76     140  HUP140_phaseII_D01-D02   2017-05-10     07:15:00   \n",
       "77     139          HUP139_phaseII   2017-04-26     07:15:00   \n",
       "78     138          HUP138_phaseII   2017-04-12     07:15:00   \n",
       "79     137  HUP137_phaseII_D01-D03   2017-03-22     07:15:00   \n",
       "\n",
       "          Explant_Date  weight_kg  \n",
       "0  2021-10-26 17:30:00       58.5  \n",
       "1  2021-10-20 00:00:00       85.5  \n",
       "2  2021-10-08 08:21:00      101.4  \n",
       "3  2021-08-23 00:00:00      124.3  \n",
       "4  2021-07-16 08:18:00      101.6  \n",
       "..                 ...        ...  \n",
       "75 2017-06-01 00:00:00       85.7  \n",
       "76 2017-05-19 00:00:00       56.7  \n",
       "77 2017-05-09 00:00:00       69.8  \n",
       "78 2017-04-20 00:00:00       84.4  \n",
       "79 2017-03-29 13:30:00      141.3  \n",
       "\n",
       "[80 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load HUP_implant_dates.xlsx\n",
    "patients_df = pd.read_excel(\"../../Data/HUP_implant_dates.xlsx\")\n",
    "patients_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping between patient ids and the index of the patient in the patients_df dataframe\n",
    "patient_hup_id_to_index = {}\n",
    "for i, patient_id in enumerate(patients_df[\"hup_id\"]):\n",
    "    patient_hup_id_to_index[patient_id] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to hold the data\n",
    "# completed_hup_ids = [160, 172, 141, 145, 157, 161, 138, 142, 151, 171, 175, 187]\n",
    "completed_hup_ids = [\n",
    "    160,\n",
    "    172,\n",
    "    # 141, # not enough time before first seizure\n",
    "    145,\n",
    "    138,\n",
    "    142,\n",
    "    151,\n",
    "    187,\n",
    "    180,\n",
    "    184,\n",
    "    # 192, # incomplete data\n",
    "    # 196, # not enough time before first seizure\n",
    "    # 204, # not enough time before first seizure\n",
    "    # 165, # incomplete data\n",
    "    # 169, # not enough time after the last seizure\n",
    "    173,\n",
    "    # 150, # not enough time before first seizure\n",
    "    # 154, # incomplete data\n",
    "    # 158, # incomplete data\n",
    "    # 207, # not enough time before first seizure\n",
    "    223,\n",
    "    # 192,  ## Monday, August 21, 2023 additions this line and below # incomplete data\n",
    "    # 196, # not enough time before first seizure\n",
    "    # 204, # not enough time before first seizure\n",
    "    177,\n",
    "    185,\n",
    "    # 189, # not enough time before first seizure\n",
    "    # 205, # not enough time before first seizure\n",
    "    166,\n",
    "    # 170, # not enough time before first seizure\n",
    "    # 174, # not enough time before first seizure\n",
    "]\n",
    "# Sort completed_hup_ids in ascending order\n",
    "completed_hup_ids.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hup_id</th>\n",
       "      <th>IEEG_Portal_Number</th>\n",
       "      <th>Implant_Date</th>\n",
       "      <th>implant_time</th>\n",
       "      <th>Explant_Date</th>\n",
       "      <th>weight_kg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>223</td>\n",
       "      <td>HUP223_phaseII</td>\n",
       "      <td>2021-09-29</td>\n",
       "      <td>07:15:00</td>\n",
       "      <td>2021-10-08 08:21:00</td>\n",
       "      <td>101.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>187</td>\n",
       "      <td>HUP187_phaseII</td>\n",
       "      <td>2019-03-11</td>\n",
       "      <td>07:15:00</td>\n",
       "      <td>2019-03-19 00:00:00</td>\n",
       "      <td>86.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>185</td>\n",
       "      <td>HUP185_phaseII</td>\n",
       "      <td>2019-01-21</td>\n",
       "      <td>07:15:00</td>\n",
       "      <td>2019-02-01 00:00:00</td>\n",
       "      <td>76.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>184</td>\n",
       "      <td>HUP184_phaseII</td>\n",
       "      <td>2019-01-14</td>\n",
       "      <td>07:15:00</td>\n",
       "      <td>2019-01-21 00:00:00</td>\n",
       "      <td>90.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180</td>\n",
       "      <td>HUP180_phaseII</td>\n",
       "      <td>2018-11-05</td>\n",
       "      <td>07:15:00</td>\n",
       "      <td>2018-11-13 00:00:00</td>\n",
       "      <td>51.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>177</td>\n",
       "      <td>HUP177_phaseII</td>\n",
       "      <td>2018-08-22</td>\n",
       "      <td>07:15:00</td>\n",
       "      <td>2018-08-31 00:00:00</td>\n",
       "      <td>88.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>173</td>\n",
       "      <td>HUP173_phaseII</td>\n",
       "      <td>2018-07-02</td>\n",
       "      <td>07:15:00</td>\n",
       "      <td>2018-07-13 00:00:00</td>\n",
       "      <td>76.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>172</td>\n",
       "      <td>HUP172_phaseII</td>\n",
       "      <td>2018-06-16</td>\n",
       "      <td>07:15:00</td>\n",
       "      <td>2018-06-29 00:00:00</td>\n",
       "      <td>109.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>166</td>\n",
       "      <td>HUP166_phaseII</td>\n",
       "      <td>2018-03-19</td>\n",
       "      <td>07:15:00</td>\n",
       "      <td>2018-03-28 00:00:00</td>\n",
       "      <td>60.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>160</td>\n",
       "      <td>HUP160_phaseII</td>\n",
       "      <td>2018-01-17</td>\n",
       "      <td>07:15:00</td>\n",
       "      <td>2018-02-01 00:00:00</td>\n",
       "      <td>80.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>151</td>\n",
       "      <td>HUP151_phaseII</td>\n",
       "      <td>2017-10-25</td>\n",
       "      <td>07:15:00</td>\n",
       "      <td>2017-11-03 00:00:00</td>\n",
       "      <td>81.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>145</td>\n",
       "      <td>HUP145_phaseII</td>\n",
       "      <td>2017-08-09</td>\n",
       "      <td>07:15:00</td>\n",
       "      <td>2017-08-21 00:00:00</td>\n",
       "      <td>122.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>142</td>\n",
       "      <td>HUP142_phaseII</td>\n",
       "      <td>2017-06-28</td>\n",
       "      <td>07:15:00</td>\n",
       "      <td>2017-07-13 00:00:00</td>\n",
       "      <td>65.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>138</td>\n",
       "      <td>HUP138_phaseII</td>\n",
       "      <td>2017-04-12</td>\n",
       "      <td>07:15:00</td>\n",
       "      <td>2017-04-20 00:00:00</td>\n",
       "      <td>84.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hup_id IEEG_Portal_Number Implant_Date implant_time        Explant_Date  \\\n",
       "0      223     HUP223_phaseII   2021-09-29     07:15:00 2021-10-08 08:21:00   \n",
       "1      187     HUP187_phaseII   2019-03-11     07:15:00 2019-03-19 00:00:00   \n",
       "2      185     HUP185_phaseII   2019-01-21     07:15:00 2019-02-01 00:00:00   \n",
       "3      184     HUP184_phaseII   2019-01-14     07:15:00 2019-01-21 00:00:00   \n",
       "4      180     HUP180_phaseII   2018-11-05     07:15:00 2018-11-13 00:00:00   \n",
       "5      177     HUP177_phaseII   2018-08-22     07:15:00 2018-08-31 00:00:00   \n",
       "6      173     HUP173_phaseII   2018-07-02     07:15:00 2018-07-13 00:00:00   \n",
       "7      172     HUP172_phaseII   2018-06-16     07:15:00 2018-06-29 00:00:00   \n",
       "8      166     HUP166_phaseII   2018-03-19     07:15:00 2018-03-28 00:00:00   \n",
       "9      160     HUP160_phaseII   2018-01-17     07:15:00 2018-02-01 00:00:00   \n",
       "10     151     HUP151_phaseII   2017-10-25     07:15:00 2017-11-03 00:00:00   \n",
       "11     145     HUP145_phaseII   2017-08-09     07:15:00 2017-08-21 00:00:00   \n",
       "12     142     HUP142_phaseII   2017-06-28     07:15:00 2017-07-13 00:00:00   \n",
       "13     138     HUP138_phaseII   2017-04-12     07:15:00 2017-04-20 00:00:00   \n",
       "\n",
       "    weight_kg  \n",
       "0       101.4  \n",
       "1        86.2  \n",
       "2        76.2  \n",
       "3        90.7  \n",
       "4        51.3  \n",
       "5        88.4  \n",
       "6        76.6  \n",
       "7       109.4  \n",
       "8        60.3  \n",
       "9        80.6  \n",
       "10       81.6  \n",
       "11      122.9  \n",
       "12       65.3  \n",
       "13       84.4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only keep the rows in patients_df that correspond to the completed_hup_ids\n",
    "patients_df = patients_df[patients_df[\"hup_id\"].isin(completed_hup_ids)]\n",
    "# reset the index of patients_df\n",
    "patients_df = patients_df.reset_index(drop=True)\n",
    "patients_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hup_id</th>\n",
       "      <th>ieeg_offset_1</th>\n",
       "      <th>ieeg_offset_2</th>\n",
       "      <th>ieeg_offset_3</th>\n",
       "      <th>ieeg_offset_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>225</td>\n",
       "      <td>136590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>224</td>\n",
       "      <td>135178</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>223</td>\n",
       "      <td>118454</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>221</td>\n",
       "      <td>135123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>219</td>\n",
       "      <td>119758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>141</td>\n",
       "      <td>133760</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>140</td>\n",
       "      <td>126678</td>\n",
       "      <td>283535.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>139</td>\n",
       "      <td>133613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>138</td>\n",
       "      <td>134989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>137</td>\n",
       "      <td>48893</td>\n",
       "      <td>370830.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    hup_id  ieeg_offset_1  ieeg_offset_2  ieeg_offset_3  ieeg_offset_4\n",
       "0      225         136590            NaN            NaN            NaN\n",
       "1      224         135178            NaN            NaN            NaN\n",
       "2      223         118454            NaN            NaN            NaN\n",
       "3      221         135123            NaN            NaN            NaN\n",
       "4      219         119758            NaN            NaN            NaN\n",
       "..     ...            ...            ...            ...            ...\n",
       "75     141         133760            NaN            NaN            NaN\n",
       "76     140         126678       283535.0            NaN            NaN\n",
       "77     139         133613            NaN            NaN            NaN\n",
       "78     138         134989            NaN            NaN            NaN\n",
       "79     137          48893       370830.0            NaN            NaN\n",
       "\n",
       "[80 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ieeg_offset_df = pd.read_excel(\"../../Data/ieeg_offset_new.xlsx\")\n",
    "ieeg_offset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['carbamazepine', 'clobazam', 'clonazepam', 'eslicarbazepine',\n",
       "       'lacosamide', 'lamotrigine', 'levetiracetam', 'lorazepam',\n",
       "       'oxcarbazepine', 'topiramate'], dtype='<U15')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_med_names = []\n",
    "\n",
    "for i, row in patients_df.iterrows():\n",
    "    # Get patient id and weight\n",
    "    patient_hup_id = row.hup_id\n",
    "\n",
    "    # Load HUP_{patient_hup_id}.npy from ../../Data/medications\n",
    "    aed_np_file = np.load(\n",
    "        f\"../../Data/medications/HUP_{patient_hup_id}.npy\", allow_pickle=True\n",
    "    )\n",
    "\n",
    "    all_dose_curves_plot = aed_np_file[0]\n",
    "    all_tHr_plot = aed_np_file[1]\n",
    "    all_med_names_plot = aed_np_file[2]\n",
    "\n",
    "    # Plot dose curves\n",
    "    for med_name in all_med_names_plot:\n",
    "        all_med_names.append(med_name)\n",
    "\n",
    "all_med_names = np.unique(np.array(all_med_names, dtype=str))\n",
    "all_med_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mg/L' 'ug/mL' 'ng/mL']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Drug</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>levetiracetam</td>\n",
       "      <td>12.00</td>\n",
       "      <td>46.00</td>\n",
       "      <td>mg/L</td>\n",
       "      <td>29.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>carbamazepine</td>\n",
       "      <td>4.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>mg/L</td>\n",
       "      <td>7.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oxcarbazepine</td>\n",
       "      <td>3.00</td>\n",
       "      <td>35.00</td>\n",
       "      <td>ug/mL</td>\n",
       "      <td>19.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clobazam</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.30</td>\n",
       "      <td>ng/mL</td>\n",
       "      <td>0.165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n-desmethylclobazam</td>\n",
       "      <td>0.30</td>\n",
       "      <td>3.00</td>\n",
       "      <td>ng/mL</td>\n",
       "      <td>1.650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>topiramate</td>\n",
       "      <td>5.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>mg/L</td>\n",
       "      <td>12.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>valproic acid</td>\n",
       "      <td>50.00</td>\n",
       "      <td>125.00</td>\n",
       "      <td>ug/mL</td>\n",
       "      <td>87.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lacosamide</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>ug/mL</td>\n",
       "      <td>5.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>felbamate</td>\n",
       "      <td>30.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>ug/mL</td>\n",
       "      <td>45.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lamotrigine</td>\n",
       "      <td>2.50</td>\n",
       "      <td>15.00</td>\n",
       "      <td>mg/L</td>\n",
       "      <td>8.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>clonazepam</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.07</td>\n",
       "      <td>ng/mL</td>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>zonisamide</td>\n",
       "      <td>10.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>mg/L</td>\n",
       "      <td>25.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pregabalin</td>\n",
       "      <td>2.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>ug/mL</td>\n",
       "      <td>6.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>phenytoin</td>\n",
       "      <td>10.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>ug/mL</td>\n",
       "      <td>15.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>brivaracetam</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.00</td>\n",
       "      <td>ug/mL</td>\n",
       "      <td>1.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>eslicarbazepine</td>\n",
       "      <td>3.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>mg/L</td>\n",
       "      <td>14.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gabapentin</td>\n",
       "      <td>3.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>mg/L</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>rufinamide</td>\n",
       "      <td>4.00</td>\n",
       "      <td>31.00</td>\n",
       "      <td>mg/L</td>\n",
       "      <td>17.500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Drug    Min     Max   Unit     Avg\n",
       "0         levetiracetam  12.00   46.00   mg/L  29.000\n",
       "1         carbamazepine   4.00   10.00   mg/L   7.000\n",
       "2         oxcarbazepine   3.00   35.00  ug/mL  19.000\n",
       "3              clobazam   0.03    0.30  ng/mL   0.165\n",
       "4   n-desmethylclobazam   0.30    3.00  ng/mL   1.650\n",
       "5            topiramate   5.00   20.00   mg/L  12.500\n",
       "6         valproic acid  50.00  125.00  ug/mL  87.500\n",
       "7            lacosamide   1.00   10.00  ug/mL   5.500\n",
       "8             felbamate  30.00   60.00  ug/mL  45.000\n",
       "9           lamotrigine   2.50   15.00   mg/L   8.750\n",
       "10           clonazepam   0.02    0.07  ng/mL   0.045\n",
       "11           zonisamide  10.00   40.00   mg/L  25.000\n",
       "12           pregabalin   2.00   10.00  ug/mL   6.000\n",
       "13            phenytoin  10.00   20.00  ug/mL  15.000\n",
       "14         brivaracetam   0.20    2.00  ug/mL   1.100\n",
       "15      eslicarbazepine   3.00   26.00   mg/L  14.500\n",
       "16           gabapentin   3.00   21.00   mg/L  12.000\n",
       "17           rufinamide   4.00   31.00   mg/L  17.500"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load aed_ref_ranges.xlsx from ./data/\n",
    "aed_ref_ranges_df = pd.read_excel(\"../../Data/aed_ref_ranges.xlsx\")\n",
    "# Lowercase Drug column\n",
    "aed_ref_ranges_df[\"Drug\"] = aed_ref_ranges_df[\"Drug\"].str.lower()\n",
    "# show unique units\n",
    "print(aed_ref_ranges_df[\"Unit\"].unique())\n",
    "# mg/L and ug/mL are the same\n",
    "# If Unit is ng/mL, convert to ug/mL\n",
    "aed_ref_ranges_df.loc[aed_ref_ranges_df[\"Unit\"] == \"ng/mL\", \"Min\"] = (\n",
    "    aed_ref_ranges_df[\"Min\"] / 1000\n",
    ")\n",
    "aed_ref_ranges_df.loc[aed_ref_ranges_df[\"Unit\"] == \"ng/mL\", \"Max\"] = (\n",
    "    aed_ref_ranges_df[\"Max\"] / 1000\n",
    ")\n",
    "# Add a column that takes the average of Min and Max\n",
    "aed_ref_ranges_df[\"Avg\"] = (aed_ref_ranges_df[\"Min\"] + aed_ref_ranges_df[\"Max\"]) / 2\n",
    "aed_ref_ranges_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spikes stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hup_id</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>fs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138</td>\n",
       "      <td>HUP138_phaseII</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>142</td>\n",
       "      <td>HUP142_phaseII</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>145</td>\n",
       "      <td>HUP145_phaseII</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151</td>\n",
       "      <td>HUP151_phaseII</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>160</td>\n",
       "      <td>HUP160_phaseII</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>166</td>\n",
       "      <td>HUP166_phaseII</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>172</td>\n",
       "      <td>HUP172_phaseII</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>173</td>\n",
       "      <td>HUP173_phaseII</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>177</td>\n",
       "      <td>HUP177_phaseII</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>180</td>\n",
       "      <td>HUP180_phaseII</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>184</td>\n",
       "      <td>HUP184_phaseII</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>185</td>\n",
       "      <td>HUP185_phaseII</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>187</td>\n",
       "      <td>HUP187_phaseII</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>223</td>\n",
       "      <td>HUP223_phaseII</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hup_id    dataset_name    fs\n",
       "0     138  HUP138_phaseII  1024\n",
       "1     142  HUP142_phaseII   512\n",
       "2     145  HUP145_phaseII   512\n",
       "3     151  HUP151_phaseII   512\n",
       "4     160  HUP160_phaseII  1024\n",
       "5     166  HUP166_phaseII  1024\n",
       "6     172  HUP172_phaseII   512\n",
       "7     173  HUP173_phaseII   256\n",
       "8     177  HUP177_phaseII   512\n",
       "9     180  HUP180_phaseII   512\n",
       "10    184  HUP184_phaseII   512\n",
       "11    185  HUP185_phaseII   512\n",
       "12    187  HUP187_phaseII   512\n",
       "13    223  HUP223_phaseII  1024"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"dma_ieeglogin.bin\", \"r\") as f:\n",
    "    session = Session(\"dma\", f.read())\n",
    "# Initialize a dataframe with hup_id, dataset_name, fs\n",
    "patients_df = pd.DataFrame(columns=[\"hup_id\", \"dataset_name\", \"fs\"])\n",
    "for patient_hup_id in completed_hup_ids:\n",
    "    dataset_name = f\"HUP{patient_hup_id}_phaseII\"\n",
    "    dataset = session.open_dataset(dataset_name)\n",
    "    all_channel_labels = np.array(dataset.get_channel_labels())\n",
    "    channel_labels_to_download = all_channel_labels[\n",
    "        electrode_selection(all_channel_labels)\n",
    "    ]\n",
    "\n",
    "    fs = int(dataset.get_time_series_details(channel_labels_to_download[0]).sample_rate)\n",
    "    # Construct a row and add it to the dataframe\n",
    "    row_df = pd.DataFrame(\n",
    "        [{\"hup_id\": patient_hup_id, \"dataset_name\": dataset_name, \"fs\": fs}]\n",
    "    )\n",
    "    patients_df = pd.concat([patients_df, row_df], ignore_index=True)\n",
    "# Sort the dataframe by hup_id\n",
    "patients_df = patients_df.sort_values(by=\"hup_id\")\n",
    "# reset the index\n",
    "patients_df = patients_df.reset_index(drop=True)\n",
    "patients_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing HUP 138 with fs 1024\n",
      "Processing HUP 142 with fs 512\n",
      "Processing HUP 145 with fs 512\n",
      "Processing HUP 151 with fs 512\n",
      "Processing HUP 160 with fs 1024\n",
      "Processing HUP 166 with fs 1024\n",
      "Processing HUP 172 with fs 512\n",
      "Processing HUP 173 with fs 256\n",
      "Processing HUP 177 with fs 512\n",
      "Processing HUP 180 with fs 512\n",
      "Processing HUP 184 with fs 512\n",
      "Processing HUP 185 with fs 512\n",
      "Processing HUP 187 with fs 512\n",
      "Processing HUP 223 with fs 1024\n"
     ]
    }
   ],
   "source": [
    "all_spikes_dfs = []\n",
    "all_fs = []\n",
    "\n",
    "for index, row in patients_df.iterrows():\n",
    "    patient_hup_id = row[\"hup_id\"]\n",
    "    fs = row[\"fs\"]\n",
    "    all_fs.append(fs)\n",
    "    print(f\"Processing HUP {patient_hup_id} with fs {fs}\")\n",
    "\n",
    "    ###############################\n",
    "    # Construct spike_files_df\n",
    "    ###############################\n",
    "\n",
    "    # Initialize an empty list to hold the data\n",
    "    data = []\n",
    "\n",
    "    # Iterate through all files in the directory\n",
    "    for filename in os.listdir(SPIKES_OUTPUT_DIR):\n",
    "        # Check if the file ends with .npy\n",
    "        if filename.endswith(\".npy\"):\n",
    "            # Use regular expression to match the pattern and extract desired numbers\n",
    "            match = re.match(r\"HUP(\\d+)_phaseII_(\\d+).npy\", filename)\n",
    "\n",
    "            if match:\n",
    "                current_patient_hup_id = int(match.group(1))\n",
    "                if current_patient_hup_id != patient_hup_id:\n",
    "                    continue\n",
    "                interval_index = int(match.group(2))\n",
    "\n",
    "                # Append the data to the list\n",
    "                data.append(\n",
    "                    {\n",
    "                        \"filename\": filename,\n",
    "                        \"interval_index\": interval_index,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    # Convert the list of dictionaries to a pandas DataFrame\n",
    "    spike_files_df = pd.DataFrame(data)\n",
    "    # Sort the DataFrame by the interval index\n",
    "    spike_files_df = spike_files_df.sort_values(by=\"interval_index\")\n",
    "    # Reset the index\n",
    "    spike_files_df = spike_files_df.reset_index(drop=True)\n",
    "    # Add a new column called \"start_sample_index\"\n",
    "    spike_files_df[\"start_sample_index\"] = (\n",
    "        spike_files_df[\"interval_index\"] * fs * 60 * 2\n",
    "    )\n",
    "\n",
    "    ###############################\n",
    "    # Construct all_spikes_df\n",
    "    ###############################\n",
    "    # Initialize an empty list to store individual DataFrames\n",
    "    dfs = []\n",
    "\n",
    "    for index, row in spike_files_df.iterrows():\n",
    "        filename = row[\"filename\"]\n",
    "        start_sample_index = row[\"start_sample_index\"]\n",
    "\n",
    "        # Load the data\n",
    "        spike_data = np.load(os.path.join(SPIKES_OUTPUT_DIR, filename))\n",
    "\n",
    "        # Adjust the start_sample_index\n",
    "        spike_data[:, 0] += start_sample_index\n",
    "\n",
    "        # Convert the modified spike_data to a DataFrame and append to the dfs list\n",
    "        dfs.append(\n",
    "            pd.DataFrame(\n",
    "                spike_data,\n",
    "                columns=[\n",
    "                    \"peak_index\",\n",
    "                    \"channel_index\",\n",
    "                    \"peak\",\n",
    "                    \"left_point\",\n",
    "                    \"right_point\",\n",
    "                    \"slow_end\",\n",
    "                    \"slow_max\",\n",
    "                    \"rise_amp\",\n",
    "                    \"decay_amp\",\n",
    "                    \"slow_width\",\n",
    "                    \"slow_amp\",\n",
    "                    \"rise_slope\",\n",
    "                    \"decay_slope\",\n",
    "                    \"average_amp\",\n",
    "                    \"linelen\",\n",
    "                ],\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Concatenate all the individual DataFrames into a single DataFrame\n",
    "    all_spikes_df = pd.concat(dfs, ignore_index=True)\n",
    "    # Drop any rows with any NaN values\n",
    "    all_spikes_df = all_spikes_df.dropna().reset_index(drop=True)\n",
    "    # Make peak_index and channel_index integers\n",
    "    all_spikes_df[\"peak_index\"] = all_spikes_df[\"peak_index\"].astype(int)\n",
    "    all_spikes_df[\"channel_index\"] = all_spikes_df[\"channel_index\"].astype(int)\n",
    "\n",
    "    ###############################\n",
    "    # ISI\n",
    "    ###############################\n",
    "    # Calculate the inter-spike interval\n",
    "    all_spikes_df[\"inter_spike_interval_samples\"] = all_spikes_df[\"peak_index\"].diff()\n",
    "\n",
    "    # Drop the first row and reset index\n",
    "    all_spikes_df = all_spikes_df.dropna().reset_index(drop=True)\n",
    "\n",
    "    # Convert the inter_spike_interval_samples column to integer\n",
    "    all_spikes_df[\"inter_spike_interval_samples\"] = all_spikes_df[\n",
    "        \"inter_spike_interval_samples\"\n",
    "    ].astype(int)\n",
    "\n",
    "    all_spikes_df[\"inter_spike_interval_sec\"] = (\n",
    "        all_spikes_df[\"inter_spike_interval_samples\"] / fs\n",
    "    ).astype(int)\n",
    "\n",
    "    all_spikes_dfs.append(all_spikes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 99.48431564,  54.59815003,  73.6997937 ,  54.59815003,\n",
       "        244.69193226,  60.3402876 ,  54.59815003,  20.08553692,\n",
       "         54.59815003,  54.59815003,  54.59815003,  40.44730436,\n",
       "         54.59815003, 148.4131591 ]),\n",
       " 14)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds = [4.6, 4, 4.3, 4, 5.5, 4.1, 4, 3, 4, 4, 4, 3.7, 4, 5]\n",
    "thresholds = np.exp(thresholds)\n",
    "thresholds, len(thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HUP 138 with fs 1024\n",
      "HUP 142 with fs 512\n",
      "HUP 145 with fs 512\n",
      "HUP 151 with fs 512\n",
      "HUP 160 with fs 1024\n",
      "HUP 166 with fs 1024\n",
      "HUP 172 with fs 512\n",
      "HUP 173 with fs 256\n",
      "HUP 177 with fs 512\n",
      "HUP 180 with fs 512\n",
      "HUP 184 with fs 512\n",
      "HUP 185 with fs 512\n",
      "HUP 187 with fs 512\n",
      "HUP 223 with fs 1024\n"
     ]
    }
   ],
   "source": [
    "for all_spikes_df, fs, hup_id, threshold in zip(\n",
    "    all_spikes_dfs, all_fs, completed_hup_ids, thresholds\n",
    "):\n",
    "    print(f\"HUP {hup_id} with fs {fs}\")\n",
    "    # Convert peak_index to second\n",
    "    all_spikes_df[\"peak_second\"] = all_spikes_df[\"peak_index\"] // fs\n",
    "    # Convert peak_index to minute\n",
    "    all_spikes_df[\"peak_minute\"] = all_spikes_df[\"peak_index\"] / fs // 60\n",
    "    # Convert peak_index to hour\n",
    "    all_spikes_df[\"peak_hour\"] = all_spikes_df[\"peak_index\"] / fs // 3600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing HUP 138\n",
      "ieeg_offset_seconds: 134989.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28100/1296569811.py:209: RuntimeWarning: Mean of empty slice\n",
      "  ad_ratio = np.nanmean(ad_ratio, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing HUP 142\n",
      "ieeg_offset_seconds: 127857.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28100/1296569811.py:209: RuntimeWarning: Mean of empty slice\n",
      "  ad_ratio = np.nanmean(ad_ratio, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing HUP 145\n",
      "ieeg_offset_seconds: 137942.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28100/1296569811.py:209: RuntimeWarning: Mean of empty slice\n",
      "  ad_ratio = np.nanmean(ad_ratio, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing HUP 151\n",
      "ieeg_offset_seconds: 138542.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28100/1296569811.py:209: RuntimeWarning: Mean of empty slice\n",
      "  ad_ratio = np.nanmean(ad_ratio, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing HUP 160\n",
      "ieeg_offset_seconds: 127579.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28100/1296569811.py:209: RuntimeWarning: Mean of empty slice\n",
      "  ad_ratio = np.nanmean(ad_ratio, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing HUP 166\n",
      "ieeg_offset_seconds: 132768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28100/1296569811.py:209: RuntimeWarning: Mean of empty slice\n",
      "  ad_ratio = np.nanmean(ad_ratio, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing HUP 172\n",
      "ieeg_offset_seconds: 143801.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28100/1296569811.py:209: RuntimeWarning: Mean of empty slice\n",
      "  ad_ratio = np.nanmean(ad_ratio, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing HUP 173\n",
      "ieeg_offset_seconds: 141119.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28100/1296569811.py:209: RuntimeWarning: Mean of empty slice\n",
      "  ad_ratio = np.nanmean(ad_ratio, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing HUP 177\n",
      "ieeg_offset_seconds: 127780.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28100/1296569811.py:209: RuntimeWarning: Mean of empty slice\n",
      "  ad_ratio = np.nanmean(ad_ratio, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing HUP 180\n",
      "ieeg_offset_seconds: 136260.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28100/1296569811.py:209: RuntimeWarning: Mean of empty slice\n",
      "  ad_ratio = np.nanmean(ad_ratio, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing HUP 184\n",
      "ieeg_offset_seconds: 124663.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28100/1296569811.py:209: RuntimeWarning: Mean of empty slice\n",
      "  ad_ratio = np.nanmean(ad_ratio, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing HUP 185\n",
      "ieeg_offset_seconds: 135857.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28100/1296569811.py:209: RuntimeWarning: Mean of empty slice\n",
      "  ad_ratio = np.nanmean(ad_ratio, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing HUP 187\n",
      "ieeg_offset_seconds: 121019.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28100/1296569811.py:209: RuntimeWarning: Mean of empty slice\n",
      "  ad_ratio = np.nanmean(ad_ratio, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing HUP 223\n",
      "ieeg_offset_seconds: 118454.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28100/1296569811.py:209: RuntimeWarning: Mean of empty slice\n",
      "  ad_ratio = np.nanmean(ad_ratio, axis=0)\n"
     ]
    }
   ],
   "source": [
    "for i, row in patients_df.iterrows():\n",
    "    # Get patient id and weight\n",
    "    patient_hup_id = row.hup_id\n",
    "    patient_idx = patient_hup_id_to_index[patient_hup_id]\n",
    "    fs = row.fs\n",
    "    all_spikes_df = all_spikes_dfs[i]\n",
    "    threshold = thresholds[i]\n",
    "    print(f\"Processing HUP {patient_hup_id}\")\n",
    "\n",
    "    # Find the ieeg_offset_1 value for patient_hup_id in ieeg_offset_df and convert it into float\n",
    "    ieeg_offset_seconds = float(\n",
    "        ieeg_offset_df.loc[\n",
    "            ieeg_offset_df[\"hup_id\"] == patient_hup_id, \"ieeg_offset_1\"\n",
    "        ].values[0]\n",
    "    )\n",
    "    print(f\"ieeg_offset_seconds: {ieeg_offset_seconds}\")\n",
    "    ieeg_offset_minutes = ieeg_offset_seconds / 60\n",
    "\n",
    "    ##############################################\n",
    "    # MEDICATIONS\n",
    "    ##############################################\n",
    "    # Load HUP_{patient_hup_id}.npy from ../../Data/medications\n",
    "    aed_np_file = np.load(\n",
    "        f\"../../Data/medications/HUP_{patient_hup_id}.npy\", allow_pickle=True\n",
    "    )\n",
    "\n",
    "    all_dose_curves_plot = aed_np_file[0]\n",
    "    all_tHr_plot = aed_np_file[1]\n",
    "    all_med_names_plot = aed_np_file[2]\n",
    "\n",
    "    # Construct the time axis\n",
    "    emu_start_time_hrs = min([all_tHr_plot[i][0] for i in range(len(all_tHr_plot))])\n",
    "    emu_end_time_hrs = all_tHr_plot[0][-1]\n",
    "    max_length = max([len(all_tHr_plot[i]) for i in range(len(all_tHr_plot))])\n",
    "    time_axis = np.linspace(emu_start_time_hrs, emu_end_time_hrs, max_length)\n",
    "\n",
    "    first_emu_hr = time_axis[0]\n",
    "\n",
    "    # Create a dataframe that will hold the dose curves for all patients\n",
    "    hourly_patient_features_df = pd.DataFrame(columns=[\"emu_time\"])\n",
    "    hourly_patient_features_df[\"emu_time\"] = time_axis\n",
    "\n",
    "    for potential_med_name in all_med_names:\n",
    "        hourly_patient_features_df[f\"med_{potential_med_name}_raw\"] = np.zeros(\n",
    "            len(time_axis)\n",
    "        )\n",
    "\n",
    "    sum_array = []\n",
    "\n",
    "    ##############################################\n",
    "    # MEDICATIONS Normalize to 1\n",
    "    ##############################################\n",
    "    for med_idx, med_name in enumerate(all_med_names_plot):\n",
    "        dose_times = all_tHr_plot[med_idx].flatten()\n",
    "        dose = all_dose_curves_plot[med_idx].flatten()\n",
    "\n",
    "        interp_func = interpolate.interp1d(\n",
    "            dose_times, dose, bounds_error=False, fill_value=0\n",
    "        )\n",
    "        dose_interp = interp_func(time_axis)\n",
    "\n",
    "        if med_name != \"lorazepam\":\n",
    "            sum_array.append(dose_interp)\n",
    "\n",
    "        hourly_patient_features_df[f\"med_{med_name}_raw\"] = dose_interp\n",
    "\n",
    "    cumulative_dose_curve = np.sum(sum_array, axis=0)\n",
    "    cumulative_dose_curve = cumulative_dose_curve / np.max(cumulative_dose_curve)\n",
    "\n",
    "    assert len(cumulative_dose_curve) == len(\n",
    "        time_axis\n",
    "    ), \"cumulative_dose_curve and time_axis should have the same length\"\n",
    "\n",
    "    hourly_patient_features_df[\"med_sum_no_lorazepam_raw\"] = cumulative_dose_curve\n",
    "\n",
    "    ##############################################\n",
    "    # MEDICATIONS Normalize with DDD\n",
    "    ##############################################\n",
    "    for med_idx, med_name in enumerate(all_med_names_plot):\n",
    "        dose_times = all_tHr_plot[med_idx].flatten()\n",
    "\n",
    "        # Find Avg for medication med_name in aed_ref_ranges_df\n",
    "        if med_name != \"lorazepam\":\n",
    "            ref_range = float(\n",
    "                aed_ref_ranges_df.loc[\n",
    "                    aed_ref_ranges_df[\"Drug\"] == med_name, \"Avg\"\n",
    "                ].values[0]\n",
    "            )\n",
    "        else:\n",
    "            ref_range = 1\n",
    "\n",
    "        dose = all_dose_curves_plot[med_idx].flatten()\n",
    "        dose = dose / ref_range\n",
    "\n",
    "        interp_func = interpolate.interp1d(\n",
    "            dose_times, dose, bounds_error=False, fill_value=0\n",
    "        )\n",
    "        dose_interp = interp_func(time_axis)\n",
    "\n",
    "        if med_name != \"lorazepam\":\n",
    "            sum_array.append(dose_interp)\n",
    "\n",
    "        hourly_patient_features_df[f\"med_{med_name}_raw\"] = dose_interp\n",
    "\n",
    "    cumulative_dose_curve = np.sum(sum_array, axis=0)\n",
    "\n",
    "    assert len(cumulative_dose_curve) == len(\n",
    "        time_axis\n",
    "    ), \"cumulative_dose_curve and time_axis should have the same length\"\n",
    "\n",
    "    hourly_patient_features_df[\"med_sum_no_lorazepam_ddd\"] = cumulative_dose_curve\n",
    "\n",
    "    ##############################################\n",
    "    # Group by 2 minutes and compute mean\n",
    "    ##############################################\n",
    "    hourly_patient_features_df[\"emu_minute\"] = (\n",
    "        (hourly_patient_features_df[\"emu_time\"] * 60).astype(int) // 2 * 2\n",
    "    )\n",
    "    hourly_patient_features_df = hourly_patient_features_df.groupby(\"emu_minute\").mean()\n",
    "    hourly_patient_features_df = hourly_patient_features_df.reset_index()\n",
    "    hourly_patient_features_df = hourly_patient_features_df.drop(columns=[\"emu_time\"])\n",
    "\n",
    "    ##############################################\n",
    "    # SEIZURE COUNT\n",
    "    ##############################################\n",
    "    seizure_times_sec = np.load(\n",
    "        f\"../../Data/seizures/source_mat/HUP_{patient_hup_id}.npy\"\n",
    "    )\n",
    "    seizure_times_sec = seizure_times_sec + ieeg_offset_seconds\n",
    "\n",
    "    # Convert seizure times from seconds to minutes\n",
    "    seizure_times_min = seizure_times_sec / 60\n",
    "\n",
    "    hourly_patient_features_df[\"had_seizure\"] = np.zeros(\n",
    "        len(hourly_patient_features_df), dtype=int\n",
    "    )\n",
    "\n",
    "    for sz_min in seizure_times_min[:, 0]:\n",
    "        hourly_patient_features_df.loc[\n",
    "            hourly_patient_features_df[\"emu_minute\"] == int(sz_min) // 2 * 2,\n",
    "            \"had_seizure\",\n",
    "        ] += 1\n",
    "\n",
    "    ##############################################\n",
    "    # Time since last seizure\n",
    "    ##############################################\n",
    "    # Initialize the list and timer\n",
    "    time_since_last_seizure = []\n",
    "    timer = None\n",
    "\n",
    "    # Loop through the dataframe and calculate the time since the last seizure\n",
    "    for had_seizure in hourly_patient_features_df[\"had_seizure\"]:\n",
    "        if had_seizure == 1:\n",
    "            timer = 0\n",
    "        elif timer is not None:  # if there has been a seizure before\n",
    "            timer += 2\n",
    "        else:\n",
    "            timer = None\n",
    "        time_since_last_seizure.append(timer)\n",
    "\n",
    "    # Add the list as a new column\n",
    "    hourly_patient_features_df[\"time_since_last_seizure\"] = time_since_last_seizure\n",
    "\n",
    "    ##########################################\n",
    "    # SYNCHRONY\n",
    "    ##########################################\n",
    "\n",
    "    # Determine the starting index for the synchrony data\n",
    "    start_index = None\n",
    "    for i, emu_min in enumerate(hourly_patient_features_df[\"emu_minute\"]):\n",
    "        if i < len(hourly_patient_features_df[\"emu_minute\"]) - 1:\n",
    "            next_emu_min = hourly_patient_features_df[\"emu_minute\"].iloc[i + 1]\n",
    "        else:\n",
    "            next_emu_min = emu_min + 2\n",
    "\n",
    "        if emu_min <= ieeg_offset_minutes < next_emu_min:\n",
    "            start_index = i\n",
    "            break\n",
    "\n",
    "    if start_index is None:\n",
    "        print(\"start_index is actually 0...\")\n",
    "        start_index = 0\n",
    "\n",
    "    synchrony_np = np.load(\n",
    "        f\"../../Data/synchrony/all/broadband/HUP_{patient_hup_id}.npy\"\n",
    "    )\n",
    "\n",
    "    # Initialize the synchrony column with NaNs\n",
    "    hourly_patient_features_df[f\"synchrony_broadband\"] = np.nan\n",
    "\n",
    "    # Insert synchrony values starting from the appropriate index\n",
    "    end_index = min(start_index + len(synchrony_np), len(hourly_patient_features_df))\n",
    "    hourly_patient_features_df.iloc[\n",
    "        start_index:end_index,\n",
    "        hourly_patient_features_df.columns.get_loc(f\"synchrony_broadband\"),\n",
    "    ] = synchrony_np[: end_index - start_index]\n",
    "\n",
    "    ##########################################\n",
    "    # AD Ratio\n",
    "    ##########################################\n",
    "    mat_file = scipy.io.loadmat(\n",
    "        f\"../../../erinconr/projects/fc_toolbox/results/analysis/intermediate/HUP{patient_hup_id}.mat\"\n",
    "    )\n",
    "    mat_file = mat_file[\"summ\"][0][0]\n",
    "    ad_ratio = mat_file[17]\n",
    "    num_channels = mat_file[6].shape[0]\n",
    "    assert ad_ratio.shape[0] == num_channels\n",
    "\n",
    "    ad_ratio = np.nanmean(ad_ratio, axis=0)\n",
    "    ad_ratio = (ad_ratio - np.nanmedian(ad_ratio)) / iqr(ad_ratio, nan_policy=\"omit\")\n",
    "    assert np.nansum(ad_ratio) != 0\n",
    "\n",
    "    # Reshape ad_ratio to match the granularity of the dataframe\n",
    "    reshaped_ad_ratio = np.repeat(ad_ratio, 5)\n",
    "\n",
    "    # Initialize the ad_ratio column with NaNs\n",
    "    hourly_patient_features_df[\"ad_ratio\"] = np.nan\n",
    "\n",
    "    # Insert reshaped_ad_ratio values starting from the appropriate index\n",
    "    end_index_ad_ratio = min(\n",
    "        start_index + len(reshaped_ad_ratio), len(hourly_patient_features_df)\n",
    "    )\n",
    "    hourly_patient_features_df.iloc[\n",
    "        start_index:end_index_ad_ratio,\n",
    "        hourly_patient_features_df.columns.get_loc(\"ad_ratio\"),\n",
    "    ] = reshaped_ad_ratio[: end_index_ad_ratio - start_index]\n",
    "\n",
    "    ##########################################\n",
    "    # EEG time\n",
    "    ##########################################\n",
    "    # Create the eeg_time column with NaN values\n",
    "    hourly_patient_features_df[\"eeg_time\"] = np.nan\n",
    "\n",
    "    # Define the eeg_time values starting from start_index\n",
    "    eeg_time_values = np.arange(\n",
    "        0, (end_index_ad_ratio - start_index) * 2, 2\n",
    "    )  # incrementing by 2 since the time is grouped by 2 minutes\n",
    "    hourly_patient_features_df.iloc[\n",
    "        start_index:end_index_ad_ratio,\n",
    "        hourly_patient_features_df.columns.get_loc(\"eeg_time\"),\n",
    "    ] = eeg_time_values\n",
    "\n",
    "    ##########################################\n",
    "    # SPIKES\n",
    "    ##########################################\n",
    "    filtered_df = all_spikes_df[\n",
    "        all_spikes_df.inter_spike_interval_samples < threshold\n",
    "    ].copy()\n",
    "\n",
    "    spike_rate_array = np.full_like(synchrony_np, np.nan)\n",
    "    spike_isi_array = np.full_like(synchrony_np, np.nan)\n",
    "    spike_fano_factor_array = np.full_like(synchrony_np, np.nan)\n",
    "    spike_num_channels_array = np.full_like(synchrony_np, np.nan)\n",
    "\n",
    "    for i in range(len(synchrony_np)):\n",
    "        current_df = filtered_df[\n",
    "            (filtered_df[\"peak_minute\"] >= i * 2)\n",
    "            & (filtered_df[\"peak_minute\"] < i * 2 + 2)\n",
    "        ]\n",
    "\n",
    "        spike_rate_array[i] = current_df.shape[0]\n",
    "        spike_isi_array[i] = current_df[\"inter_spike_interval_samples\"].mean()\n",
    "\n",
    "        # Compute Fano Factor = Variance(ISI) / Mean(ISI)\n",
    "        mean_isi = current_df[\"inter_spike_interval_samples\"].mean()\n",
    "        if mean_isi != 0:\n",
    "            spike_fano_factor_array[i] = (\n",
    "                current_df[\"inter_spike_interval_samples\"].var() / mean_isi\n",
    "            )\n",
    "        else:\n",
    "            spike_fano_factor_array[i] = np.nan\n",
    "\n",
    "        spike_num_channels_array[i] = current_df[\"channel_index\"].nunique() // (\n",
    "            current_df[\"channel_index\"].max() + 1\n",
    "        )\n",
    "\n",
    "    # Normalize spike_rate_array to have a max of 1\n",
    "    spike_rate_array = spike_rate_array / np.nanmax(spike_rate_array)\n",
    "\n",
    "    # Add spike metrics to dataframe\n",
    "    hourly_patient_features_df[\"spike_rate\"] = np.nan\n",
    "    hourly_patient_features_df[\"spike_isi\"] = np.nan\n",
    "    hourly_patient_features_df[\"spike_fano_factor\"] = np.nan\n",
    "    hourly_patient_features_df[\"spike_num_channels\"] = np.nan\n",
    "\n",
    "    hourly_patient_features_df.iloc[\n",
    "        start_index:end_index,\n",
    "        hourly_patient_features_df.columns.get_loc(\"spike_rate\"),\n",
    "    ] = spike_rate_array[: end_index - start_index]\n",
    "\n",
    "    hourly_patient_features_df.iloc[\n",
    "        start_index:end_index,\n",
    "        hourly_patient_features_df.columns.get_loc(\"spike_isi\"),\n",
    "    ] = spike_isi_array[: end_index - start_index]\n",
    "\n",
    "    hourly_patient_features_df.iloc[\n",
    "        start_index:end_index,\n",
    "        hourly_patient_features_df.columns.get_loc(\"spike_fano_factor\"),\n",
    "    ] = spike_fano_factor_array[: end_index - start_index]\n",
    "\n",
    "    hourly_patient_features_df.iloc[\n",
    "        start_index:end_index,\n",
    "        hourly_patient_features_df.columns.get_loc(\"spike_num_channels\"),\n",
    "    ] = spike_num_channels_array[: end_index - start_index]\n",
    "\n",
    "    ##############################################\n",
    "    # SAVE TO CSV\n",
    "    ##############################################\n",
    "\n",
    "    hourly_patient_features_df.to_csv(\n",
    "        f\"../../Data/giant_new_tables/HUP_{patient_hup_id}.csv\", index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
